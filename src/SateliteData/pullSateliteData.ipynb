{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install cdsapi  \n",
    "pip install pygrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, cdsapi, pygrib, calendar\n",
    "from QueryHandler import QueryHandler\n",
    "from shapely.geometry import Point\n",
    "from dotenv import load_dotenv\n",
    "import sqlalchemy as sq \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')\n",
    "from DataService import DataService\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "PG_DB = os.getenv('POSTGRES_DB')\n",
    "PG_ADDR = os.getenv('POSTGRES_ADDR')\n",
    "PG_PORT = os.getenv('POSTGRES_PORT')\n",
    "PG_USER = os.getenv('POSTGRES_USER')\n",
    "PG_PW = os.getenv('POSTGRES_PW')\n",
    "\n",
    "MIN_MONTH = 3\n",
    "MAX_MONTH = 12\n",
    "\n",
    "MIN_YEAR = 1995\n",
    "MAX_YEAR = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client()\n",
    "queryHandler = QueryHandler()\n",
    "db = DataService(PG_DB, PG_ADDR, PG_PORT, PG_USER, PG_PW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTable(db):\n",
    "    query = sq.text(queryHandler.tableExistsReq('copernicus_satelite_data'))\n",
    "    tableExists = queryHandler.readTableExists(db.execute(query))\n",
    "    \n",
    "    if not tableExists:\n",
    "        query = sq.text(queryHandler.createCopernicusTableReq())\n",
    "        db.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAgRegion(agRegions: gpd.GeoDataFrame, point: Point) -> str:\n",
    "    area = ''\n",
    "\n",
    "    for index, region in agRegions.iterrows():\n",
    "        if region['geometry'].contains(point)[0]:\n",
    "            area = region['car_name']\n",
    "            break\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeData(db, lon, lat, year, month, day, hour, region, attr, value):\n",
    "    datetime = datetime = np.datetime64(f'{year}-{month}-{day}T{hour}')\n",
    "    query = sq.text(queryHandler.createRowExistsInDBReq(lon, lat, datetime))\n",
    "    rowExists = queryHandler.readRowExistsInDB(db.execute(query))\n",
    "    hour = int(hour.split(':')[0])\n",
    "    \n",
    "    if rowExists:\n",
    "        query = sq.text(queryHandler.createUpdateRowReq(lon, lat, datetime, attr, value))\n",
    "        db.execute(query)\n",
    "    else:\n",
    "        query = sq.text(queryHandler.createInsertRowReq(lon, lat, datetime, year, month, day, hour, region, attr, value))\n",
    "        db.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(grbs, db, agRegions: gpd.GeoDataFrame, year, month, day, hour, attr):\n",
    "    listOfdata, listOfLats, listOfLons = grbs[1].data()\n",
    "\n",
    "    for listIndex, list in enumerate(listOfdata):\n",
    "        for dataIndex, data in enumerate(list):\n",
    "            x = listOfLons[listIndex][dataIndex]\n",
    "            y = listOfLats[listIndex][dataIndex]\n",
    "\n",
    "            point = Point(x, y)\n",
    "            point = gpd.GeoSeries(point, crs='EPSG:4326') \n",
    "            region = calcAgRegion(agRegions, point)\n",
    "\n",
    "        if region:\n",
    "            print('about to store in db')\n",
    "            storeData(db, x, y, year, month, day, hour, region, attr, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGeometry(conn) -> gpd.GeoDataFrame:\n",
    "    query = sq.text('select car_name, geometry FROM public.census_ag_regions')\n",
    "    agRegions = gpd.GeoDataFrame.from_postgis(query, conn, geom_col='geometry') # crs='EPSG:3347'\n",
    "    agRegions = agRegions.set_crs(\"EPSG:3347\", allow_override=True)\n",
    "    agRegions = agRegions.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    return agRegions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data for 1995 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 22:16:06,666 INFO Welcome to the CDS\n",
      "2023-06-11 22:16:06,668 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-land\n",
      "2023-06-11 22:16:06,857 INFO Request is queued\n",
      "2023-06-11 22:16:08,003 INFO Request is running\n",
      "2023-06-11 22:16:09,651 INFO Request is completed\n",
      "2023-06-11 22:16:09,653 INFO Downloading https://download-0014-clone.copernicus-climate.eu/cache-compute-0014/cache/data9/adaptor.mars.internal-1686521766.93957-7263-7-b2e27730-c39c-44c7-a520-b3cdd58f590d.grib to download.grib (96K)\n",
      "2023-06-11 22:16:10,803 INFO Download rate 83.6K/s  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file\n"
     ]
    }
   ],
   "source": [
    "years = [str(year) for year in range(MIN_YEAR, MAX_YEAR + 1)]\n",
    "months = [str(month) for month in range(MIN_MONTH, MAX_MONTH + 1)]\n",
    "\n",
    "attrs = [\n",
    "    '2m_dewpoint_temperature', '2m_temperature', 'evaporation_from_bare_soil', 'skin_reservoir_content', 'skin_temperature',\n",
    "    'snowmelt', 'soil_temperature_level_1', 'soil_temperature_level_2', 'soil_temperature_level_3', 'soil_temperature_level_4',\n",
    "    'surface_net_solar_radiation', 'surface_pressure', 'volumetric_soil_water_layer_1', 'volumetric_soil_water_layer_2', \n",
    "    'volumetric_soil_water_layer_3', 'volumetric_soil_water_layer_4'\n",
    "]\n",
    "\n",
    "hours = [\n",
    "    '00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00','12:00', '13:00', \n",
    "    '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00'\n",
    "]\n",
    "\n",
    "\n",
    "conn = db.connect()\n",
    "\n",
    "createTable(db)\n",
    "agRegions = loadGeometry(conn)\n",
    "\n",
    "for year in years:\n",
    "    print(f'Pulling data for {year} ...')\n",
    "\n",
    "    for month in months:\n",
    "        numDays = calendar.monthrange(int(year), int(month))[1]\n",
    "        days = [str(day) for day in range(1, numDays + 1)]\n",
    "\n",
    "        for day in days:\n",
    "            for hour in hours:\n",
    "                for attr in attrs:\n",
    "                    c.retrieve(\n",
    "                        'reanalysis-era5-land',\n",
    "                        {\n",
    "                            'format': 'grib',\n",
    "                            'variable': [attr],\n",
    "                            'year': year,\n",
    "                            'month': month,\n",
    "                            'day': [day],\n",
    "                            'time': [hour],\n",
    "                            'area': [61, -125, 48, -88],\n",
    "                        },\n",
    "                        'download.grib'\n",
    "                    )\n",
    "\n",
    "                    if attr == '2m_dewpoint_temperature' or attr == '2m_temperature':\n",
    "                        attr = attr[3:]\n",
    "\n",
    "                    # read the file, process it, delete it then go onto the next set of data\n",
    "                    grbs = pygrib.open('download.grib')\n",
    "                    processFile(grbs, db, agRegions, year, month, day, hour, attr)\n",
    "                    os.remove('download.grib')\n",
    "\n",
    "print('[SUCCESS] data pulled successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
