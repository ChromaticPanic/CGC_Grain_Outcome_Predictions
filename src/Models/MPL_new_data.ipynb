{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, VarianceThreshold\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import kerastuner as kt\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(\"../Shared/\")\n",
    "from DataService import DataService\n",
    "\n",
    "sys.path.append(\"../Datasets/\")\n",
    "# print(os.getcwd())\n",
    "from DataCreation import getDatasetV1, getDatasetV2, getDatasetV3, getDatasetV4\n",
    "from DataTestSplit import splitData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.config.set_visible_devices([], 'GPU')  # Hide GPU devices\n",
    "tensorflow.config.set_visible_devices(tensorflow.config.list_physical_devices('CPU'), 'CPU')  # Show CPU devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Optional, Tuple\n",
    "# def extractYears(df: pd.DataFrame, year: int, yearEnd: Optional[int] = None) -> pd.DataFrame:\n",
    "#     \"\"\"Extract the rows of a dataframe that correspond to a given year.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): The dataframe to extract from.\n",
    "#         year (int): The year to extract.\n",
    "#         yearEnd (int, optional): The end year to extract. Defaults to None.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: The extracted dataframe.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if yearEnd is None:\n",
    "#         return df.loc[df[\"year\"] == year]\n",
    "#     else:\n",
    "#         return df.loc[(df[\"year\"] >= year) & (df[\"year\"] <= yearEnd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conning to database\n",
    "load_dotenv()\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")\n",
    "\n",
    "if (\n",
    "    PG_DB is None\n",
    "    or PG_ADDR is None\n",
    "    or PG_PORT is None\n",
    "    or PG_USER is None\n",
    "    or PG_PW is None\n",
    "):\n",
    "    raise ValueError(\"Environment variables not set\")\n",
    "\n",
    "# connecting to database\n",
    "db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for weather station data\n",
    "weatherStationQuery = sq.text(\"\"\"\n",
    "    SELECT * from dataset_monthly_station\n",
    "\"\"\")\n",
    "# query for sat data\n",
    "weatherSatQuery = sq.text(\"\"\"\n",
    "    SELECT * from dataset_monthly_sat\n",
    "\"\"\")\n",
    "# query for ergot prev year data\n",
    "ergotPrevYearsAggQuery = sq.text(\"\"\"\n",
    "    SELECT year, district, \n",
    "    present_prev1, present_prev2, present_prev3,\n",
    "    percnt_true_prev1, percnt_true_prev2, percnt_true_prev3 \n",
    "    from agg_ergot_sample_v2\n",
    "\"\"\")\n",
    "# query for ergot data\n",
    "ergotTargetQuery = sq.text(\"\"\"\n",
    "    SELECT year, district, downgrade from ergot_sample_feat_eng\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriving data from database\n",
    "stationDf = pd.read_sql(weatherStationQuery, conn)\n",
    "satelliteDf = pd.read_sql(weatherSatQuery, conn)\n",
    "ergotPrevDf = pd.read_sql(ergotPrevYearsAggQuery, conn)\n",
    "ergotTargetDf = pd.read_sql(ergotTargetQuery, conn)\n",
    "\n",
    "conn.close()\n",
    "del conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>district</th>\n",
       "      <th>downgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1995</td>\n",
       "      <td>4820</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1995</td>\n",
       "      <td>4830</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1995</td>\n",
       "      <td>4840</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1995</td>\n",
       "      <td>4840</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157041</th>\n",
       "      <td>2022</td>\n",
       "      <td>4751</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157126</th>\n",
       "      <td>2022</td>\n",
       "      <td>4791</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157219</th>\n",
       "      <td>2022</td>\n",
       "      <td>4731</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157727</th>\n",
       "      <td>2022</td>\n",
       "      <td>4604</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157847</th>\n",
       "      <td>2022</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1633 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  district  downgrade\n",
       "0       1995      4810      False\n",
       "48      1995      4820      False\n",
       "190     1995      4830      False\n",
       "230     1995      4840      False\n",
       "280     1995      4840       True\n",
       "...      ...       ...        ...\n",
       "157041  2022      4751       True\n",
       "157126  2022      4791       True\n",
       "157219  2022      4731       True\n",
       "157727  2022      4604       True\n",
       "157847  2022      4830       True\n",
       "\n",
       "[1633 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheching for dublicates\n",
    "if ergotTargetDf.duplicated().any():\n",
    "    print('dublicates found')\n",
    "    ergotTargetDf.drop_duplicates( inplace=True)\n",
    "if (ergotTargetDf.isna().sum().sum() > 0):\n",
    "    print('NaN found')\n",
    "    ergotTargetDf.dropna(inplace=True)\n",
    "ergotTargetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>district</th>\n",
       "      <th>present_prev1</th>\n",
       "      <th>present_prev2</th>\n",
       "      <th>present_prev3</th>\n",
       "      <th>percnt_true_prev1</th>\n",
       "      <th>percnt_true_prev2</th>\n",
       "      <th>percnt_true_prev3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>4820</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>4830</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>4840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>4850</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2022</td>\n",
       "      <td>4761</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.062893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2022</td>\n",
       "      <td>4771</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.013072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2022</td>\n",
       "      <td>4790</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.147727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2022</td>\n",
       "      <td>4791</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.328571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2022</td>\n",
       "      <td>4610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  district  present_prev1  present_prev2  present_prev3  \\\n",
       "0     1995      4810          False          False          False   \n",
       "1     1995      4820          False          False          False   \n",
       "2     1995      4830          False          False          False   \n",
       "3     1995      4840          False          False          False   \n",
       "4     1995      4850          False          False          False   \n",
       "...    ...       ...            ...            ...            ...   \n",
       "1087  2022      4761          False           True           True   \n",
       "1088  2022      4771          False           True          False   \n",
       "1089  2022      4790           True           True           True   \n",
       "1090  2022      4791          False           True           True   \n",
       "1091  2022      4610          False          False          False   \n",
       "\n",
       "      percnt_true_prev1  percnt_true_prev2  percnt_true_prev3  \n",
       "0              0.000000           0.000000           0.000000  \n",
       "1              0.000000           0.000000           0.000000  \n",
       "2              0.000000           0.000000           0.000000  \n",
       "3              0.000000           0.000000           0.000000  \n",
       "4              0.000000           0.000000           0.000000  \n",
       "...                 ...                ...                ...  \n",
       "1087           0.010204           0.076923           0.062893  \n",
       "1088           0.000000           0.153333           0.013072  \n",
       "1089           0.025316           0.229167           0.147727  \n",
       "1090           0.028986           0.223881           0.328571  \n",
       "1091           0.000000           0.000000           0.000000  \n",
       "\n",
       "[1092 rows x 8 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ergotPrevDf.duplicated().any():\n",
    "    print('dublicates found')\n",
    "    ergotPrevDf.drop_duplicates( inplace=True)\n",
    "if (ergotPrevDf.isna().sum().sum() > 0):\n",
    "    print('NaN found')\n",
    "    ergotPrevDf.fillna(0, inplace=True)\n",
    "ergotPrevDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>district</th>\n",
       "      <th>min_temp_x</th>\n",
       "      <th>max_temp_x</th>\n",
       "      <th>mean_temp_x</th>\n",
       "      <th>min_dew_point_temp</th>\n",
       "      <th>max_dew_point_temp</th>\n",
       "      <th>mean_dew_point_temp</th>\n",
       "      <th>min_humidex</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_total_rain</th>\n",
       "      <th>min_total_snow</th>\n",
       "      <th>max_total_snow</th>\n",
       "      <th>mean_total_snow</th>\n",
       "      <th>min_total_precip</th>\n",
       "      <th>max_total_precip</th>\n",
       "      <th>mean_total_precip</th>\n",
       "      <th>min_snow_on_grnd</th>\n",
       "      <th>max_snow_on_grnd</th>\n",
       "      <th>mean_snow_on_grnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953</td>\n",
       "      <td>1</td>\n",
       "      <td>4606</td>\n",
       "      <td>-37.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-16.650918</td>\n",
       "      <td>-22.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.170833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953</td>\n",
       "      <td>1</td>\n",
       "      <td>4607</td>\n",
       "      <td>-31.7</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-14.224855</td>\n",
       "      <td>-33.9</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-14.939367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953</td>\n",
       "      <td>1</td>\n",
       "      <td>4611</td>\n",
       "      <td>-31.7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-13.608918</td>\n",
       "      <td>-32.2</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-14.508056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953</td>\n",
       "      <td>1</td>\n",
       "      <td>4612</td>\n",
       "      <td>-38.9</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-23.922143</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23.888548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.439583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.439583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953</td>\n",
       "      <td>1</td>\n",
       "      <td>4710</td>\n",
       "      <td>-33.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-11.815733</td>\n",
       "      <td>-33.9</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-12.818630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22602</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4830</td>\n",
       "      <td>-46.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-11.121018</td>\n",
       "      <td>-51.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-13.209914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.028596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.420344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.857147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22603</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4840</td>\n",
       "      <td>-41.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-17.592067</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-20.147237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.501989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.498098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22604</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4850</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>-16.074466</td>\n",
       "      <td>-46.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-19.138173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.291207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22605</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4860</td>\n",
       "      <td>-48.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-18.400136</td>\n",
       "      <td>-52.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-20.571919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.052028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.570979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.136807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22606</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4870</td>\n",
       "      <td>-45.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-20.325191</td>\n",
       "      <td>-50.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-23.248943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.727072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.742411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22607 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  district  min_temp_x  max_temp_x  mean_temp_x  \\\n",
       "0      1953      1      4606       -37.2        -3.3   -16.650918   \n",
       "1      1953      1      4607       -31.7        -4.4   -14.224855   \n",
       "2      1953      1      4611       -31.7        -5.0   -13.608918   \n",
       "3      1953      1      4612       -38.9        -7.2   -23.922143   \n",
       "4      1953      1      4710       -33.9         3.3   -11.815733   \n",
       "...     ...    ...       ...         ...         ...          ...   \n",
       "22602  2022     12      4830       -46.5        11.7   -11.121018   \n",
       "22603  2022     12      4840       -41.9         5.9   -17.592067   \n",
       "22604  2022     12      4850       -41.8         9.9   -16.074466   \n",
       "22605  2022     12      4860       -48.1         4.9   -18.400136   \n",
       "22606  2022     12      4870       -45.5         3.4   -20.325191   \n",
       "\n",
       "       min_dew_point_temp  max_dew_point_temp  mean_dew_point_temp  \\\n",
       "0                   -22.2                 0.0            -3.170833   \n",
       "1                   -33.9                -5.0           -14.939367   \n",
       "2                   -32.2                -5.6           -14.508056   \n",
       "3                   -40.0                 0.0           -23.888548   \n",
       "4                   -33.9                -1.1           -12.818630   \n",
       "...                   ...                 ...                  ...   \n",
       "22602               -51.8                 2.8           -13.209914   \n",
       "22603               -46.0                 2.7           -20.147237   \n",
       "22604               -46.6                 1.5           -19.138173   \n",
       "22605               -52.4                 0.4           -20.571919   \n",
       "22606               -50.2                -0.1           -23.248943   \n",
       "\n",
       "       min_humidex  ...  mean_total_rain  min_total_snow  max_total_snow  \\\n",
       "0              0.0  ...         0.000000             0.0            18.3   \n",
       "1              0.0  ...         0.000000             0.0             2.8   \n",
       "2              0.0  ...         0.000000             0.0             7.4   \n",
       "3              0.0  ...         0.000000             0.0             3.8   \n",
       "4              0.0  ...         0.000000             0.0             2.5   \n",
       "...            ...  ...              ...             ...             ...   \n",
       "22602          0.0  ...         0.000357             0.0             7.2   \n",
       "22603          0.0  ...         0.000000             0.0            12.6   \n",
       "22604          0.0  ...         0.000000             0.0             2.7   \n",
       "22605          0.0  ...         0.000000             0.0            15.5   \n",
       "22606          0.0  ...         0.007222             0.0             6.6   \n",
       "\n",
       "       mean_total_snow  min_total_precip  max_total_precip  mean_total_precip  \\\n",
       "0             1.375000               0.0              18.3           1.375000   \n",
       "1             0.466667               0.0               2.8           0.466667   \n",
       "2             1.366667               0.0               7.4           1.366667   \n",
       "3             0.439583               0.0               3.8           0.439583   \n",
       "4             0.220000               0.0               2.5           0.220000   \n",
       "...                ...               ...               ...                ...   \n",
       "22602         0.028596               0.0               8.4           0.420344   \n",
       "22603         0.030833               0.0               8.7           0.501989   \n",
       "22604         0.022471               0.0              10.0           0.291207   \n",
       "22605         0.052028               0.0              10.1           0.570979   \n",
       "22606         0.046507               0.0               8.6           0.727072   \n",
       "\n",
       "       min_snow_on_grnd  max_snow_on_grnd  mean_snow_on_grnd  \n",
       "0                   0.0               0.0           0.000000  \n",
       "1                   0.0               0.0           0.000000  \n",
       "2                   0.0               0.0           0.000000  \n",
       "3                   0.0               0.0           0.000000  \n",
       "4                   0.0               0.0           0.000000  \n",
       "...                 ...               ...                ...  \n",
       "22602               0.0              49.0           4.857147  \n",
       "22603               0.0              44.0           4.498098  \n",
       "22604               0.0              36.0           5.410004  \n",
       "22605               0.0              47.0           7.136807  \n",
       "22606               0.0              37.0           3.742411  \n",
       "\n",
       "[22607 rows x 39 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheching for dublicates\n",
    "if stationDf.duplicated().any():\n",
    "    print('dublicates found')\n",
    "    stationDf.drop_duplicates( inplace=True)\n",
    "if (stationDf.isna().sum().sum() > 0):\n",
    "    print('NaN found')\n",
    "    stationDf.dropna(inplace=True)\n",
    "stationDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on year and district\n",
    "# tempdf = pd.merge(satelliteDf, ergotPrevDf, on=[\"year\", \"district\"], how=\"left\")\n",
    "# del satelliteDf\n",
    "# del ergotPrevDf\n",
    "# tempdf = satelliteDf\n",
    "tempdf = stationDf\n",
    "\n",
    "# merge on year and district\n",
    "datasetDf = pd.merge(ergotTargetDf, tempdf, on=[\"year\", \"district\"], how=\"left\")\n",
    "datasetDf = pd.merge(datasetDf, ergotPrevDf, on=[\"year\", \"district\"], how=\"left\")\n",
    "del ergotTargetDf\n",
    "del tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>district</th>\n",
       "      <th>downgrade</th>\n",
       "      <th>month</th>\n",
       "      <th>min_temp_x</th>\n",
       "      <th>max_temp_x</th>\n",
       "      <th>mean_temp_x</th>\n",
       "      <th>min_dew_point_temp</th>\n",
       "      <th>max_dew_point_temp</th>\n",
       "      <th>mean_dew_point_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_total_precip</th>\n",
       "      <th>min_snow_on_grnd</th>\n",
       "      <th>max_snow_on_grnd</th>\n",
       "      <th>mean_snow_on_grnd</th>\n",
       "      <th>present_prev1</th>\n",
       "      <th>present_prev2</th>\n",
       "      <th>present_prev3</th>\n",
       "      <th>percnt_true_prev1</th>\n",
       "      <th>percnt_true_prev2</th>\n",
       "      <th>percnt_true_prev3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-29.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-10.052509</td>\n",
       "      <td>-31.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-12.584334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-26.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-5.029997</td>\n",
       "      <td>-29.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-10.819124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-28.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>-1.511578</td>\n",
       "      <td>-32.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-8.330515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.804839</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.551604</td>\n",
       "      <td>-21.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>-2.984549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.471667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>11.397211</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.413164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18658</th>\n",
       "      <td>2022</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>18.476221</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.039598</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18659</th>\n",
       "      <td>2022</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>36.9</td>\n",
       "      <td>13.501864</td>\n",
       "      <td>-30.9</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.855264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.066177</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18660</th>\n",
       "      <td>2022</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>28.3</td>\n",
       "      <td>7.661494</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.843584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.929443</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18661</th>\n",
       "      <td>2022</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-31.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-6.694053</td>\n",
       "      <td>-38.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-10.254210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.963579</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18662</th>\n",
       "      <td>2022</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-46.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-11.121018</td>\n",
       "      <td>-51.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-13.209914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.857147</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.513369</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18663 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  district  downgrade  month  min_temp_x  max_temp_x  mean_temp_x  \\\n",
       "0      1995      4810      False    1.0       -29.5        11.1   -10.052509   \n",
       "1      1995      4810      False    2.0       -26.1        20.0    -5.029997   \n",
       "2      1995      4810      False    3.0       -28.4        17.3    -1.511578   \n",
       "3      1995      4810      False    4.0       -14.8        19.0     3.551604   \n",
       "4      1995      4810      False    5.0        -4.6        31.5    11.397211   \n",
       "...     ...       ...        ...    ...         ...         ...          ...   \n",
       "18658  2022      4830       True    8.0        -2.0        34.6    18.476221   \n",
       "18659  2022      4830       True    9.0        -6.3        36.9    13.501864   \n",
       "18660  2022      4830       True   10.0       -10.6        28.3     7.661494   \n",
       "18661  2022      4830       True   11.0       -31.5        13.4    -6.694053   \n",
       "18662  2022      4830       True   12.0       -46.5        11.7   -11.121018   \n",
       "\n",
       "       min_dew_point_temp  max_dew_point_temp  mean_dew_point_temp  ...  \\\n",
       "0                   -31.9                 4.8           -12.584334  ...   \n",
       "1                   -29.9                 4.1           -10.819124  ...   \n",
       "2                   -32.2                 5.6            -8.330515  ...   \n",
       "3                   -21.3                 9.1            -2.984549  ...   \n",
       "4                   -10.2                11.2             2.413164  ...   \n",
       "...                   ...                 ...                  ...  ...   \n",
       "18658                -6.6                20.6             7.039598  ...   \n",
       "18659               -30.9                15.6             2.855264  ...   \n",
       "18660               -21.0                13.0            -0.843584  ...   \n",
       "18661               -38.8                 1.9           -10.254210  ...   \n",
       "18662               -51.8                 2.8           -13.209914  ...   \n",
       "\n",
       "       mean_total_precip  min_snow_on_grnd  max_snow_on_grnd  \\\n",
       "0               0.103226               0.0               9.0   \n",
       "1               0.078929               0.0               8.0   \n",
       "2               0.293871               0.0               8.0   \n",
       "3               0.603000               0.0              14.0   \n",
       "4               1.340645               0.0               0.0   \n",
       "...                  ...               ...               ...   \n",
       "18658           1.161233               0.0               0.0   \n",
       "18659           0.615462               0.0               4.0   \n",
       "18660           0.826722               0.0              45.0   \n",
       "18661           0.836543               0.0              38.0   \n",
       "18662           0.420344               0.0              49.0   \n",
       "\n",
       "       mean_snow_on_grnd  present_prev1  present_prev2  present_prev3  \\\n",
       "0               1.612903          False          False          False   \n",
       "1               0.326786          False          False          False   \n",
       "2               0.804839          False          False          False   \n",
       "3               0.471667          False          False          False   \n",
       "4               0.000000          False          False          False   \n",
       "...                  ...            ...            ...            ...   \n",
       "18658           0.000000          False           True           True   \n",
       "18659           0.066177          False           True           True   \n",
       "18660           0.929443          False           True           True   \n",
       "18661           3.963579          False           True           True   \n",
       "18662           4.857147          False           True           True   \n",
       "\n",
       "       percnt_true_prev1  percnt_true_prev2  percnt_true_prev3  \n",
       "0               0.000000           0.000000           0.000000  \n",
       "1               0.000000           0.000000           0.000000  \n",
       "2               0.000000           0.000000           0.000000  \n",
       "3               0.000000           0.000000           0.000000  \n",
       "4               0.000000           0.000000           0.000000  \n",
       "...                  ...                ...                ...  \n",
       "18658           0.025641           0.513369           0.083333  \n",
       "18659           0.025641           0.513369           0.083333  \n",
       "18660           0.025641           0.513369           0.083333  \n",
       "18661           0.025641           0.513369           0.083333  \n",
       "18662           0.025641           0.513369           0.083333  \n",
       "\n",
       "[18663 rows x 46 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess after merging the data \n",
    "mean = datasetDf.mean()\n",
    "datasetDf.fillna(mean, inplace=True)\n",
    "# one-hot encoding\n",
    "t = pd.get_dummies(datasetDf[\"district\"], drop_first=True)\n",
    "datasetDf = pd.concat([datasetDf, t], axis=1)\n",
    "datasetDf.columns = datasetDf.columns.astype(str)\n",
    "datasetDf.drop([\"district\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>downgrade</th>\n",
       "      <th>month</th>\n",
       "      <th>min_temp_x</th>\n",
       "      <th>max_temp_x</th>\n",
       "      <th>mean_temp_x</th>\n",
       "      <th>min_dew_point_temp</th>\n",
       "      <th>max_dew_point_temp</th>\n",
       "      <th>mean_dew_point_temp</th>\n",
       "      <th>min_humidex</th>\n",
       "      <th>...</th>\n",
       "      <th>4781</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4810</th>\n",
       "      <th>4820</th>\n",
       "      <th>4830</th>\n",
       "      <th>4840</th>\n",
       "      <th>4850</th>\n",
       "      <th>4860</th>\n",
       "      <th>4870</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-29.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-10.052509</td>\n",
       "      <td>-31.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-12.584334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-26.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-5.029997</td>\n",
       "      <td>-29.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-10.819124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-28.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>-1.511578</td>\n",
       "      <td>-32.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-8.330515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.551604</td>\n",
       "      <td>-21.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>-2.984549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>11.397211</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.413164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18658</th>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>18.476221</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.039598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18659</th>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>36.9</td>\n",
       "      <td>13.501864</td>\n",
       "      <td>-30.9</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.855264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18660</th>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>28.3</td>\n",
       "      <td>7.661494</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.843584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18661</th>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-31.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-6.694053</td>\n",
       "      <td>-38.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-10.254210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18662</th>\n",
       "      <td>2022</td>\n",
       "      <td>True</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-46.5</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-11.121018</td>\n",
       "      <td>-51.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-13.209914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18663 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  downgrade  month  min_temp_x  max_temp_x  mean_temp_x  \\\n",
       "0      1995      False    1.0       -29.5        11.1   -10.052509   \n",
       "1      1995      False    2.0       -26.1        20.0    -5.029997   \n",
       "2      1995      False    3.0       -28.4        17.3    -1.511578   \n",
       "3      1995      False    4.0       -14.8        19.0     3.551604   \n",
       "4      1995      False    5.0        -4.6        31.5    11.397211   \n",
       "...     ...        ...    ...         ...         ...          ...   \n",
       "18658  2022       True    8.0        -2.0        34.6    18.476221   \n",
       "18659  2022       True    9.0        -6.3        36.9    13.501864   \n",
       "18660  2022       True   10.0       -10.6        28.3     7.661494   \n",
       "18661  2022       True   11.0       -31.5        13.4    -6.694053   \n",
       "18662  2022       True   12.0       -46.5        11.7   -11.121018   \n",
       "\n",
       "       min_dew_point_temp  max_dew_point_temp  mean_dew_point_temp  \\\n",
       "0                   -31.9                 4.8           -12.584334   \n",
       "1                   -29.9                 4.1           -10.819124   \n",
       "2                   -32.2                 5.6            -8.330515   \n",
       "3                   -21.3                 9.1            -2.984549   \n",
       "4                   -10.2                11.2             2.413164   \n",
       "...                   ...                 ...                  ...   \n",
       "18658                -6.6                20.6             7.039598   \n",
       "18659               -30.9                15.6             2.855264   \n",
       "18660               -21.0                13.0            -0.843584   \n",
       "18661               -38.8                 1.9           -10.254210   \n",
       "18662               -51.8                 2.8           -13.209914   \n",
       "\n",
       "       min_humidex  ...  4781  4790  4791  4810  4820  4830  4840  4850  4860  \\\n",
       "0              0.0  ...     0     0     0     1     0     0     0     0     0   \n",
       "1              0.0  ...     0     0     0     1     0     0     0     0     0   \n",
       "2              0.0  ...     0     0     0     1     0     0     0     0     0   \n",
       "3              0.0  ...     0     0     0     1     0     0     0     0     0   \n",
       "4              0.0  ...     0     0     0     1     0     0     0     0     0   \n",
       "...            ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "18658          0.0  ...     0     0     0     0     0     1     0     0     0   \n",
       "18659          0.0  ...     0     0     0     0     0     1     0     0     0   \n",
       "18660          0.0  ...     0     0     0     0     0     1     0     0     0   \n",
       "18661          0.0  ...     0     0     0     0     0     1     0     0     0   \n",
       "18662          0.0  ...     0     0     0     0     0     1     0     0     0   \n",
       "\n",
       "       4870  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "18658     0  \n",
       "18659     0  \n",
       "18660     0  \n",
       "18661     0  \n",
       "18662     0  \n",
       "\n",
       "[18663 rows x 83 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheching for dublicates\n",
    "if datasetDf.duplicated().any():\n",
    "    print('dublicates found')\n",
    "    datasetDf.drop_duplicates( inplace=True)\n",
    "if (datasetDf.isna().sum().sum() > 0):\n",
    "    print('NaN found')\n",
    "    datasetDf.dropna(inplace=True)\n",
    "\n",
    "datasetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/dodhiajk/CGC_Grain_Outcome_Predictions/src/Models/../Datasets/DataTestSplit.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=drop_features, inplace=True)\n",
      "/home/student/dodhiajk/CGC_Grain_Outcome_Predictions/src/Models/../Datasets/DataTestSplit.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=drop_features, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# train 1995 - 2015 test 2016 - 2020\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = splitData(datasetDf, drop_features=[\"year\"], target_variable=\"downgrade\", pivot=2015, val_size=0.2, stratified=False)\n",
    "del datasetDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# oversampling data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_rs, y_train_rs = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    6824\n",
       "True     3704\n",
       "Name: downgrade, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    6824\n",
       "True     6824\n",
       "Name: downgrade, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_rs.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tensorflow.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tensorflow.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(input_dim=X_train.shape[1]))\n",
    "    for i in range(hp.Int('num_layers', 2, 30)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=124, #32\n",
    "                                            max_value=1748, # 512\n",
    "                                            step=32),\n",
    "                                activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid']),# , 'tanh', 'elu', 'selu', 'softplus', 'softsign', 'exponential', 'linear'])))\n",
    "                                kernel_regularizer = l1_l2(0.01)))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tensorflow.keras.metrics.AUC(name='auc')])\n",
    "    return model\n",
    "\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=256, step=32),\n",
    "#                            activation='relu', input_shape=(X_train.shape[1],)))\n",
    "#     for i in range(hp.Int('num_layers', min_value=1, max_value=5)):\n",
    "#         model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
    "#                                activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     # Compile the model with the desired optimizer, loss, and metrics\n",
    "#     model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "#                   loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = RandomSearch(\n",
    "#     build_model,\n",
    "#     objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "#     max_trials=5,\n",
    "#     executions_per_trial=3,\n",
    "#     overwrite=True,\n",
    "#     directory='data/random_search',\n",
    "#     project_name='ergot_random_search'\n",
    "#     )\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    # objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    executions_per_trial=2,\n",
    "    directory='data/BayesianOptimization',\n",
    "    project_name='ergot_random_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 30, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 124, 'max_value': 1748, 'step': 32, 'sampling': 'linear'}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 124, 'max_value': 1748, 'step': 32, 'sampling': 'linear'}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "7                 |7                 |num_layers\n",
      "1180              |1180              |units_0\n",
      "sigmoid           |sigmoid           |act_0\n",
      "1148              |1148              |units_1\n",
      "sigmoid           |sigmoid           |act_1\n",
      "0.0001            |0.0001            |learning_rate\n",
      "\n",
      "Epoch 1/20\n",
      "427/427 [==============================] - 7s 13ms/step - loss: 224.5672 - accuracy: 0.5039 - auc: 0.5017 - val_loss: 51.4813 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 23.0096 - accuracy: 0.5000 - auc: 0.5053 - val_loss: 11.9113 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 6.9445 - accuracy: 0.4978 - auc: 0.5000 - val_loss: 3.1295 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 1.5337 - accuracy: 0.4968 - auc: 0.5000 - val_loss: 0.8999 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8993 - accuracy: 0.4982 - auc: 0.5000 - val_loss: 0.8995 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8989 - accuracy: 0.5000 - auc: 0.5000 - val_loss: 0.8988 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8982 - accuracy: 0.4934 - auc: 0.5000 - val_loss: 0.8984 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8974 - accuracy: 0.5000 - auc: 0.5000 - val_loss: 0.8975 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8967 - accuracy: 0.4903 - auc: 0.5000 - val_loss: 0.8963 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8960 - accuracy: 0.4968 - auc: 0.5000 - val_loss: 0.8956 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8953 - accuracy: 0.4987 - auc: 0.5000 - val_loss: 0.8949 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8949 - accuracy: 0.4971 - auc: 0.5000 - val_loss: 0.8946 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8945 - accuracy: 0.4993 - auc: 0.5000 - val_loss: 0.8943 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8943 - accuracy: 0.4985 - auc: 0.5000 - val_loss: 0.8942 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8941 - accuracy: 0.5000 - auc: 0.5000 - val_loss: 0.8936 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 6s 13ms/step - loss: 0.8939 - accuracy: 0.4938 - auc: 0.5000 - val_loss: 0.8933 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 6s 13ms/step - loss: 0.8934 - accuracy: 0.4950 - auc: 0.5000 - val_loss: 0.8930 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8929 - accuracy: 0.4975 - auc: 0.5000 - val_loss: 0.8923 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8923 - accuracy: 0.4922 - auc: 0.5000 - val_loss: 0.8923 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 6s 14ms/step - loss: 0.8921 - accuracy: 0.4971 - auc: 0.5000 - val_loss: 0.8922 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 1/20\n",
      "427/427 [==============================] - 7s 14ms/step - loss: 224.6723 - accuracy: 0.5067 - auc: 0.5072 - val_loss: 51.5682 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 6s 14ms/step - loss: 23.0673 - accuracy: 0.5000 - auc: 0.4935 - val_loss: 11.9391 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 6s 13ms/step - loss: 6.9590 - accuracy: 0.5000 - auc: 0.5018 - val_loss: 3.1345 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 1.5329 - accuracy: 0.5003 - auc: 0.4979 - val_loss: 0.8978 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8978 - accuracy: 0.4890 - auc: 0.5000 - val_loss: 0.8974 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8974 - accuracy: 0.4949 - auc: 0.5000 - val_loss: 0.8973 - val_accuracy: 0.3423 - val_auc: 0.5000\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 6s 13ms/step - loss: 0.8967 - accuracy: 0.4955 - auc: 0.5000 - val_loss: 0.8962 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 6s 13ms/step - loss: 0.8960 - accuracy: 0.4988 - auc: 0.4960 - val_loss: 0.8952 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 5s 13ms/step - loss: 0.8953 - accuracy: 0.4974 - auc: 0.4965 - val_loss: 0.8939 - val_accuracy: 0.6577 - val_auc: 0.5000\n",
      "Epoch 10/20\n",
      "365/427 [========================>.....] - ETA: 0s - loss: 0.8947 - accuracy: 0.5014 - auc: 0.4984"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:251\u001b[0m, in \u001b[0;36mCondition.__init__\u001b[0;34m(self, lock)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_acquire_restore \u001b[39m=\u001b[39m lock\u001b[39m.\u001b[39;49m_acquire_restore\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_thread.lock' object has no attribute '_acquire_restore'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train_rs, y_train_rs, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/engine/training.py:1691\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1690\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1691\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1693\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseen, \u001b[39mlist\u001b[39;49m(logs\u001b[39m.\u001b[39;49mitems()), finalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/utils/generic_utils.py:296\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    293\u001b[0m         info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m info\n\u001b[0;32m--> 296\u001b[0m     io_utils\u001b[39m.\u001b[39;49mprint_msg(message, line_break\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    297\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/keras/utils/io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(message)\n\u001b[0;32m---> 80\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mflush()\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     logging\u001b[39m.\u001b[39minfo(message)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/ipykernel/iostream.py:559\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[1;32m    558\u001b[0m \u001b[39m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m--> 559\u001b[0m evt \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39;49mEvent()\n\u001b[1;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(evt\u001b[39m.\u001b[39mset)\n\u001b[1;32m    561\u001b[0m \u001b[39m# and give a timeout to avoid\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:546\u001b[0m, in \u001b[0;36mEvent.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 546\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond \u001b[39m=\u001b[39m Condition(Lock())\n\u001b[1;32m    547\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:251\u001b[0m, in \u001b[0;36mCondition.__init__\u001b[0;34m(self, lock)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_acquire_restore \u001b[39m=\u001b[39m lock\u001b[39m.\u001b[39;49m_acquire_restore\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_rs, y_train_rs, epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of hyper perameter tuning\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method : 1\n",
    "# model = tuner.hypermodel.build(best_hps)\n",
    "# model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# Method : 2\n",
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.build(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using  validation_data\n",
    "# history = model.fit(X_train_rs, y_train_rs, epochs=500, batch_size=64, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# using validation_split\n",
    "history = model.fit(X_train_rs, y_train_rs, epochs=500, batch_size=64, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the training and validation loss for each epoch\n",
    "def evaluate_model(history):\n",
    "    # Get the training and validation loss from the history\n",
    "    training_loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "\n",
    "    # Get the training and validation accuracy from the history\n",
    "    training_accuracy = history.history['accuracy']\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Plot the training and validation loss\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_loss, label='Training Loss')\n",
    "    plt.plot(validation_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_accuracy, label='Training Accuracy')\n",
    "    plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Check if the model is overfitting, underfitting, or performing well\n",
    "    # final_training_loss = np.array(training_loss).mean()\n",
    "    # final_validation_loss = np.array(validation_loss).mean()\n",
    "\n",
    "    # final_training_accuracy = np.array(training_accuracy).mean()\n",
    "    # final_validation_accuracy = np.array(validation_accuracy).mean()\n",
    "\n",
    "    # if final_training_loss < final_validation_loss:\n",
    "    #     print(\"The model is likely underfitting.\")\n",
    "    # elif final_training_loss > final_validation_loss:\n",
    "    #     print(\"The model is likely overfitting.\")\n",
    "    # else:\n",
    "    #     print(\"The model is performing well and generalizing to new data.\")\n",
    "\n",
    "    # if final_training_accuracy == 1.0 and final_validation_accuracy == 1.0:\n",
    "    #     print(\"The model has achieved 100% accuracy on both training and validation data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, X_test):\n",
    "    y_log = model.predict(X_test)\n",
    "    y_pred = np.where(y_log > 0.5, 1, 0)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "    precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "    print(\"Precision: \", precision)\n",
    "\n",
    "    recall = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "    print(\"Recall: \", recall)\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"F1 Score: \", f1_score)\n",
    "\n",
    "    auc_score = roc_auc_score(y_val, y_pred)\n",
    "    print(\"AUC Score: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/83 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 585us/step\n",
      "Accuracy:  0.6576747720364742\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "F1 Score:  nan\n",
      "AUC Score:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1017537/1050445781.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n"
     ]
    }
   ],
   "source": [
    "model_predict(model, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 690us/step\n"
     ]
    }
   ],
   "source": [
    "# predicting the validation set results\n",
    "y_log = model.predict(X_val)\n",
    "y_pred = np.where(y_log > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6576747720364742\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "F1 Score:  nan\n",
      "AUC Score:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1017537/3592300193.py:6: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "recall = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score: \", f1_score)\n",
    "\n",
    "auc_score = roc_auc_score(y_val, y_pred)\n",
    "print(\"AUC Score: \", auc_score)\n",
    "\n",
    "# print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d1\n",
    "[64, 16, 8, 4, 1]\n",
    "- Accuracy:  0.7759562841530054\n",
    "- Precision:  0.8767123287671232\n",
    "- Recall:  0.847682119205298\n",
    "- F1 Score:  0.861952861952862\n",
    "- AUC Score:  0.642591059602649\n",
    "\n",
    "[48, 48, 48, 48, 1]\n",
    "- Accuracy:  0.7978142076502732\n",
    "- Precision:  0.9014084507042254\n",
    "- Recall:  0.847682119205298\n",
    "- F1 Score:  0.8737201365187712\n",
    "- AUC Score:  0.705091059602649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main prediction\n",
    "\n",
    "y_main_log = model.predict(X_test)\n",
    "y_main_pred = np.where(y_main_log > 0.5, 1, 0)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_main_pred)\n",
    "\n",
    "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "recall = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score: \", f1_score)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_main_pred)\n",
    "print(\"AUC Score: \", auc_score)\n",
    "\n",
    "# print(classification_report(y_test, y_main_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names):\n",
    "    # Get the weights of the first hidden layer\n",
    "    first_hidden_layer_weights = model.layers[0].get_weights()[0]\n",
    "    \n",
    "    # Calculate the mean absolute weight for each feature\n",
    "    feature_importance = np.mean(np.abs(first_hidden_layer_weights), axis=1)\n",
    "    \n",
    "    # Sort the features based on their importance\n",
    "    sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "    sorted_feature_importance = feature_importance[sorted_indices]\n",
    "    sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "    \n",
    "    # Plot the feature importance\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.bar(range(len(feature_names)), sorted_feature_importance)\n",
    "    plt.xticks(range(len(feature_names)), sorted_feature_names, rotation=45, ha='right')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Feature Importance')\n",
    "    plt.title('Feature Importance of MLP')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(model, X_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "\n",
    "        # Tune the number of dense layers and units\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
    "            model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                      min_value=32,\n",
    "                                                      max_value=512,\n",
    "                                                      step=32),\n",
    "                                        activation='relu'))\n",
    "\n",
    "        model.add(keras.layers.Dense(self.num_classes, activation='sigmoid'))\n",
    "\n",
    "        # Tune the learning rate for the optimizer\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        # model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        #               loss='binary_crossentropy',\n",
    "        #               metrics=['accuracy'])\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy', AUC(name='auc')])  # Add AUC metric\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "input_shape = (X_train.shape[1],)\n",
    "num_classes = 1\n",
    "\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "# Define your hypermodel with the input shape and number of classes\n",
    "hypermodel = MyHyperModel(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "# Initialize the BayesianOptimization tuner with the objective set to maximize AUC\n",
    "tuner = BayesianOptimization(\n",
    "    hypermodel,\n",
    "    objective=keras_tuner.Objective(\"val_auc\", direction=\"max\"),\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    directory='my_tuner_dir',\n",
    "    project_name='my_model_tuning'\n",
    ")\n",
    "\n",
    "# Start the hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             validation_data=(X_val, y_val),\n",
    "             epochs=10,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the best model with the best hyperparameters\n",
    "best_model = hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(X_train, y_train,\n",
    "               validation_data=(X_val, y_val),\n",
    "               epochs=50,  # Use an appropriate number of epochs\n",
    "               batch_size=32)  # Set a batch size that fits your data and hardware\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main_log = best_model.predict(X_val)\n",
    "y_main_pred = np.where(y_main_log > 0.5, 1, 0)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val, y_main_pred)\n",
    "\n",
    "accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "precision = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "recall = conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score: \", f1_score)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_main_pred)\n",
    "print(\"AUC Score: \", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
