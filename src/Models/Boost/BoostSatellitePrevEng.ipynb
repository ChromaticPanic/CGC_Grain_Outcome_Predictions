{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model on Satellite Data + previous ergot engineer features\n",
    "\n",
    "- Gradient builds an additive model in a forward stage-wise fashion, which allows for the optimization of arbitrary differentiable loss functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy as sq\n",
    "import sys, os\n",
    "import pickle\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import (  # type: ignore\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from imblearn.ensemble import (  # type: ignore\n",
    "    RUSBoostClassifier,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (  # type: ignore\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "os.chdir(\"../../\")\n",
    "from ModelBuilderMethods import getConn, extractYears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlimited line output\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>**Step 1**</u>: Data Selection\n",
    "\n",
    "In this step, we would choose the particular data/table, pick attributes from existing tables. Further aggregation/feature engineer can be done here to support the point of the research.\n",
    "\n",
    "Particular, for this notebook, we grab the following data and merge them (on year, district) into a single table:\n",
    "- Satellite weather data\n",
    "- ergot data (downgrade)\n",
    "- ergot previous feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherSatQuery = sq.text(\n",
    "    \"\"\"\n",
    "    SELECT * from dataset_cross_monthly_sat\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "ergotPrevYearsAggQuery = sq.text(\n",
    "    \"\"\"\n",
    "    SELECT year, district, \n",
    "    present_prev1, present_prev2, present_prev3,\n",
    "    percnt_true_prev1, percnt_true_prev2, percnt_true_prev3 \n",
    "    from agg_ergot_sample_v2\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "ergotTargetQuery = sq.text(\n",
    "    \"\"\"\n",
    "    SELECT year, district, downgrade from ergot_sample_feat_eng\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = getConn(\"./.env\")\n",
    "\n",
    "satelliteDf = pd.read_sql(weatherSatQuery, conn)\n",
    "ergotPrevDf = pd.read_sql(ergotPrevYearsAggQuery, conn)\n",
    "ergotTargetDf = pd.read_sql(ergotTargetQuery, conn)\n",
    "\n",
    "conn.close()\n",
    "del conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on year and district\n",
    "tempdf = pd.merge(satelliteDf, ergotPrevDf, on=[\"year\", \"district\"], how=\"left\")\n",
    "del satelliteDf\n",
    "del ergotPrevDf\n",
    "\n",
    "# merge on year and district\n",
    "datasetDf = pd.merge(ergotTargetDf, tempdf, on=[\"year\", \"district\"], how=\"left\")\n",
    "del ergotTargetDf\n",
    "del tempdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the district number would be categorized using [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) techniques.\n",
    "\n",
    "One-hot encoding techniques would take input, which is a categorical value. Then, the features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse_output parameter).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode district\n",
    "datasetDf[\"district\"] = datasetDf[\"district\"].astype(\"category\")\n",
    "\n",
    "temp = pd.get_dummies(datasetDf[\"district\"], prefix=\"district\", drop_first=True)\n",
    "datasetDf = pd.concat([datasetDf, temp], axis=1)\n",
    "\n",
    "datasetDf = datasetDf.drop(columns=[\"district\"])\n",
    "datasetDf[\"present_prev1\"] = datasetDf[\"present_prev1\"].astype(\"bool\")\n",
    "datasetDf[\"present_prev2\"] = datasetDf[\"present_prev2\"].astype(\"bool\")\n",
    "datasetDf[\"present_prev3\"] = datasetDf[\"present_prev3\"].astype(\"bool\")\n",
    "\n",
    "del temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>**Step 2**</u>: Splitting dataset\n",
    "\n",
    "- We split the whole dataset into the train/test split. Particularly, split them by year (1995 - 2015 for training, 2016 - 2020 for testing) since this is a time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 1995 - 2015 test 2016 - 2020\n",
    "trainDf = extractYears(datasetDf, 1995, 2015)\n",
    "testDf = extractYears(datasetDf, 2016, 2020)\n",
    "del datasetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop year\n",
    "trainDf = trainDf.drop(columns=[\"year\"])\n",
    "testDf = testDf.drop(columns=[\"year\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>**Step 3**</u>: [Balancing the dataset](https://imbalanced-learn.org/stable/)\n",
    "\n",
    "- Our dataset is unbalanced and can lead to bias when training/testing. Balacing step would help to eliminate the bias of the dataset, thus provide more reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downgrade\n",
      "False    122202\n",
      "True       2082\n",
      "Name: count, dtype: int64\n",
      "downgrade\n",
      "False    26307\n",
      "True      1016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pre balancing check\n",
    "# print value counts downgrade\n",
    "print(trainDf[\"downgrade\"].value_counts())\n",
    "print(testDf[\"downgrade\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downgrade                           0\n",
      "1:min_dewpoint_temperature          0\n",
      "1:min_temperature                   0\n",
      "1:min_evaporation_from_bare_soil    0\n",
      "1:min_skin_reservoir_content        0\n",
      "                                   ..\n",
      "district_4830                       0\n",
      "district_4840                       0\n",
      "district_4850                       0\n",
      "district_4860                       0\n",
      "district_4870                       0\n",
      "Length: 693, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count nan\n",
    "print(trainDf.isna().sum())\n",
    "# set nan to 0\n",
    "# trainDf = trainDf.fillna(0)\n",
    "\n",
    "# drop nan\n",
    "trainDf = trainDf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "balancer = SMOTEENN(sampling_strategy=1, random_state=42)\n",
    "balancedTrainDfX, balancedTrainDfY = balancer.fit_resample(\n",
    "    trainDf.drop(columns=\"downgrade\"), trainDf[\"downgrade\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downgrade\n",
      "False    77752\n",
      "True     15878\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# post balancing check\n",
    "# print value counts downgrade\n",
    "print(balancedTrainDfY.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>**Step 4**</u>: Regularization / Normalization\n",
    "some blurb about scalers  \n",
    "\n",
    "1. [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)             \n",
    "2. [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)  \n",
    "3. [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)  \n",
    "4. [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)  \n",
    "5. [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html)  \n",
    "6. [PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html)  \n",
    "7. [QuantileTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(model_name, y_true, y_pred):\n",
    "    print(model_name)\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision: \", precision_score(y_true, y_pred))\n",
    "    print(\"Recall: \", recall_score(y_true, y_pred))\n",
    "    print(\"F1: \", f1_score(y_true, y_pred))\n",
    "    print(\"ROC AUC: \", roc_auc_score(y_true, y_pred))\n",
    "    print(\"Classification Report: \\n\", classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>**Step 5**</u>: Gradient Boosting Classifier Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u>**Step 5.1**</u>: Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATORS = 400\n",
    "DEPTH = 40\n",
    "CORES = -1\n",
    "MINSPLSPLIT = 8\n",
    "MINSAMPLELEAF = 4\n",
    "\n",
    "gradient_boosting_model = GradientBoostingClassifier(\n",
    "    n_estimators=ESTIMATORS,\n",
    "    random_state=42,\n",
    "    max_depth=DEPTH,\n",
    "    verbose=1,\n",
    "    n_iter_no_change=200,\n",
    ")\n",
    "balanced_gradient_boosting_model = GradientBoostingClassifier(\n",
    "    n_estimators=ESTIMATORS,\n",
    "    random_state=42,\n",
    "    max_depth=DEPTH,\n",
    "    verbose=1,\n",
    "    n_iter_no_change=200,\n",
    ")\n",
    "rusboost_model = RUSBoostClassifier(\n",
    "    n_estimators=ESTIMATORS, random_state=42, sampling_strategy=0.5\n",
    ")\n",
    "balanced_rusboost_model = RUSBoostClassifier(\n",
    "    n_estimators=ESTIMATORS, random_state=42, sampling_strategy=0.5\n",
    ")\n",
    "xgboost_model = XGBClassifier(\n",
    "    n_estimators=ESTIMATORS, random_state=42, max_depth=DEPTH, verbosity=1, n_jobs=CORES\n",
    ")\n",
    "balanced_xgboost_model = XGBClassifier(\n",
    "    n_estimators=ESTIMATORS, random_state=42, max_depth=DEPTH, verbosity=1, n_jobs=CORES\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u>**Step 5.2**</u>: Fit the training data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1921          782.22m\n",
      "         2           0.1861          776.89m\n",
      "         3           0.1819          775.55m\n",
      "         4           0.1786          766.19m\n",
      "         5           0.1761          753.05m\n",
      "         6           0.1739          687.79m\n",
      "         7           0.1722          627.68m\n",
      "         8           0.1707          588.95m\n",
      "         9           0.1695          534.67m\n",
      "        10           0.1684          489.71m\n",
      "        20           0.1630          286.10m\n",
      "        30           0.1614          215.93m\n",
      "        40           0.1608          178.71m\n",
      "        50           0.1607          157.61m\n",
      "        60           0.1606          139.41m\n",
      "        70           0.1606          125.12m\n",
      "        80           0.1606          113.72m\n",
      "        90           0.1605          104.54m\n",
      "       100           0.1605           96.61m\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_model.fit(trainDf.drop(columns=\"downgrade\"), trainDf[\"downgrade\"])\n",
    "balanced_gradient_boosting_model.fit(balancedTrainDfX, balancedTrainDfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RUSBoostClassifier(n_estimators=400, random_state=42, sampling_strategy=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RUSBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>RUSBoostClassifier(n_estimators=400, random_state=42, sampling_strategy=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RUSBoostClassifier(n_estimators=400, random_state=42, sampling_strategy=0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusboost_model.fit(trainDf.drop(columns=\"downgrade\"), trainDf[\"downgrade\"])\n",
    "balanced_rusboost_model.fit(balancedTrainDfX, balancedTrainDfY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:present_prev1: object, present_prev2: object, present_prev3: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xgboost_model\u001b[39m.\u001b[39;49mfit(trainDf\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdowngrade\u001b[39;49m\u001b[39m\"\u001b[39;49m), trainDf[\u001b[39m\"\u001b[39;49m\u001b[39mdowngrade\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m balanced_xgboost_model\u001b[39m.\u001b[39mfit(balancedTrainDfX, balancedTrainDfY)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[0;32m-> 1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1474\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1475\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1476\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1477\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1478\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1479\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1480\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1481\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1482\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1483\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1484\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1485\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1486\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[1;32m   1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    430\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    446\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[39m=\u001b[39m dispatch_data_backend(\n\u001b[1;32m    744\u001b[0m     data,\n\u001b[1;32m    745\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m    746\u001b[0m     threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnthread,\n\u001b[1;32m    747\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    748\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    749\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    750\u001b[0m )\n\u001b[1;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/data.py:970\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[1;32m    969\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[1;32m    971\u001b[0m                            feature_names, feature_types)\n\u001b[1;32m    972\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[1;32m    973\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_series(\n\u001b[1;32m    974\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[1;32m    975\u001b[0m     )\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/data.py:417\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_pandas_df\u001b[39m(\n\u001b[1;32m    410\u001b[0m     data: DataFrame,\n\u001b[1;32m    411\u001b[0m     enable_categorical: \u001b[39mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    416\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[0;32m--> 417\u001b[0m     data, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[1;32m    418\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[1;32m    419\u001b[0m     )\n\u001b[1;32m    420\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/data.py:391\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m     is_sparse,\n\u001b[1;32m    381\u001b[0m     is_categorical_dtype,\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    385\u001b[0m     dtype\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _pandas_dtype_mapper\n\u001b[1;32m    386\u001b[0m     \u001b[39mor\u001b[39;00m is_sparse(dtype)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mdtypes\n\u001b[1;32m    390\u001b[0m ):\n\u001b[0;32m--> 391\u001b[0m     _invalid_dataframe_dtype(data)\n\u001b[1;32m    393\u001b[0m feature_names, feature_types \u001b[39m=\u001b[39m _pandas_feature_info(\n\u001b[1;32m    394\u001b[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001b[1;32m    395\u001b[0m )\n\u001b[1;32m    397\u001b[0m transformed \u001b[39m=\u001b[39m _pandas_cat_null(data)\n",
      "File \u001b[0;32m~/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/xgboost/data.py:283\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    281\u001b[0m type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m{\u001b[39;00mtype_err\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:present_prev1: object, present_prev2: object, present_prev3: object"
     ]
    }
   ],
   "source": [
    "xgboost_model.fit(trainDf.drop(columns=\"downgrade\"), trainDf[\"downgrade\"])\n",
    "balanced_xgboost_model.fit(balancedTrainDfX, balancedTrainDfY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u>**Step 5.3**</u>: Test the model on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set nan to 0\n",
    "testDf = testDf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "\n",
    "predictions_gradient_boosting = gradient_boosting_model.predict(\n",
    "    testDf.drop(columns=\"downgrade\")\n",
    ")\n",
    "predictions_balanced_gradient_boosting = balanced_gradient_boosting_model.predict(\n",
    "    testDf.drop(columns=\"downgrade\")\n",
    ")\n",
    "predictions_rusboost = rusboost_model.predict(testDf.drop(columns=\"downgrade\"))\n",
    "predictions_balanced_rusboost = balanced_rusboost_model.predict(\n",
    "    testDf.drop(columns=\"downgrade\")\n",
    ")\n",
    "# predictions_xgboost = xgboost_model.predict(testDf.drop(columns=\"downgrade\"))\n",
    "# predictions_balanced_xgboost = balanced_xgboost_model.predict(\n",
    "#     testDf.drop(columns=\"downgrade\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    27323\n",
      "Name: count, dtype: int64\n",
      "False    20846\n",
      "True      6477\n",
      "Name: count, dtype: int64\n",
      "False    21013\n",
      "True      6310\n",
      "Name: count, dtype: int64\n",
      "False    26160\n",
      "True      1163\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(predictions_gradient_boosting).value_counts())\n",
    "print(pd.DataFrame(predictions_balanced_gradient_boosting).value_counts())\n",
    "print(pd.DataFrame(predictions_rusboost).value_counts())\n",
    "print(pd.DataFrame(predictions_balanced_rusboost).value_counts())\n",
    "# print(pd.DataFrame(predictions_xgboost).value_counts())\n",
    "# print(pd.DataFrame(predictions_balanced_xgboost).value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u>**Step 5.4**</u>: Evaluate models based on different metrics:\n",
    "- ACCURACY:\n",
    "- PRECISION:\n",
    "- RECALL:\n",
    "- F1:\n",
    "- ROC AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk GB imbalanced train set\n",
      "Accuracy:  0.9628152106284082\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1:  0.0\n",
      "ROC AUC:  0.5\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      1.00      0.98     26307\n",
      "        True       0.00      0.00      0.00      1016\n",
      "\n",
      "    accuracy                           0.96     27323\n",
      "   macro avg       0.48      0.50      0.49     27323\n",
      "weighted avg       0.93      0.96      0.94     27323\n",
      "\n",
      "\n",
      "imb GB balanced train set\n",
      "Accuracy:  0.7387914943454232\n",
      "Precision:  0.027481858885286398\n",
      "Recall:  0.17519685039370078\n",
      "F1:  0.047511010276257835\n",
      "ROC AUC:  0.467877438387256\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.76      0.85     26307\n",
      "        True       0.03      0.18      0.05      1016\n",
      "\n",
      "    accuracy                           0.74     27323\n",
      "   macro avg       0.49      0.47      0.45     27323\n",
      "weighted avg       0.93      0.74      0.82     27323\n",
      "\n",
      "\n",
      "sk RUS imbalanced train set\n",
      "Accuracy:  0.7635691541924386\n",
      "Precision:  0.06862123613312203\n",
      "Recall:  0.42618110236220474\n",
      "F1:  0.11820911820911821\n",
      "ROC AUC:  0.6013902432782627\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.78      0.86     26307\n",
      "        True       0.07      0.43      0.12      1016\n",
      "\n",
      "    accuracy                           0.76     27323\n",
      "   macro avg       0.52      0.60      0.49     27323\n",
      "weighted avg       0.94      0.76      0.84     27323\n",
      "\n",
      "\n",
      "imb RUS balanced train set\n",
      "Accuracy:  0.9226658858836877\n",
      "Precision:  0.028374892519346516\n",
      "Recall:  0.03248031496062992\n",
      "F1:  0.030289123451124368\n",
      "ROC AUC:  0.4947629841044074\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.96      0.96     26307\n",
      "        True       0.03      0.03      0.03      1016\n",
      "\n",
      "    accuracy                           0.92     27323\n",
      "   macro avg       0.50      0.49      0.50     27323\n",
      "weighted avg       0.93      0.92      0.93     27323\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/maith/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/student/maith/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/student/maith/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/student/maith/CGC_Grain_Outcome_Predictions/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# get accuracy precision recall f1 roc_auc\n",
    "printMetrics(\n",
    "    \"sk GB imbalanced train set\", testDf[\"downgrade\"], predictions_gradient_boosting\n",
    ")\n",
    "printMetrics(\n",
    "    \"imb GB balanced train set\",\n",
    "    testDf[\"downgrade\"],\n",
    "    predictions_balanced_gradient_boosting,\n",
    ")\n",
    "printMetrics(\"sk RUS imbalanced train set\", testDf[\"downgrade\"], predictions_rusboost)\n",
    "printMetrics(\n",
    "    \"imb RUS balanced train set\", testDf[\"downgrade\"], predictions_balanced_rusboost\n",
    ")\n",
    "# printMetrics(\"sk XGB imbalanced train set\", testDf[\"downgrade\"], predictions_xgboost)\n",
    "# printMetrics(\n",
    "#     \"imb XGB balanced train set\", testDf[\"downgrade\"], predictions_balanced_xgboost\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <u>**Step 5.5**</u>: Exports metric results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
