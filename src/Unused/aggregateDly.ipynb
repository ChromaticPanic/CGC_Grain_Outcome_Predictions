{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregateDly.ipynb\n",
    "After loading the [daily weather stations](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#stations_dly) and the [daily weather station data](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#ab_hld_station_data) the following class can be used to calculate the minimum, mean and maximum of all attributes per district\n",
    "\n",
    "##### Output:\n",
    "An excel document with the expected output columns (saves as specified by pathToSave i.e datasets uses datasets/data/)\n",
    "\n",
    "##### Remarks: \n",
    "- As weeks change per year, the weekly aggregation uses the year of 2001 (not a leap year)\n",
    "- Although a tablename is assigned there is a column limit in postgres that hinders this option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sqlalchemy as sq\n",
    "import geopandas as gpd  # type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, calendar\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLY_STATIONS = \"stations_dly\"  # table that contains the hourly stations\n",
    "\n",
    "AB_DLY_TABLE = \"ab_dly_station_data\"  # table that contains Albertas data\n",
    "MB_DLY_TABLE = \"mb_dly_station_data\"  # table that contains Manitobas data\n",
    "SK_DLY_TABLE = \"sk_dly_station_data\"  # table that contains Saskatchewans data\n",
    "\n",
    "MIN_MONTH = 1  # The month to start aggregating on\n",
    "MAX_MONTH = 12  # The month to finish aggregating on\n",
    "\n",
    "MIN_YEAR = 1995  # The year to start aggregating on\n",
    "MAX_YEAR = 2022  # The year to finish aggregating on\n",
    "TABLENAME = \"agg_dly_weather\"  # Name of the table where results are stored\n",
    "\n",
    "\n",
    "# Load the database connection environment variables located in the docker folder\n",
    "load_dotenv(\"../docker/.env\")\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if (\n",
    "        PG_DB is None\n",
    "        or PG_ADDR is None\n",
    "        or PG_PORT is None\n",
    "        or PG_USER is None\n",
    "        or PG_PW is None\n",
    "    ):\n",
    "        raise ValueError(\"Environment variables not set\")\n",
    "\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "    conn = db.connect()\n",
    "\n",
    "    weatherData = pullWeatherData(conn)\n",
    "    stationData = pullStationData(conn)\n",
    "\n",
    "    # merge both the weather station data and the station data together\n",
    "    df = weatherData.merge(stationData, on=\"station_id\")\n",
    "\n",
    "    agg_df = aggregateDlyData(df)\n",
    "    dates = getDates()\n",
    "    listForDF = reshapeDlyData(dates, agg_df, stationData)\n",
    "    final_df = pd.DataFrame(listForDF)\n",
    "\n",
    "    try:\n",
    "        final_df.to_csv(\n",
    "            path_or_buf=\"data/aggregatedDly.csv\",\n",
    "            sep=\",\",\n",
    "            columns=final_df.columns.tolist(),\n",
    "        )\n",
    "        # final_df.to_sql(TABLENAME, conn, schema=\"public\", if_exists=\"append\", index=False)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR]\")\n",
    "        print(e)\n",
    "\n",
    "    db.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullWeatherData(conn: sq.engine.Connection) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Loads the weather station data per province from the weather station data tables\n",
    "\n",
    "    Tables:\n",
    "    - [ab_dly_station_data](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#ab_dly_station_data)\n",
    "    - [mb_dly_station_data](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#mb_dly_station_data)\n",
    "    - [sk_dly_station_data](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#sk_dly_station_data)\n",
    "\n",
    "    Psuedocode:\n",
    "    - Create the weather station data SQL query\n",
    "    - [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "    \"\"\"\n",
    "    weatherDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{AB_DLY_TABLE}\n",
    "        UNION\n",
    "        SELECT * FROM public.{MB_DLY_TABLE}\n",
    "        UNION\n",
    "        SELECT * FROM public.{SK_DLY_TABLE};\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return pd.read_sql(weatherDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullStationData(conn: sq.engine.Connection) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Loads the weather stations from the daily weather station table\n",
    "\n",
    "    Tables:\n",
    "    - [stations_dly](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#stations_dly)\n",
    "\n",
    "    Psuedocode:\n",
    "    - Create the weather station SQL query\n",
    "    - [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "    - [Cast district into an integer](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)\n",
    "\n",
    "    Remarks: if district is not casted, future methods will throw errors\n",
    "    \"\"\"\n",
    "    stationDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT station_id, district FROM public.{DLY_STATIONS}\n",
    "        WHERE district IS NOT NULL;\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    stationData = pd.read_sql(stationDataQuery, conn)\n",
    "    stationData[[\"district\"]] = stationData[[\"district\"]].astype(int)\n",
    "\n",
    "    return stationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateDlyData(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Aggregate the daily weather station data by district and date\n",
    "\n",
    "    Psuedocode:\n",
    "    - Aggregate the columns by district and date\n",
    "    - Name the columns into the final DataFrame\n",
    "    \"\"\"\n",
    "    agg_df = (\n",
    "        df.groupby([\"district\", \"date\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"max_temp\": \"mean\",\n",
    "                \"min_temp\": \"mean\",\n",
    "                \"mean_temp\": \"mean\",\n",
    "                \"total_rain\": [\"min\", \"max\", \"mean\"],\n",
    "                \"total_snow\": [\"min\", \"max\", \"mean\"],\n",
    "                \"total_precip\": [\"min\", \"max\", \"mean\"],\n",
    "                \"snow_on_grnd\": [\"min\", \"max\", \"mean\"],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # sets the column names for the aggregate dataframe\n",
    "    agg_df.columns = [  # type: ignore\n",
    "        \"district\",\n",
    "        \"date\",\n",
    "        \"max_temp\",\n",
    "        \"min_temp\",\n",
    "        \"mean_temp\",\n",
    "        \"min_total_rain\",\n",
    "        \"max_total_rain\",\n",
    "        \"mean_total_rain\",\n",
    "        \"min_total_snow\",\n",
    "        \"max_total_snow\",\n",
    "        \"mean_total_snow\",\n",
    "        \"min_total_precip\",\n",
    "        \"max_total_precip\",\n",
    "        \"mean_total_precip\",\n",
    "        \"min_snow_on_grnd\",\n",
    "        \"max_snow_on_grnd\",\n",
    "        \"mean_snow_on_grnd\",\n",
    "    ]\n",
    "\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDates() -> list:\n",
    "    # figure out the date range for date processing - puts all 365 days as MO-DA into dates\n",
    "    dates = []  # all 365 days as MO-DA - strings\n",
    "\n",
    "    # the month range we want to pull data from - strings\n",
    "    months = [str(month) for month in range(MIN_MONTH, MAX_MONTH + 1)]\n",
    "    for month in months:\n",
    "        if len(month) == 1:\n",
    "            month = \"0\" + month\n",
    "\n",
    "        numDays = calendar.monthrange(2001, int(month))[1]\n",
    "        days = [str(day) for day in range(1, numDays + 1)]\n",
    "\n",
    "        for day in days:\n",
    "            if len(day) == 1:\n",
    "                day = \"0\" + day\n",
    "\n",
    "            dates.append(f\"{month}-{day}\")\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeDlyData(\n",
    "    dates: list, agg_df: pd.DataFrame, stationData: pd.DataFrame\n",
    ") -> list:\n",
    "    # loads all data where each row is its own dictionary so that it may added to a dataframe later (fast processing)\n",
    "    listForDF = []\n",
    "\n",
    "    # the year range we want to pull data from - ints\n",
    "    years = [year for year in range(MIN_YEAR, MAX_YEAR + 1)]\n",
    "    uniqueDistricts = stationData[\"district\"].unique()\n",
    "\n",
    "    # get the columns we will want to pull information from\n",
    "    cols = agg_df.columns.tolist()  # type: ignore\n",
    "    cols.remove(\"district\")\n",
    "    cols.remove(\"date\")\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"Processing year: {year}\")\n",
    "\n",
    "        for district in uniqueDistricts:\n",
    "            currData = {}  # for each year/district combination create a dictionary\n",
    "\n",
    "            # adds the year and district\n",
    "            currData[\"year\"] = year\n",
    "            currData[\"district\"] = district\n",
    "\n",
    "            # for each day we want to grab all attributes and establish them as columns i.e MO-DA:attribute\n",
    "            for date in dates:\n",
    "                # calculates the date we are current processing\n",
    "                fullDate = np.datetime64(f\"{str(year)}-{date}\")\n",
    "\n",
    "                # grab the row from the aggregated df\n",
    "                currRow = agg_df.loc[\n",
    "                    (agg_df[\"date\"] == fullDate) & (agg_df[\"district\"] == district)\n",
    "                ]\n",
    "\n",
    "                for col in cols:  # parse each of the desired columns\n",
    "                    currAttr = f\"{date}:{col}\"  # the current attribute which corresponds to the date and the column\n",
    "                    currVal = 0  # defaults as zero incase it does not exist\n",
    "\n",
    "                    if len(currRow[col]) == 1:\n",
    "                        # the current value from the loaded data\n",
    "                        currVal = currRow[col].item()\n",
    "\n",
    "                    currData[currAttr] = currVal\n",
    "\n",
    "            listForDF.append(currData)\n",
    "\n",
    "    return listForDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
