{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PullMoistureData.ipynb\n",
    "After [agriculture regions have been loaded](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions/blob/main/src/WeatherStation/importBoundariesAndStations.ipynb) and the soil moisture files have been downloaded, this script will load satellite soil moisture data into the database\n",
    "\n",
    "##### Required files: \n",
    "- [soil moisture data](https://www.esa.int/Applications/Observing_the_Earth/Space_for_our_climate/Nearly_four_decades_of_soil_moisture_data_now_available)\n",
    "\n",
    "##### Output:\n",
    "- [soil_moisture](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#soil_moisture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import geopandas as gpd  # type: ignore\n",
    "import xarray as xr  # type: ignore\n",
    "import sqlalchemy as sq\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService\n",
    "from SoilMoistureQueryHandler import SoilMoistureQueryHandler  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE = \"soil_moisture\"  # The table used to store the moisture data\n",
    "AG_REGIONS_TABLE = \"census_ag_regions\"  # The table that holds the agriculture regions\n",
    "\n",
    "MAIN_FOLDER_PATH = \"data/common/Images/\"  # Main folder that contains the moisture files\n",
    "LOG_FILE = \"data/pull_moisture.log\"  # The file used to store progress information\n",
    "ERROR_FILE = \"data/pull_moisture.err\"  # The file used to store ERROR information\n",
    "\n",
    "\n",
    "# Load the database connection environment variables located in the docker folder\n",
    "load_dotenv(\"../docker/.env\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if (\n",
    "        PG_DB is None\n",
    "        or PG_ADDR is None\n",
    "        or PG_PORT is None\n",
    "        or PG_USER is None\n",
    "        or PG_PW is None\n",
    "    ):\n",
    "        updateLog(LOG_FILE, \"Missing database credentials\")\n",
    "        raise ValueError(\"Environment variables not set\")\n",
    "\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "    conn = db.connect()\n",
    "\n",
    "    # Check if the soil moisture table exists, if not create it\n",
    "    queryHandler = SoilMoistureQueryHandler()\n",
    "    queryHandler.createSoilMoistureTableReq(db)\n",
    "\n",
    "    # Load the agriculture regions\n",
    "    agRegions = loadGeometry(conn)\n",
    "    folders = os.listdir(MAIN_FOLDER_PATH)\n",
    "\n",
    "    numErrors = 0  # Used to keep track of how many files are added to the database\n",
    "\n",
    "    for folder in folders:\n",
    "        try:\n",
    "            folderPath = os.path.join(MAIN_FOLDER_PATH, folder)\n",
    "            updateLog(LOG_FILE, f\"Started Updating data for {folder} in {TABLE} ...\")\n",
    "\n",
    "            fileList = get_nc_file_list(folderPath)\n",
    "\n",
    "            for file in fileList:\n",
    "                # Construct the full file path to get the netCDF files\n",
    "                filePath = os.path.join(folderPath, file)\n",
    "\n",
    "                # Process then store the moisture data\n",
    "                df = readNetCDF(filePath)\n",
    "                df = formatData(df)\n",
    "                df = addRegions(df, agRegions)\n",
    "                df.to_sql(TABLE, conn, schema=\"public\", if_exists=\"append\", index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            numErrors += 1\n",
    "            updateLog(\n",
    "                ERROR_FILE,\n",
    "                f\"\"\"\n",
    "                [Error] occurred while listing files in the main folder path: {MAIN_FOLDER_PATH}\n",
    "                {e}\n",
    "                \"\"\",\n",
    "            )\n",
    "\n",
    "    updateLog(\n",
    "        LOG_FILE,\n",
    "        f\"[SUCCESS] loaded {len(folder_names) - numErrors}/{len(folder_names)} data from {folder_name} into {TABLE}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Outputs progress updates to log files and to the console\n",
    "\n",
    "Pseudocode:  \n",
    "- Check if a filename is provided\n",
    "- Opens the file and adds the progress message\n",
    "- Print the message to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateLog(fileName: str, message: str) -> None:\n",
    "    try:\n",
    "        if fileName is not None:\n",
    "            with open(fileName, \"a\") as log:\n",
    "                log.write(message + \"\\n\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Retrieves a list of netCDF files from a folder\n",
    "\n",
    "Pseudocode:  \n",
    "- [Get a list of files in the folder](https://www.geeksforgeeks.org/python-os-listdir-method/)\n",
    "- Pick only the files that end with .nc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nc_file_list(folder_path: str) -> list:\n",
    "    file_list = os.listdir(folder_path)  # Get a list of files in the folder\n",
    "    nc_file_list = [filename for filename in file_list if filename.endswith(\".nc\")]\n",
    "\n",
    "    return nc_file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Load the [regions](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#census_ag_regions) from the database\n",
    "\n",
    "Pseudocode:  \n",
    "- Create the region SQL query\n",
    "- [Load the regions directly into a GeoDataFrame](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.from_postgis.html)\n",
    "    - crs sets the coordinate system, in our case we want EPSG:3347\n",
    "    - geom_col specifies which column holds the geometry/boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGeometry(conn: sq.engine.Connection) -> gpd.GeoDataFrame:\n",
    "    query = sq.text(f\"select cr_num, district, geometry FROM public.{AG_REGIONS_TABLE}\")\n",
    "\n",
    "    agRegions = gpd.GeoDataFrame.from_postgis(\n",
    "        query, conn, crs=\"EPSG:3347\", geom_col=\"geometry\"\n",
    "    )\n",
    "\n",
    "    return agRegions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Reads a netCDF file\n",
    "\n",
    "Pseudocode:  \n",
    "- [Open the file](https://docs.xarray.dev/en/stable/generated/xarray.open_dataset.html)\n",
    "- [Convert its contents into a DataFrame](https://docs.xarray.dev/en/latest/generated/xarray.DataArray.to_dataframe.html)\n",
    "- Close the file\n",
    "- If an error is encountered, log it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNetCDF(file: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        dataset = xr.open_dataset(file)\n",
    "        df = dataset.to_dataframe().reset_index()\n",
    "        dataset.close()\n",
    "    except Exception as e:\n",
    "        updateLog(ERROR_FILE, f\"Error reading netCDF file {e}\\n\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Prepares the DataFrame for future processing\n",
    "\n",
    "Preprocessing:  \n",
    "- [Drop irrelevant columns](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
    "- Drop irrelevant data\n",
    "- [Rename DataFrame columns](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            \"flag\",\n",
    "            \"freqbandID\",\n",
    "            \"dnflag\",\n",
    "            \"mode\",\n",
    "            \"sensor\",\n",
    "            \"t0\",\n",
    "            \"sm_uncertainty\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    df = df[df[\"soil_moisture\"].notna()]\n",
    "\n",
    "    df.rename(columns={df.columns[0]: \"date\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[3]: \"soil_moisture\"}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Labels the soil moisture data with the agriculture region districts\n",
    "\n",
    "Psuedocode:  \n",
    "- [Create geometry for each set of longitude/latitude](https://geopandas.org/en/stable/docs/reference/api/geopandas.points_from_xy.html) for the data found in the soil moisture data\n",
    "- [Set the coordinate system](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.to_crs.html) to the same one used throughout the codebase (EPSG:3347)\n",
    "- Label the data to the regions [by joining them together](https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html)\n",
    "    - how=left specifies that the Copernicus data is always kept even if it does not fall within a region\n",
    "    - predicate=within joins the data based on which rows of Copernicus data fall into what regions\n",
    "- [Drop irrelevant columns](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
    "- [Drop irregular data](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notna.html)\n",
    "- [Cast cr_num to an integer](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRegions(df: pd.DataFrame, agRegions: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    # Creates geometry from df using lon and lat as cords to create points (points being geometry)\n",
    "    df = gpd.GeoDataFrame(\n",
    "        df, crs=\"EPSG:4326\", geometry=gpd.points_from_xy(df.lon, df.lat)\n",
    "    )\n",
    "\n",
    "    # Changes the points projection to match the agriculture regions of EPSG:3347\n",
    "    df.to_crs(crs=\"EPSG:3347\", inplace=True)  # type: ignore\n",
    "\n",
    "    # Join the two dataframes based on which points fit within what agriculture regions\n",
    "    df = gpd.sjoin(df, agRegions, how=\"left\", predicate=\"within\")\n",
    "\n",
    "    df = pd.DataFrame(df.drop(columns=[\"index_right\", \"geometry\"]))\n",
    "\n",
    "    df = df[df[\"cr_num\"].notna()]  # Take rows that are valid numbers\n",
    "    df[[\"cr_num\"]] = df[[\"cr_num\"]].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
