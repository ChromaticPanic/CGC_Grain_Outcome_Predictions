{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# ImportErgot.py\n",
    "#\n",
    "# Purpose: to validate then store ergot data samples into a database\n",
    "#\n",
    "# Remarks:\n",
    "# - Eventually the goal is to create data folders. You then drop the files you want to read the data from\n",
    "#   after reading the data these files then get moved else where\n",
    "# ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ErgotQueryBuilder import ErgotQueryBuilder  # type: ignore\n",
    "from dotenv import load_dotenv\n",
    "import os, sys, math\n",
    "import sqlalchemy as sq  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"newErgot\"  # the name of the file you want to read\n",
    "TABLENAME = \"ergot_sample\"  # the name of the table where the data should be stored\n",
    "\n",
    "# the expected csv column names\n",
    "EXPECTED_COLS = [\n",
    "    \"Year\",\n",
    "    \"ProvinceAbbr\",\n",
    "    \"CropDistrictCode\",\n",
    "    \"Incidence\",\n",
    "    \"Severity\",\n",
    "]\n",
    "\n",
    "# the desired database column names\n",
    "RENAMED_COLS = [\n",
    "    \"year\",\n",
    "    \"province\",\n",
    "    \"crop_district\",\n",
    "    \"incidence\",\n",
    "    \"severity\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Holds the ergot data to import\n",
    "    ergotSamples = pd.read_csv(f\"./data/{FILENAME}.csv\")\n",
    "\n",
    "    if (\n",
    "        PG_DB is None\n",
    "        or PG_ADDR is None\n",
    "        or PG_PORT is None\n",
    "        or PG_USER is None\n",
    "        or PG_PW is None\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"One of the following environment variables is not set: POSTGRES_DB, POSTGRES_ADDR, POSTGRES_PORT, POSTGRES_USER, POSTGRES_PW\"\n",
    "        )\n",
    "\n",
    "    # Handles connections to the database\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "    conn = db.connect()  # Connect to the database\n",
    "\n",
    "    # Handles (builds/processes) requests to the database\n",
    "    queryHandler = ErgotQueryBuilder()\n",
    "    ommitedData = []  # Holds data that failed to meet constraint (and was thus ommited)\n",
    "\n",
    "    checkAttributes(ergotSamples, EXPECTED_COLS)\n",
    "    checkTable(db, queryHandler)\n",
    "\n",
    "    # For each sample, verify the data\n",
    "    for index, sample in ergotSamples.iterrows():\n",
    "        validYear = not None and sample[EXPECTED_COLS[0]] > 0\n",
    "        validProv = not None and len(sample[EXPECTED_COLS[1]]) == 2\n",
    "        validCode = sample[EXPECTED_COLS[2]] > 0\n",
    "        validIncidence = not None and (\n",
    "            sample[EXPECTED_COLS[3]] == 0 or sample[EXPECTED_COLS[3]] == 1\n",
    "        )\n",
    "        validSeverity = (\n",
    "            sample[EXPECTED_COLS[4]] >= 0 and sample[EXPECTED_COLS[4]] <= 100\n",
    "        )\n",
    "\n",
    "        # Both CropDistrictCode and Severity can be Null, but if thats the case they need to be manually adjusted\n",
    "        if math.isnan(sample[EXPECTED_COLS[4]]):\n",
    "            validSeverity = True\n",
    "\n",
    "        # If data fails to meet requirements, save for later\n",
    "        if (\n",
    "            not validYear\n",
    "            or not validProv\n",
    "            or not validCode\n",
    "            or not validIncidence\n",
    "            or not validSeverity\n",
    "        ):\n",
    "            ommitedData.append({\"index\": index, \"sample\": sample})\n",
    "\n",
    "    # Remove the data that failed to meet requirements\n",
    "    for data in ommitedData:\n",
    "        ergotSamples.drop(data[\"index\"], inplace=True)\n",
    "\n",
    "    # Drops extra attributes and renames columns\n",
    "    dropExtraAttributes(ergotSamples, EXPECTED_COLS)\n",
    "    ergotSamples.rename(\n",
    "        columns={ergotSamples.columns[0]: RENAMED_COLS[0]}, inplace=True\n",
    "    )\n",
    "    ergotSamples.rename(\n",
    "        columns={ergotSamples.columns[1]: RENAMED_COLS[1]}, inplace=True\n",
    "    )\n",
    "    ergotSamples.rename(\n",
    "        columns={ergotSamples.columns[2]: RENAMED_COLS[2]}, inplace=True\n",
    "    )\n",
    "    ergotSamples.rename(\n",
    "        columns={ergotSamples.columns[3]: RENAMED_COLS[3]}, inplace=True\n",
    "    )\n",
    "    ergotSamples.rename(\n",
    "        columns={ergotSamples.columns[4]: RENAMED_COLS[4]}, inplace=True\n",
    "    )\n",
    "    ergotSamples.loc[ergotSamples[\"severity\"].isna(), \"severity\"] = 0\n",
    "\n",
    "    # Sets the according data type for each attribute\n",
    "    ergotSamples[[\"province\"]] = ergotSamples[[\"province\"]].astype(str)\n",
    "    ergotSamples[[\"severity\"]] = ergotSamples[[\"severity\"]].astype(float)\n",
    "    ergotSamples[[\"incidence\"]] = ergotSamples[[\"incidence\"]].astype(bool)\n",
    "    ergotSamples[[\"year\", \"crop_district\"]] = ergotSamples[\n",
    "        [\"year\", \"crop_district\"]\n",
    "    ].astype(int)\n",
    "\n",
    "    # Stores the resulting data (not using return value due to its inaccuracy)\n",
    "    ergotSamples.to_sql(\n",
    "        TABLENAME, conn, schema=\"public\", if_exists=\"append\", index=False\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[SUCCESS] added {len(ergotSamples) - len(ommitedData)}/{len(ergotSamples)} ergot data samples from {FILENAME}.csv\"\n",
    "    )\n",
    "    if len(ommitedData) > 0:\n",
    "        print(\n",
    "            f\"{len(ommitedData)} samples were ommited due to data constraints, they are as follows:\"\n",
    "        )\n",
    "\n",
    "        for sample in ommitedData:\n",
    "            print(f'\\t{sample[\"index\"]}: {sample[\"sample\"]}')\n",
    "\n",
    "    db.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAttributes(data: pd.DataFrame, expectedCols: list):\n",
    "    for col in expectedCols:  # For each of the expected columns\n",
    "        if not col in data.keys():  # check if its in the dataframe\n",
    "            print(f\"[ERROR] ergot sample file is missing the expected attribute: {col}\")\n",
    "            sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTable(db: DataService, queryHandler: ErgotQueryBuilder):\n",
    "    # Checks if the table needed to run the pipeline has been created, if not creates it\n",
    "\n",
    "    # Create the command needed to check if the table exists\n",
    "    query = sq.text(queryHandler.tableExistsReq(TABLENAME))\n",
    "    tableExists = queryHandler.readTableExists(db.execute(query))  # type: ignore\n",
    "\n",
    "    if not tableExists:\n",
    "        # Create the command needed to create the table\n",
    "        query = sq.text(queryHandler.createErgotSampleTableReq())\n",
    "        db.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropExtraAttributes(data: pd.DataFrame, requiredCol: list):\n",
    "    attributesToDrop = []  # Stores the extra attributes we wish to drop\n",
    "\n",
    "    for attr in data.keys():  # For each attribute in the dataframe\n",
    "        if attr not in requiredCol:  # Check if its one of the attributes we want\n",
    "            attributesToDrop.append(attr)\n",
    "\n",
    "    for attr in attributesToDrop:  # Drop all unnecessary attributes\n",
    "        data.drop(attr, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
