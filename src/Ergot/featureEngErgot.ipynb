{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# featureEngErgot.ipynb\n",
    "\n",
    "Feature Engineering for ergot and agg_ergot by creating additional columns and processing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "import geopandas as gpd  # type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os, sys, calendar\n",
    "from aggregateErgot import calcUIDs  # type: ignore\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService\n",
    "from Shared.GenericQueryBuilder import GenericQueryBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Psuedocode:  \n",
    "- Load the environment database variables\n",
    "- Create the ergot data SQL query\n",
    "- Create the agg_ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")\n",
    "\n",
    "if (\n",
    "    PG_DB is None\n",
    "    or PG_ADDR is None\n",
    "    or PG_PORT is None\n",
    "    or PG_USER is None\n",
    "    or PG_PW is None\n",
    "):\n",
    "    raise ValueError(\"Environment variables not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullIndividualErgotSampleData(conn: sq.engine.Connection) -> pd.DataFrame:\n",
    "    # pulling weather station data from the database\n",
    "    weatherDataQuery = sq.text(\n",
    "        \"\"\"\n",
    "        SELECT * FROM public.ergot_sample\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return pd.read_sql(weatherDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAggErgotData(conn: sq.engine.Connection) -> pd.DataFrame:\n",
    "    # pulling weather station data from the database\n",
    "    weatherDataQuery = sq.text(\n",
    "        \"\"\"\n",
    "        SELECT * FROM public.agg_ergot_sample_v2\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return pd.read_sql(weatherDataQuery, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- Create a table containg relevant attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createErgotFeatEngTableV1(db, tablename: str):\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE {tablename} (\n",
    "            year                        INT,\n",
    "            province                    VARCHAR(2),\n",
    "            crop_district               INT,\n",
    "            incidence                   BOOL,\n",
    "            severity                    FLOAT,\n",
    "            district                    INT,\n",
    "            downgrade                   BOOL,\n",
    "            severity_bin_quan           INT,\n",
    "            severity_bin_arb            INT,\n",
    "\n",
    "            CONSTRAINT PK_{tablename} PRIMARY KEY(year, district)\n",
    "        );\n",
    "        COMMIT;\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    db.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "- The purpose of this function is to add a new column called \"downgrade\" to the input DataFrame, indicating whether each district is considered a \"downgrade\" district based on its severity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDowngradeColumn(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    DOWNGRADE_THRESHOLD = 0.04\n",
    "    df[\"downgrade\"] = False\n",
    "    df.loc[df[\"severity\"] >= DOWNGRADE_THRESHOLD, \"downgrade\"] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "- The purpose of this function is to add a new column named \"severity_bin_quan\" to the input DataFrame, which represents the quantile bin numbers of severity levels for each district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSeverityBinQuan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # quantiles only on severities > 0\n",
    "    df[\"severity_bin_quan\"] = 0\n",
    "    df.loc[df[\"severity\"] > 0, \"severity_bin_quan\"] = pd.qcut(\n",
    "        df.loc[df[\"severity\"] > 0][\"severity\"], 4, labels=False\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "- The purpose of this function is to add a new column named \"severity_bin_arb\" to the input DataFrame df, which represents the bin numbers of severity levels for each district based on arbitrary threshold values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSeverityBinArbitrary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"severity_bin_arb\"] = 0\n",
    "    df.loc[df[\"severity\"] >= 0.02, \"severity_bin_arb\"] = 1\n",
    "    df.loc[df[\"severity\"] >= 0.04, \"severity_bin_arb\"] = 2\n",
    "    df.loc[df[\"severity\"] >= 0.08, \"severity_bin_arb\"] = 3\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "- The purpose of the code snippet is to process ergot sample data, calculate additional columns (\"downgrade,\" \"severity_bin_quan,\" \"severity_bin_arb\"), and store the processed data in a database table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    TABLENAME = \"ergot_sample_feat_eng\"\n",
    "\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "    conn = db.connect()\n",
    "\n",
    "    ergotDf = pullIndividualErgotSampleData(conn)\n",
    "    ergotDf = calcUIDs(ergotDf)\n",
    "    ergotDf = calculateDowngradeColumn(ergotDf)\n",
    "    ergotDf = calculateSeverityBinQuan(ergotDf)\n",
    "    ergotDf = calculateSeverityBinArbitrary(ergotDf)\n",
    "\n",
    "    try:\n",
    "        queryBuilder = GenericQueryBuilder()\n",
    "        request = sq.text(queryBuilder.tableExistsReq(TABLENAME))\n",
    "        tableExists = queryBuilder.readTableExists(db.execute(request))\n",
    "\n",
    "        if not tableExists:\n",
    "            createErgotFeatEngTableV1(db)\n",
    "\n",
    "        ergotDf.to_sql(\n",
    "            TABLENAME, conn, schema=\"public\", if_exists=\"replace\", index=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while writing to the database {}\".format(e))\n",
    "        raise e\n",
    "\n",
    "    db.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
