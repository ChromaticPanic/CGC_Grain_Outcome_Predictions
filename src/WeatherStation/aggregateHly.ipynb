{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\geopandas\\_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danew\\AppData\\Local\\Temp\\ipykernel_28608\\1050338221.py:2: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sq\n",
    "import geopandas as gpd  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os, sys, calendar\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MONTH = 1\n",
    "MAX_MONTH = 12\n",
    "\n",
    "MIN_YEAR = 1995\n",
    "MAX_YEAR = 2022\n",
    "TABLENAME = \"agg_hly_weather\"\n",
    "final_df = None\n",
    "\n",
    "load_dotenv()\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullWeatherData(conn: sq.engine.Connection) -> pd.DataFrame:\n",
    "    # pulling weather station data from the database\n",
    "    weatherDataQuery = sq.text(\n",
    "        \"\"\"\n",
    "        SELECT * FROM public.ab_hly_station_data\n",
    "        UNION\n",
    "        SELECT * FROM public.mb_hly_station_data\n",
    "        UNION\n",
    "        SELECT * FROM public.sk_hly_station_data;\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return pd.read_sql(weatherDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullStationData(conn: sq.engine.Connection) -> pd.DataFrame:\n",
    "    # pulling station data from the database\n",
    "    stationDataQuery = sq.text(\n",
    "        \"\"\"\n",
    "        SELECT station_id, district FROM public.stations_dly\n",
    "        WHERE district IS NOT NULL;\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    stationData = pd.read_sql(stationDataQuery, conn)\n",
    "    stationData[[\"district\"]] = stationData[[\"district\"]].astype(int)\n",
    "\n",
    "    return stationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateHlyData(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # aggregate the values in the dataframe by date and district\n",
    "    agg_df = (\n",
    "        df.groupby([\"district\", \"year\", \"month\", \"day\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"min_temp\": \"mean\",\n",
    "                \"max_temp\": \"mean\",\n",
    "                \"mean_temp\": \"mean\",\n",
    "                \"min_dew_point_temp\": \"mean\",\n",
    "                \"max_dew_point_temp\": \"mean\",\n",
    "                \"mean_dew_point_temp\": \"mean\",\n",
    "                \"min_humidex\": \"mean\",\n",
    "                \"max_humidex\": \"mean\",\n",
    "                \"mean_humidex\": \"mean\",\n",
    "                \"total_precip\": [\"min\", \"max\", \"mean\"],\n",
    "                \"min_rel_humid\": \"mean\",\n",
    "                \"max_rel_humid\": \"mean\",\n",
    "                \"mean_rel_humid\": \"mean\",\n",
    "                \"min_stn_press\": \"mean\",\n",
    "                \"max_stn_press\": \"mean\",\n",
    "                \"mean_stn_press\": \"mean\",\n",
    "                \"min_visibility\": \"mean\",\n",
    "                \"max_visibility\": \"mean\",\n",
    "                \"mean_visibility\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # sets the column names for the aggregate dataframe\n",
    "    agg_df.columns = [  # type: ignore\n",
    "        \"district\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"min_temp\",\n",
    "        \"max_temp\",\n",
    "        \"mean_temp\",\n",
    "        \"min_dew_point_temp\",\n",
    "        \"max_dew_point_temp\",\n",
    "        \"mean_dew_point_temp\",\n",
    "        \"min_humidex\",\n",
    "        \"max_humidex\",\n",
    "        \"mean_humidex\",\n",
    "        \"min_precip\",\n",
    "        \"max_precip\",\n",
    "        \"mean_precip\",\n",
    "        \"min_rel_humid\",\n",
    "        \"max_rel_humid\",\n",
    "        \"mean_rel_humid\",\n",
    "        \"min_stn_press\",\n",
    "        \"max_stn_press\",\n",
    "        \"mean_stn_press\",\n",
    "        \"min_visibility\",\n",
    "        \"max_visibility\",\n",
    "        \"mean_visibility\",\n",
    "    ]\n",
    "\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDates() -> list:\n",
    "    # figure out the date range for date processing - puts all 365 days as MO-DA into dates\n",
    "    dates = []  # all 365 days as MO-DA - strings\n",
    "\n",
    "    # the month range we want to pull data from - strings\n",
    "    months = [str(month) for month in range(MIN_MONTH, MAX_MONTH + 1)]\n",
    "    for month in months:\n",
    "        if len(month) == 1:\n",
    "            month = \"0\" + month\n",
    "\n",
    "        numDays = calendar.monthrange(2001, int(month))[1]\n",
    "        days = [str(day) for day in range(1, numDays + 1)]\n",
    "\n",
    "        for day in days:\n",
    "            if len(day) == 1:\n",
    "                day = \"0\" + day\n",
    "\n",
    "            dates.append(f\"{month}-{day}\")\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeHlyData(\n",
    "    dates: list, agg_df: pd.DataFrame, stationData: pd.DataFrame\n",
    ") -> list:\n",
    "    # loads all data where each row is its own dictionary so that it may added to a dataframe later (fast processing)\n",
    "    listForDF = []\n",
    "\n",
    "    # the year range we want to pull data from - ints\n",
    "    years = [year for year in range(MIN_YEAR, MAX_YEAR + 1)]\n",
    "    uniqueDistricts = stationData[\"district\"].unique()\n",
    "\n",
    "    # get the columns we will want to pull information from\n",
    "    cols = agg_df.columns.tolist()  # type: ignore\n",
    "    cols.remove(\"district\")\n",
    "    cols.remove(\"year\")\n",
    "    cols.remove(\"month\")\n",
    "    cols.remove(\"day\")\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"Processing year: {year}\")\n",
    "\n",
    "        for district in uniqueDistricts:\n",
    "            currData = {}  # for each year/district combination create a dictionary\n",
    "\n",
    "            # adds the year and district\n",
    "            currData[\"year\"] = year\n",
    "            currData[\"district\"] = district\n",
    "\n",
    "            # for each day we want to grab all attributes and establish them as columns i.e MO-DA:attribute\n",
    "            for date in dates:\n",
    "                dateComponents = date.split(\"-\")\n",
    "                monthInt = int(dateComponents[0])\n",
    "                dayInt = int(dateComponents[1])\n",
    "\n",
    "                # grab the row from the aggregated df\n",
    "                currRow = agg_df.loc[\n",
    "                    (agg_df[\"year\"] == year)\n",
    "                    & (agg_df[\"month\"] == monthInt)\n",
    "                    & (agg_df[\"day\"] == dayInt)\n",
    "                    & (agg_df[\"district\"] == district)\n",
    "                ]\n",
    "\n",
    "                for col in cols:  # parse each of the desired columns\n",
    "                    currAttr = f\"{date}:{col}\"  # the current attribute which corresponds to the date and the column\n",
    "                    currVal = 0  # defaults as zero incase it does not exist\n",
    "\n",
    "                    if len(currRow[col]) == 1:\n",
    "                        # the current value from the loaded data\n",
    "                        currVal = currRow[col].item()\n",
    "\n",
    "                    currData[currAttr] = currVal\n",
    "\n",
    "            listForDF.append(currData)\n",
    "\n",
    "    return listForDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if (\n",
    "        PG_DB is None\n",
    "        or PG_ADDR is None\n",
    "        or PG_PORT is None\n",
    "        or PG_USER is None\n",
    "        or PG_PW is None\n",
    "    ):\n",
    "        raise ValueError(\"Environment variables not set\")\n",
    "\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "    conn = db.connect()\n",
    "\n",
    "    weatherData = pullWeatherData(conn)\n",
    "    stationData = pullStationData(conn)\n",
    "\n",
    "    # merge both the weather station data and the station data together\n",
    "    df = weatherData.merge(stationData, on=\"station_id\")\n",
    "\n",
    "    agg_df = aggregateHlyData(df)\n",
    "    dates = getDates()\n",
    "    listForDF = reshapeHlyData(dates, agg_df, stationData)\n",
    "    final_df = pd.DataFrame(listForDF)\n",
    "\n",
    "    # final_df.to_sql(TABLENAME, conn, schema=\"public\", if_exists=\"append\", index=False)\n",
    "    db.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedTable) relation \"public.ab_hly_station_data\" does not exist\nLINE 2:         SELECT * FROM public.ab_hly_station_data\n                              ^\n\n[SQL: \n        SELECT * FROM public.ab_hly_station_data\n        UNION\n        SELECT * FROM public.mb_hly_station_data\n        UNION\n        SELECT * FROM public.sk_hly_station_data;\n        ]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1968\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1968\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1969\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1970\u001b[0m         )\n\u001b[0;32m   1972\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\default.py:920\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 920\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mUndefinedTable\u001b[0m: relation \"public.ab_hly_station_data\" does not exist\nLINE 2:         SELECT * FROM public.ab_hly_station_data\n                              ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m db \u001b[39m=\u001b[39m DataService(PG_DB, PG_ADDR, \u001b[39mint\u001b[39m(PG_PORT), PG_USER, PG_PW)\n\u001b[0;32m     12\u001b[0m conn \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mconnect()\n\u001b[1;32m---> 14\u001b[0m weatherData \u001b[39m=\u001b[39m pullWeatherData(conn)\n\u001b[0;32m     15\u001b[0m stationData \u001b[39m=\u001b[39m pullStationData(conn)\n\u001b[0;32m     17\u001b[0m \u001b[39m# merge both the weather station data and the station data together\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mpullWeatherData\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpullWeatherData\u001b[39m(conn: sq\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mConnection) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m      2\u001b[0m     \u001b[39m# pulling weather station data from the database\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     weatherDataQuery \u001b[39m=\u001b[39m sq\u001b[39m.\u001b[39mtext(\n\u001b[0;32m      4\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m        SELECT * FROM public.ab_hly_station_data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     )\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_sql(weatherDataQuery, conn)\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\pandas\\io\\sql.py:663\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    654\u001b[0m         sql,\n\u001b[0;32m    655\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    660\u001b[0m         dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    661\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[0;32m    664\u001b[0m         sql,\n\u001b[0;32m    665\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    666\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    667\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[0;32m    668\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    669\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    670\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    671\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    672\u001b[0m     )\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\pandas\\io\\sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[0;32m   1682\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1683\u001b[0m     sql: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1691\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1692\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[39m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1694\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1736\u001b[0m \n\u001b[0;32m   1737\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1738\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[0;32m   1739\u001b[0m     columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m   1741\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\pandas\\io\\sql.py:1563\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sql, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1562\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon\u001b[39m.\u001b[39mexec_driver_sql(sql, \u001b[39m*\u001b[39margs)\n\u001b[1;32m-> 1563\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon\u001b[39m.\u001b[39;49mexecute(sql, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1413\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1413\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[0;32m   1414\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1415\u001b[0m         distilled_parameters,\n\u001b[0;32m   1416\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[0;32m   1417\u001b[0m     )\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:483\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    482\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[1;32m--> 483\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[0;32m    484\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[0;32m    485\u001b[0m     )\n\u001b[0;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1637\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1625\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1626\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[0;32m   1627\u001b[0m )\n\u001b[0;32m   1629\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1630\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[0;32m   1631\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1635\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1636\u001b[0m )\n\u001b[1;32m-> 1637\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1638\u001b[0m     dialect,\n\u001b[0;32m   1639\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[0;32m   1640\u001b[0m     compiled_sql,\n\u001b[0;32m   1641\u001b[0m     distilled_parameters,\n\u001b[0;32m   1642\u001b[0m     execution_options,\n\u001b[0;32m   1643\u001b[0m     compiled_sql,\n\u001b[0;32m   1644\u001b[0m     distilled_parameters,\n\u001b[0;32m   1645\u001b[0m     elem,\n\u001b[0;32m   1646\u001b[0m     extracted_params,\n\u001b[0;32m   1647\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[0;32m   1648\u001b[0m )\n\u001b[0;32m   1649\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[0;32m   1650\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[0;32m   1651\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1652\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1656\u001b[0m         ret,\n\u001b[0;32m   1657\u001b[0m     )\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1842\u001b[0m         dialect,\n\u001b[0;32m   1843\u001b[0m         context,\n\u001b[0;32m   1844\u001b[0m     )\n\u001b[0;32m   1845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[0;32m   1847\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1848\u001b[0m     )\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1987\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1986\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1987\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1988\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1989\u001b[0m     )\n\u001b[0;32m   1991\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2344\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2343\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2344\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   2345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2346\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1968\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1968\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1969\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1970\u001b[0m         )\n\u001b[0;32m   1972\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1973\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1974\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1975\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1979\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1980\u001b[0m     )\n",
      "File \u001b[1;32me:\\Programming\\CGC_Grain_Outcome_Predictions\\env\\lib\\site-packages\\sqlalchemy\\engine\\default.py:920\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 920\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (psycopg2.errors.UndefinedTable) relation \"public.ab_hly_station_data\" does not exist\nLINE 2:         SELECT * FROM public.ab_hly_station_data\n                              ^\n\n[SQL: \n        SELECT * FROM public.ab_hly_station_data\n        UNION\n        SELECT * FROM public.mb_hly_station_data\n        UNION\n        SELECT * FROM public.sk_hly_station_data;\n        ]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_df.to_csv(path_or_buf='data/aggregatedDly.csv', sep=',', columns=final_df.columns.tolist())\n",
    "except Exception as e:\n",
    "    print('[ERROR]')\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
