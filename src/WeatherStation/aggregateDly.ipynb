{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sq\n",
    "import geopandas as gpd  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os, sys, calendar\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MONTH = 1\n",
    "MAX_MONTH = 12\n",
    "\n",
    "MIN_YEAR = 1995\n",
    "MAX_YEAR = 2022\n",
    "TABLENAME = \"agg_dly_weather\"\n",
    "\n",
    "load_dotenv()\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    PG_DB is None\n",
    "    or PG_ADDR is None\n",
    "    or PG_PORT is None\n",
    "    or PG_USER is None\n",
    "    or PG_PW is None\n",
    "):\n",
    "    raise ValueError(\"Environment variables not set\")\n",
    "\n",
    "db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling weather station data from the database\n",
    "weatherDataQuery = sq.text(\n",
    "    \"\"\"\n",
    "    SELECT * FROM public.ab_station_data\n",
    "    UNION\n",
    "    SELECT * FROM public.mb_station_data\n",
    "    UNION\n",
    "    SELECT * FROM public.sk_station_data;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "weatherData = pd.read_sql(weatherDataQuery, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling station data from the database\n",
    "stationDataQuery = sq.text(\n",
    "    \"\"\"\n",
    "    SELECT station_id, district FROM public.stations_dly\n",
    "    WHERE district IS NOT NULL;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "stationData = pd.read_sql(stationDataQuery, conn)\n",
    "stationData[[\"district\"]] = stationData[[\"district\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both the weather station data and the station data together\n",
    "df = weatherData.merge(stationData, on=\"station_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the values in the dataframe by date and district\n",
    "agg_df = (\n",
    "    df.groupby([\"district\", \"date\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"max_temp\": \"mean\",\n",
    "            \"min_temp\": \"mean\",\n",
    "            \"mean_temp\": \"mean\",\n",
    "            \"total_rain\": [\"min\", \"max\", \"mean\"],\n",
    "            \"total_snow\": [\"min\", \"max\", \"mean\"],\n",
    "            \"total_precip\": [\"min\", \"max\", \"mean\"],\n",
    "            \"snow_on_grnd\": [\"min\", \"max\", \"mean\"],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# sets the column names for the aggregate dataframe\n",
    "agg_df.columns = [  # type: ignore\n",
    "    \"district\",\n",
    "    \"date\",\n",
    "    \"max_temp\",\n",
    "    \"min_temp\",\n",
    "    \"mean_temp\",\n",
    "    \"min_total_rain\",\n",
    "    \"max_total_rain\",\n",
    "    \"mean_total_rain\",\n",
    "    \"min_total_snow\",\n",
    "    \"max_total_snow\",\n",
    "    \"mean_total_snow\",\n",
    "    \"min_total_precip\",\n",
    "    \"max_total_precip\",\n",
    "    \"mean_total_precip\",\n",
    "    \"min_snow_on_grnd\",\n",
    "    \"max_snow_on_grnd\",\n",
    "    \"mean_snow_on_grnd\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the date range for date processing - puts all 365 days as MO-DA into dates\n",
    "dates = []  # all 365 days as MO-DA - strings\n",
    "\n",
    "months = [\n",
    "    str(month) for month in range(MIN_MONTH, MAX_MONTH + 1)\n",
    "]  # the month range we want to pull data from - strings\n",
    "for month in months:\n",
    "    if len(month) == 1:\n",
    "        month = \"0\" + month\n",
    "\n",
    "    numDays = calendar.monthrange(2001, int(month))[1]\n",
    "    days = [str(day) for day in range(1, numDays + 1)]\n",
    "\n",
    "    for day in days:\n",
    "        if len(day) == 1:\n",
    "            day = \"0\" + day\n",
    "\n",
    "        dates.append(f\"{month}-{day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\n",
    "    year for year in range(MIN_YEAR, MAX_YEAR + 1)\n",
    "]  # the year range we want to pull data from - ints\n",
    "uniqueDistricts = stationData[\"district\"].unique()\n",
    "\n",
    "cols = agg_df.columns.tolist()  # type: ignore\n",
    "cols.remove(\"district\")\n",
    "cols.remove(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listForDF = (\n",
    "    []\n",
    ")  # loads all data where each row is its own dictionary so that it may added to a dataframe later (fast processing)\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Processing year: {year}\")\n",
    "\n",
    "    for district in uniqueDistricts:\n",
    "        currData = {}  # for each year/district combination create a dictionary\n",
    "\n",
    "        # adds the year and district\n",
    "        currData[\"year\"] = year\n",
    "        currData[\"district\"] = district\n",
    "\n",
    "        for (\n",
    "            date\n",
    "        ) in (\n",
    "            dates\n",
    "        ):  # for each day we want to grab all attributes and establish them as columns i.e MO-DA:attribute\n",
    "            fullDate = np.datetime64(\n",
    "                f\"{str(year)}-{date}\"\n",
    "            )  # calculates the date we are current processing\n",
    "            currRow = agg_df.loc[\n",
    "                (agg_df[\"date\"] == fullDate) & (agg_df[\"district\"] == district)\n",
    "            ]  # grab the row from the aggregated df\n",
    "\n",
    "            for col in cols:  # parse each of the desired columns\n",
    "                currAttr = f\"{date}:{col}\"  # the current attribute which corresponds to the date and the column\n",
    "                currVal = 0  # defaults as zero incase it does not exist\n",
    "\n",
    "                if len(currRow[col]) == 1:\n",
    "                    currVal = currRow[\n",
    "                        col\n",
    "                    ].item()  # the current value from the loaded data\n",
    "\n",
    "                currData[currAttr] = currVal\n",
    "\n",
    "        listForDF.append(currData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(listForDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_sql(TABLENAME, conn, schema=\"public\", if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
