{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import relevant modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import sqlalchemy as sq\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "from ClimateDataRequester import ClimateDataRequester as cdr\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from DataService import DataService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/data\")\n",
    "load_dotenv(\"docker/.env\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_data(df: pd.DataFrame) -> None:\n",
    "    dataService = DataService(PG_DB, PG_ADDR, PG_PORT, PG_USER, PG_PW)\n",
    "    db_con = dataService.connect()\n",
    "    df.to_sql(\"WeatherData\", db_con, if_exists=\"append\", index=False)\n",
    "    dataService.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcessA(df: pd.DataFrame, stationID: str) -> None:\n",
    "    dataService = DataService(PG_DB, PG_ADDR, PG_PORT, PG_USER, PG_PW)\n",
    "    db_con = dataService.connect()\n",
    "    try:\n",
    "        df.drop(\n",
    "            columns=[\n",
    "                \"Data Quality\",\n",
    "                \"Max Temp Flag\",\n",
    "                \"Mean Temp Flag\",\n",
    "                \"Min Temp Flag\",\n",
    "                \"Heat Deg Days Flag\",\n",
    "                \"Cool Deg Days Flag\",\n",
    "                \"Spd of Max Gust (km/h)\",\n",
    "                \"Total Rain Flag\",\n",
    "                \"Total Snow Flag\",\n",
    "                \"Total Precip Flag\",\n",
    "                \"Snow on Grnd Flag\",\n",
    "                \"Dir of Max Gust Flag\",\n",
    "                \"Spd of Max Gust Flag\",\n",
    "                \"Heat Deg Days (°C)\",\n",
    "                \"Cool Deg Days (°C)\",\n",
    "                \"Longitude (x)\",\n",
    "                \"Latitude (y)\",\n",
    "                \"Station Name\",\n",
    "                \"Dir of Max Gust (10s deg)\",\n",
    "            ],\n",
    "            inplace=True,\n",
    "        )\n",
    "    except:\n",
    "        df.to_csv(\n",
    "            \"data/failed/\" + str(df.iloc[0, 0]) + \"_unexpected_column_names.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    # Climate ID\tDate/Time\tYear\tMonth\tDay\tMax Temp (Â°C)\tMin Temp (Â°C)\tMean Temp (Â°C)\tTotal Rain (mm)\tTotal Snow (cm)\tTotal Precip (mm)\tSnow on Grnd (cm)\tDir of Max Gust (10s deg)\tSpd of Max Gust (km/h)\n",
    "    # ClimateID Date Year Month Day MaxTemp MinTemp MeanTemp TotalRain TotalSnow TotalPrecip SnowOnGrnd DirOfMaxGust SpdOfMaxGust\n",
    "    df.rename(columns={df.columns[0]: \"ClimateID\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[1]: \"Date\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[2]: \"Year\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[3]: \"Month\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[4]: \"Day\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[5]: \"MaxTemp\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[6]: \"MinTemp\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[7]: \"MeanTemp\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[8]: \"TotalRain\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[9]: \"TotalSnow\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[10]: \"TotalPrecip\"}, inplace=True)\n",
    "    df.rename(columns={df.columns[11]: \"SnowOnGrnd\"}, inplace=True)\n",
    "\n",
    "    df.dropna(subset=[\"MeanTemp\"], inplace=True)\n",
    "    df.loc[df[\"SnowOnGrnd\"].isnull(), \"SnowOnGrnd\"] = 0\n",
    "    df.loc[df[\"TotalRain\"].isnull(), \"TotalRain\"] = 0\n",
    "    df.loc[df[\"TotalSnow\"].isnull(), \"TotalSnow\"] = 0\n",
    "    df.loc[df[\"TotalPrecip\"].isnull(), \"TotalPrecip\"] = 0\n",
    "    df[\"MaxTemp\"] = np.where(df[\"MaxTemp\"].isnull(), df[\"MeanTemp\"], df[\"MaxTemp\"])\n",
    "    df[\"MinTemp\"] = np.where(df[\"MinTemp\"].isnull(), df[\"MeanTemp\"], df[\"MinTemp\"])\n",
    "\n",
    "    df[[\"ClimateID\", \"Date\"]] = df[[\"ClimateID\", \"Date\"]].astype(str)\n",
    "    df[[\"Year\", \"Month\", \"Day\"]] = df[[\"Year\", \"Month\", \"Day\"]].astype(int)\n",
    "    df[\n",
    "        [\n",
    "            \"MaxTemp\",\n",
    "            \"MinTemp\",\n",
    "            \"MeanTemp\",\n",
    "            \"TotalRain\",\n",
    "            \"TotalSnow\",\n",
    "            \"TotalPrecip\",\n",
    "            \"SnowOnGrnd\",\n",
    "        ]\n",
    "    ] = df[\n",
    "        [\n",
    "            \"MaxTemp\",\n",
    "            \"MinTemp\",\n",
    "            \"MeanTemp\",\n",
    "            \"TotalRain\",\n",
    "            \"TotalSnow\",\n",
    "            \"TotalPrecip\",\n",
    "            \"SnowOnGrnd\",\n",
    "        ]\n",
    "    ].astype(\n",
    "        float\n",
    "    )\n",
    "\n",
    "    # we try a db push, but if it fails, we place the data in a csv file\n",
    "    # try:\n",
    "    push_data(df)\n",
    "    query = sq.text(\n",
    "        'UPDATE public.\"StationsDly\" SET \"scraped\" = True WHERE \"Climate ID\" like CAST(\\'{}\\' AS TEXT);'.format(\n",
    "            stationID\n",
    "        )\n",
    "    )\n",
    "    db_con.execute(query)\n",
    "    # except:\n",
    "    #     df.to_csv(\"Failed/\" + str(df.iloc[0, 0]) +\n",
    "    #             \"_data_failed_dbpush.csv\", index=False)\n",
    "    dataService.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableName = 'public.\"StationsDly\"'\n",
    "query = \"SELECT * FROM \" + tableName + \";\"\n",
    "\n",
    "\n",
    "dataService = DataService(PG_DB, PG_ADDR, PG_PORT, PG_USER, PG_PW)\n",
    "db_con = dataService.connect()\n",
    "dfStations = gpd.GeoDataFrame.from_postgis(query, db_con, geom_col=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of MANITOBA stations\n",
    "mbStations = dfStations.loc[dfStations[\"Province\"] == \"MANITOBA\"]\n",
    "\n",
    "# remove stations with NaN DLY First Year\n",
    "mbStations = mbStations.loc[mbStations[\"DLY First Year\"].notnull()]\n",
    "\n",
    "# reindex\n",
    "mbStations.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try first 2 stations\n",
    "# mbStations = mbStations.iloc[0:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbStations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requester = cdr()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for index, row in mbStations.iterrows():\n",
    "    stationID = str(row[\"Climate ID\"])\n",
    "    errQuery = sq.text(\n",
    "        'UPDATE public.\"StationsDly\" SET \"scraped\" = False WHERE \"Climate ID\" like CAST(\\'{}\\' AS TEXT);'.format(\n",
    "            stationID\n",
    "        )\n",
    "    )\n",
    "    if row[\"scraped\"] == False or row[\"scraped\"] == None:\n",
    "        try:\n",
    "            startYr = 1995\n",
    "            endYr = 2022\n",
    "            if (\n",
    "                row[\"DLY First Year\"] != np.NAN\n",
    "                or row[\"DLY Last Year\"] != np.NAN\n",
    "                or row[\"DLY Last Year\"] > 1995\n",
    "            ):\n",
    "                if row[\"DLY First Year\"] > 1995:\n",
    "                    startYr = row[\"DLY First Year\"]\n",
    "                if row[\"DLY Last Year\"] > 1995:\n",
    "                    endYr = row[\"DLY Last Year\"]\n",
    "                df = requester.get_data(\"MB\", stationID, startYr, endYr)\n",
    "                clear_output(wait=False)\n",
    "\n",
    "                print(df.head())\n",
    "\n",
    "                if not df.empty:\n",
    "                    dataProcessA(df, stationID)\n",
    "                else:\n",
    "                    db_con.execute(errQuery)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to scrape \" + stationID)\n",
    "            print(e)\n",
    "            db_con.execute(errQuery)\n",
    "    else:\n",
    "        print(\"Data for station \" + str(stationID) + \" already exists.\")\n",
    "\n",
    "    print(\"Processed row \" + str(index + 1) + \" of \" + str(len(mbStations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataService.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
