{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DatasetJS.ipynb\n",
    "\n",
    "After all the data has been loaded and aggregated, this notebook creates the final datasets\n",
    "\n",
    "Required tables:\n",
    "- [COMBINED_WEATHER_TABLE](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_weather_combined)\n",
    "- [COPERNICUS_WEATHER_TABLE](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_day_copernicus_satellite_data)\n",
    "- [SOIL_MOISTURE_TABLE](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_soil_moisture)\n",
    "- [AGG_ERGOT_TABLE](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_ergot_sample_v2)\n",
    "- [ERGOT_SAMPLES_TABLE](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#ergot_sample_feat_eng)\n",
    "\n",
    "Output:\n",
    "- [dataset_daily_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_daily_sat)\n",
    "- [dataset_weekly_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_weekly_sat)\n",
    "- [dataset_monthly_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_monthly_sat)\n",
    "- [dataset_cross_monthly_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_monthly_sat)\n",
    "- [dataset_cross_weekly_sat_JFMA](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_sat_JFMA)\n",
    "- [dataset_cross_weekly_sat_MAMJ](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_sat_MAMJ)\n",
    "- [dataset_cross_weekly_sat_MJJA](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_sat_MJJA)\n",
    "- [dataset_cross_weekly_sat_JASO](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_sat_JASO)\n",
    "- [dataset_daily_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_daily_station)\n",
    "- [dataset_weekly_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_weekly_station)\n",
    "- [dataset_monthly_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_monthly_station)\n",
    "- [dataset_cross_monthly_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_monthly_station)\n",
    "- [dataset_cross_weekly_station_JFMA](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_station_JFMA)\n",
    "- [dataset_cross_weekly_station_MAMJ](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_station_MAMJ)\n",
    "- [dataset_cross_weekly_station_MJJA](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_station_MJJA)\n",
    "- [dataset_cross_weekly_station_JASO](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_cross_weekly_station_JASO)\n",
    "- [dataset_daily_sat_soil](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_daily_sat_soil)\n",
    "- [dataset_weekly_sat_soil](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_weekly_sat_soil)\n",
    "- [dataset_monthly_sat_soil](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_monthly_sat_soil)\n",
    "- [dataset_daily_station_soil](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_daily_station_soil)\n",
    "- [dataset_weekly_station_soil](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_weekly_station_soil)\n",
    "- [dataset_monthly_station_soil](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_monthly_station_soil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from dotenv import load_dotenv\n",
    "import geopandas as gpd  # type: ignore\n",
    "import sqlalchemy as sq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, calendar\n",
    "\n",
    "import typing\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables being used (see links in Required tables above)\n",
    "COMBINED_WEATHER_TABLE = \"agg_weather_combined\"\n",
    "COPERNICUS_WEATHER_TABLE = \"agg_day_copernicus_satellite_data\"\n",
    "SOIL_MOISTURE_TABLE = \"agg_soil_moisture\"\n",
    "AGG_ERGOT_TABLE = \"agg_ergot_sample_v2\"\n",
    "ERGOT_SAMPLES_TABLE = \"ergot_sample_feat_eng\"\n",
    "\n",
    "# Tables being created (see links in output above)\n",
    "TABLESATSOILMDAILY = \"dataset_daily_sat_soil\"\n",
    "TABLESATSOILMWEEKLY = \"dataset_weekly_sat_soil\"\n",
    "TABLESATSOILMMONTHLY = \"dataset_monthly_sat_soil\"\n",
    "TABLESTATIONSOILMDAILY = \"dataset_daily_station_soil\"\n",
    "TABLESTATIONSOILMWEEKLY = \"dataset_weekly_station_soil\"\n",
    "TABLESTATIONSOILMMONTHLY = \"dataset_monthly_station_soil\"\n",
    "TABLESATDAILY = \"dataset_daily_sat\"\n",
    "TABLESATWEEKLY = \"dataset_weekly_sat\"\n",
    "TABLESATMONTHLY = \"dataset_monthly_sat\"\n",
    "TABLESTATIONDAILY = \"dataset_daily_station\"\n",
    "TABLESTATIONWEEKLY = \"dataset_weekly_station\"\n",
    "TABLESTATIONMONTHLY = \"dataset_monthly_station\"\n",
    "\n",
    "TABLECROSSSATWEEKLYA = \"dataset_cross_weekly_sat_JFMA\"\n",
    "TABLECROSSSATWEEKLYB = \"dataset_cross_weekly_sat_MAMJ\"\n",
    "TABLECROSSSATWEEKLYC = \"dataset_cross_weekly_sat_MJJA\"\n",
    "TABLECROSSSATWEEKLYD = \"dataset_cross_weekly_sat_JASO\"\n",
    "TABLECROSSSTATIONWEEKLYA = \"dataset_cross_weekly_station_JFMA\"\n",
    "TABLECROSSSTATIONWEEKLYB = \"dataset_cross_weekly_station_MAMJ\"\n",
    "TABLECROSSSTATIONWEEKLYC = \"dataset_cross_weekly_station_MJJA\"\n",
    "TABLECROSSSTATIONWEEKLYD = \"dataset_cross_weekly_station_JASO\"\n",
    "\n",
    "TABLECROSSSATMONTHLY = \"dataset_cross_monthly_sat\"\n",
    "TABLECROSSSTATIONMONTHLY = \"dataset_cross_monthly_station\"\n",
    "\n",
    "\n",
    "# Load the database connection environment variables located in the docker folder\n",
    "load_dotenv(\"../docker/.env\")\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    generateNoErgotTables()\n",
    "    generateCrossWeeklyTables()\n",
    "    generateCrossMonthlyTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Get a connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConn():\n",
    "    if (\n",
    "        PG_DB is None\n",
    "        or PG_ADDR is None\n",
    "        or PG_PORT is None\n",
    "        or PG_USER is None\n",
    "        or PG_PW is None\n",
    "    ):\n",
    "        raise Exception(\"Missing required env var(s)\")\n",
    "\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "\n",
    "    return db.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the weather station data from the combined weather station data table\n",
    "\n",
    "Tables:\n",
    "- [agg_weather_combined](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_weather_combined)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the weather station data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullWeatherStationData() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    weatherDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{COMBINED_WEATHER_TABLE}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(weatherDataQuery, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the Copernicus data from the Copernicus weather data table\n",
    "\n",
    "Tables:\n",
    "- [agg_day_copernicus_satellite_data](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_day_copernicus_satellite_data)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the Copernicus weather data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullWeatherCopernicusData() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    weatherDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{COPERNICUS_WEATHER_TABLE}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(weatherDataQuery, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the soil moisture data from the Satellite soil moisture data table\n",
    "\n",
    "Tables:\n",
    "- [agg_soil_moisture](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_soil_moisture)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the soil moisture data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullSoilMoistureData() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    weatherDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT year, month, day, district, \n",
    "        soil_moisture_min, soil_moisture_max, soil_moisture_mean\n",
    "        FROM public.{SOIL_MOISTURE_TABLE}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(weatherDataQuery, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the ergot data from the aggregated ergot data table\n",
    "\n",
    "Tables:\n",
    "- [agg_ergot_sample_v2](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_ergot_sample_v2)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullAggErgotData() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    weatherDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT year, district, \n",
    "            present_prev1, \n",
    "            present_prev2, \n",
    "            present_prev3, \n",
    "            sum_severity_prev1, \n",
    "            sum_severity_prev2, \n",
    "            sum_severity_prev3, \n",
    "            percnt_true_prev1,\n",
    "            percnt_true_prev2,\n",
    "            percnt_true_prev3,\n",
    "            median_prev1,\n",
    "            median_prev2,\n",
    "            median_prev3\n",
    "        FROM public.{AGG_ERGOT_TABLE}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(weatherDataQuery, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the ergot data from the individual ergot sample data table\n",
    "\n",
    "Tables:\n",
    "- [ergot_sample_feat_eng](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#ergot_sample_feat_eng)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullIndividualErgotSampleData() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    weatherDataQuery = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{ERGOT_SAMPLES_TABLE}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(weatherDataQuery, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the ergot data from the ergot sample data tables and join them together\n",
    "\n",
    "Tables:\n",
    "- [agg_ergot_sample_v2](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_ergot_sample_v2)\n",
    "- [ergot_sample_feat_eng](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#ergot_sample_feat_eng)\n",
    "\n",
    "Psuedocode:\n",
    "- Get the ergot data\n",
    "- [Merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) the two DataFrames together on year and district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addErgotData(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    aggErgotDf = pullAggErgotData()\n",
    "    ergotDf = pullIndividualErgotSampleData()\n",
    "\n",
    "    # right join on year, district\n",
    "    mergedDf = pd.merge(df, aggErgotDf, on=[\"year\", \"district\"], how=\"right\")\n",
    "    mergedDf = pd.merge(mergedDf, ergotDf, on=[\"year\", \"district\"], how=\"left\")\n",
    "\n",
    "    return mergedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the Copernicus data from the Copernicus weather data table and preproccesses it\n",
    "\n",
    "Tables:\n",
    "- [agg_day_copernicus_satellite_data](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_day_copernicus_satellite_data)\n",
    "\n",
    "Psuedocode:\n",
    "- Load the Copernicus data\n",
    "- Convert the year, month and day to a date\n",
    "- Get the day of the year\n",
    "- Drop the date column we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDailySat() -> pd.DataFrame:\n",
    "    df = pullWeatherCopernicusData()\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    df.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the Weather station data from the weather station data table and preproccesses it\n",
    "\n",
    "Tables:\n",
    "- [agg_weather_combined](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_weather_combined)\n",
    "\n",
    "Psuedocode:\n",
    "- Load the data\n",
    "- Convert the year, month and day to a date\n",
    "- Get the day of the year\n",
    "- Drop the date column we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDailyStation() -> pd.DataFrame:\n",
    "    df = pullWeatherStationData()\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    df.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the soil moisture data from the satellite soil moisture data table and preproccesses it\n",
    "\n",
    "Tables:\n",
    "- [agg_soil_moisture](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#agg_soil_moisture)\n",
    "\n",
    "Psuedocode:\n",
    "- Load the data\n",
    "- Convert the year, month and day to a date\n",
    "- Get the day of the year\n",
    "- Drop the date column we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDailySoil() -> pd.DataFrame:\n",
    "    df = pullSoilMoistureData()\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "    df.drop(columns=[\"date\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Aggregate the Copernicus weather data by week\n",
    "\n",
    "Pseudocode:  \n",
    "- Add the week to the data\n",
    "- [Aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) the data [by year, month, week of year and district](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeeklySat(dailyDf: pd.DataFrame) -> pd.DataFrame:\n",
    "    dailyDf[\"date\"] = pd.to_datetime(dailyDf[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "    # add a week of year column\n",
    "    dailyDf[\"week_of_year\"] = dailyDf[\"date\"].dt.isocalendar().week\n",
    "    dailyDf = dailyDf.drop(columns=[\"date\"])\n",
    "\n",
    "    # aggregate by week of year year and district\n",
    "    weeklyDf = (\n",
    "        dailyDf.groupby([\"year\", \"month\", \"week_of_year\", \"district\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"min_dewpoint_temperature\": \"min\",\n",
    "                \"min_temperature\": \"min\",\n",
    "                \"min_evaporation_from_bare_soil\": \"min\",\n",
    "                \"min_skin_reservoir_content\": \"min\",\n",
    "                \"min_skin_temperature\": \"min\",\n",
    "                \"min_snowmelt\": \"min\",\n",
    "                \"min_soil_temperature_level_1\": \"min\",\n",
    "                \"min_soil_temperature_level_2\": \"min\",\n",
    "                \"min_soil_temperature_level_3\": \"min\",\n",
    "                \"min_soil_temperature_level_4\": \"min\",\n",
    "                \"min_surface_net_solar_radiation\": \"min\",\n",
    "                \"min_surface_pressure\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_1\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_2\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_3\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_4\": \"min\",\n",
    "                \"min_leaf_area_index_high_vegetation\": \"min\",\n",
    "                \"min_leaf_area_index_low_vegetation\": \"min\",\n",
    "                \"max_dewpoint_temperature\": \"max\",\n",
    "                \"max_temperature\": \"max\",\n",
    "                \"max_evaporation_from_bare_soil\": \"max\",\n",
    "                \"max_skin_reservoir_content\": \"max\",\n",
    "                \"max_skin_temperature\": \"max\",\n",
    "                \"max_snowmelt\": \"max\",\n",
    "                \"max_soil_temperature_level_1\": \"max\",\n",
    "                \"max_soil_temperature_level_2\": \"max\",\n",
    "                \"max_soil_temperature_level_3\": \"max\",\n",
    "                \"max_soil_temperature_level_4\": \"max\",\n",
    "                \"max_surface_net_solar_radiation\": \"max\",\n",
    "                \"max_surface_pressure\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_1\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_2\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_3\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_4\": \"max\",\n",
    "                \"max_leaf_area_index_high_vegetation\": \"max\",\n",
    "                \"max_leaf_area_index_low_vegetation\": \"max\",\n",
    "                \"mean_dewpoint_temperature\": \"mean\",\n",
    "                \"mean_temperature\": \"mean\",\n",
    "                \"mean_evaporation_from_bare_soil\": \"mean\",\n",
    "                \"mean_skin_reservoir_content\": \"mean\",\n",
    "                \"mean_skin_temperature\": \"mean\",\n",
    "                \"mean_snowmelt\": \"mean\",\n",
    "                \"mean_soil_temperature_level_1\": \"mean\",\n",
    "                \"mean_soil_temperature_level_2\": \"mean\",\n",
    "                \"mean_soil_temperature_level_3\": \"mean\",\n",
    "                \"mean_soil_temperature_level_4\": \"mean\",\n",
    "                \"mean_surface_net_solar_radiation\": \"mean\",\n",
    "                \"mean_surface_pressure\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_1\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_2\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_3\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_4\": \"mean\",\n",
    "                \"mean_leaf_area_index_high_vegetation\": \"mean\",\n",
    "                \"mean_leaf_area_index_low_vegetation\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return weeklyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Aggregate the Satellite soil moisture data by week\n",
    "\n",
    "Pseudocode:  \n",
    "- Add the week to the data\n",
    "- [Aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) the data [by year, month, week of year and district](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeeklySoilMoisture(dailyDf: pd.DataFrame) -> pd.DataFrame:\n",
    "    dailyDf[\"date\"] = pd.to_datetime(dailyDf[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "    # add a week of year column\n",
    "    dailyDf[\"week_of_year\"] = dailyDf[\"date\"].dt.isocalendar().week\n",
    "    dailyDf = dailyDf.drop(columns=[\"date\"])\n",
    "\n",
    "    # aggregate by week of year year and district\n",
    "    weeklyDf = (\n",
    "        dailyDf.groupby([\"year\", \"month\", \"week_of_year\", \"district\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"soil_moisture_min\": \"min\",\n",
    "                \"soil_moisture_max\": \"max\",\n",
    "                \"soil_moisture_mean\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return weeklyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Aggregate the Copernicus weather data by month\n",
    "\n",
    "Pseudocode:  \n",
    "- [Aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) the data [by year, month and district](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonthlySat(dailyDf: pd.DataFrame) -> pd.DataFrame:\n",
    "    monthlyDf = (\n",
    "        dailyDf.groupby([\"year\", \"month\", \"district\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"min_dewpoint_temperature\": \"min\",\n",
    "                \"min_temperature\": \"min\",\n",
    "                \"min_evaporation_from_bare_soil\": \"min\",\n",
    "                \"min_skin_reservoir_content\": \"min\",\n",
    "                \"min_skin_temperature\": \"min\",\n",
    "                \"min_snowmelt\": \"min\",\n",
    "                \"min_soil_temperature_level_1\": \"min\",\n",
    "                \"min_soil_temperature_level_2\": \"min\",\n",
    "                \"min_soil_temperature_level_3\": \"min\",\n",
    "                \"min_soil_temperature_level_4\": \"min\",\n",
    "                \"min_surface_net_solar_radiation\": \"min\",\n",
    "                \"min_surface_pressure\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_1\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_2\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_3\": \"min\",\n",
    "                \"min_volumetric_soil_water_layer_4\": \"min\",\n",
    "                \"min_leaf_area_index_high_vegetation\": \"min\",\n",
    "                \"min_leaf_area_index_low_vegetation\": \"min\",\n",
    "                \"max_dewpoint_temperature\": \"max\",\n",
    "                \"max_temperature\": \"max\",\n",
    "                \"max_evaporation_from_bare_soil\": \"max\",\n",
    "                \"max_skin_reservoir_content\": \"max\",\n",
    "                \"max_skin_temperature\": \"max\",\n",
    "                \"max_snowmelt\": \"max\",\n",
    "                \"max_soil_temperature_level_1\": \"max\",\n",
    "                \"max_soil_temperature_level_2\": \"max\",\n",
    "                \"max_soil_temperature_level_3\": \"max\",\n",
    "                \"max_soil_temperature_level_4\": \"max\",\n",
    "                \"max_surface_net_solar_radiation\": \"max\",\n",
    "                \"max_surface_pressure\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_1\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_2\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_3\": \"max\",\n",
    "                \"max_volumetric_soil_water_layer_4\": \"max\",\n",
    "                \"max_leaf_area_index_high_vegetation\": \"max\",\n",
    "                \"max_leaf_area_index_low_vegetation\": \"max\",\n",
    "                \"mean_dewpoint_temperature\": \"mean\",\n",
    "                \"mean_temperature\": \"mean\",\n",
    "                \"mean_evaporation_from_bare_soil\": \"mean\",\n",
    "                \"mean_skin_reservoir_content\": \"mean\",\n",
    "                \"mean_skin_temperature\": \"mean\",\n",
    "                \"mean_snowmelt\": \"mean\",\n",
    "                \"mean_soil_temperature_level_1\": \"mean\",\n",
    "                \"mean_soil_temperature_level_2\": \"mean\",\n",
    "                \"mean_soil_temperature_level_3\": \"mean\",\n",
    "                \"mean_soil_temperature_level_4\": \"mean\",\n",
    "                \"mean_surface_net_solar_radiation\": \"mean\",\n",
    "                \"mean_surface_pressure\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_1\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_2\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_3\": \"mean\",\n",
    "                \"mean_volumetric_soil_water_layer_4\": \"mean\",\n",
    "                \"mean_leaf_area_index_high_vegetation\": \"mean\",\n",
    "                \"mean_leaf_area_index_low_vegetation\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return monthlyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Aggregate the soil mositure data by month\n",
    "\n",
    "Pseudocode:  \n",
    "- [Aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) the data [by year, month and district](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonthlySoilMoisture(dailyDf: pd.DataFrame) -> pd.DataFrame:\n",
    "    monthlyDf = (\n",
    "        dailyDf.groupby([\"year\", \"month\", \"district\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"soil_moisture_min\": \"min\",\n",
    "                \"soil_moisture_max\": \"max\",\n",
    "                \"soil_moisture_mean\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return monthlyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Aggregate the weather station data by week\n",
    "\n",
    "Pseudocode:  \n",
    "- Add the week to the data\n",
    "- [Aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) the data [by year, month, week of year and district](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeeklyStation(dailyDf: pd.DataFrame) -> pd.DataFrame:\n",
    "    dailyDf[\"date\"] = pd.to_datetime(dailyDf[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "    # add a week of year column\n",
    "    dailyDf[\"week_of_year\"] = dailyDf[\"date\"].dt.isocalendar().week\n",
    "    dailyDf = dailyDf.drop(columns=[\"date\"])\n",
    "\n",
    "    # aggregate by week of year year and district\n",
    "    weeklyDf = (\n",
    "        dailyDf.groupby([\"year\", \"month\", \"week_of_year\", \"district\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"min_temp_x\": \"min\",\n",
    "                \"max_temp_x\": \"max\",\n",
    "                \"mean_temp_x\": \"mean\",\n",
    "                \"min_dew_point_temp\": \"min\",\n",
    "                \"max_dew_point_temp\": \"max\",\n",
    "                \"mean_dew_point_temp\": \"mean\",\n",
    "                \"min_humidex\": \"min\",\n",
    "                \"max_humidex\": \"max\",\n",
    "                \"mean_humidex\": \"mean\",\n",
    "                \"min_precip\": \"min\",\n",
    "                \"max_precip\": \"max\",\n",
    "                \"mean_precip\": \"mean\",\n",
    "                \"min_rel_humid\": \"min\",\n",
    "                \"max_rel_humid\": \"max\",\n",
    "                \"mean_rel_humid\": \"mean\",\n",
    "                \"min_stn_press\": \"min\",\n",
    "                \"max_stn_press\": \"max\",\n",
    "                \"mean_stn_press\": \"mean\",\n",
    "                \"min_visibility\": \"min\",\n",
    "                \"max_visibility\": \"max\",\n",
    "                \"mean_visibility\": \"mean\",\n",
    "                \"max_temp_y\": \"max\",\n",
    "                \"min_temp_y\": \"min\",\n",
    "                \"mean_temp_y\": \"mean\",\n",
    "                \"min_total_rain\": \"min\",\n",
    "                \"max_total_rain\": \"max\",\n",
    "                \"mean_total_rain\": \"mean\",\n",
    "                \"min_total_snow\": \"min\",\n",
    "                \"max_total_snow\": \"max\",\n",
    "                \"mean_total_snow\": \"mean\",\n",
    "                \"min_total_precip\": \"min\",\n",
    "                \"max_total_precip\": \"max\",\n",
    "                \"mean_total_precip\": \"mean\",\n",
    "                \"min_snow_on_grnd\": \"min\",\n",
    "                \"max_snow_on_grnd\": \"max\",\n",
    "                \"mean_snow_on_grnd\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return weeklyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Aggregate the weather station data by month\n",
    "\n",
    "Pseudocode:  \n",
    "- [Aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) the data [by year, month and district](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonthlyStation(dailyDf: pd.DataFrame) -> pd.DataFrame:\n",
    "    monthlyDf = (\n",
    "        dailyDf.groupby([\"year\", \"month\", \"district\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"min_temp_x\": \"min\",\n",
    "                \"max_temp_x\": \"max\",\n",
    "                \"mean_temp_x\": \"mean\",\n",
    "                \"min_dew_point_temp\": \"min\",\n",
    "                \"max_dew_point_temp\": \"max\",\n",
    "                \"mean_dew_point_temp\": \"mean\",\n",
    "                \"min_humidex\": \"min\",\n",
    "                \"max_humidex\": \"max\",\n",
    "                \"mean_humidex\": \"mean\",\n",
    "                \"min_precip\": \"min\",\n",
    "                \"max_precip\": \"max\",\n",
    "                \"mean_precip\": \"mean\",\n",
    "                \"min_rel_humid\": \"min\",\n",
    "                \"max_rel_humid\": \"max\",\n",
    "                \"mean_rel_humid\": \"mean\",\n",
    "                \"min_stn_press\": \"min\",\n",
    "                \"max_stn_press\": \"max\",\n",
    "                \"mean_stn_press\": \"mean\",\n",
    "                \"min_visibility\": \"min\",\n",
    "                \"max_visibility\": \"max\",\n",
    "                \"mean_visibility\": \"mean\",\n",
    "                \"max_temp_y\": \"max\",\n",
    "                \"min_temp_y\": \"min\",\n",
    "                \"mean_temp_y\": \"mean\",\n",
    "                \"min_total_rain\": \"min\",\n",
    "                \"max_total_rain\": \"max\",\n",
    "                \"mean_total_rain\": \"mean\",\n",
    "                \"min_total_snow\": \"min\",\n",
    "                \"max_total_snow\": \"max\",\n",
    "                \"mean_total_snow\": \"mean\",\n",
    "                \"min_total_precip\": \"min\",\n",
    "                \"max_total_precip\": \"max\",\n",
    "                \"mean_total_precip\": \"mean\",\n",
    "                \"min_snow_on_grnd\": \"min\",\n",
    "                \"max_snow_on_grnd\": \"max\",\n",
    "                \"mean_snow_on_grnd\": \"mean\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return monthlyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Stores data in the database in chunks\n",
    "\n",
    "Pseudocode:  \n",
    "- Get a database connection\n",
    "- [Push the data to the database](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html)\n",
    "- Close the connection\n",
    "\n",
    "Remarks: Some of our large data has too many columns to fit into the database, thus, we store the data in chunks accross multiple tables instead to bypass this restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushChunkwise(df: pd.DataFrame, tablename: str) -> None:\n",
    "    conn = getConn()\n",
    "\n",
    "    df.to_sql(\n",
    "        tablename,\n",
    "        conn,\n",
    "        schema=\"public\",\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        chunksize=1000,\n",
    "    )\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Stores chunks of the tables with too many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNoErgotTables():\n",
    "    pushChunkwise(pullWeatherCopernicusData(), TABLESATDAILY)\n",
    "\n",
    "    pushChunkwise(pullWeatherStationData(), TABLESTATIONDAILY)\n",
    "\n",
    "    pushChunkwise(getWeeklySat(pullWeatherCopernicusData()), TABLESATWEEKLY)\n",
    "\n",
    "    pushChunkwise(getWeeklyStation(pullWeatherStationData()), TABLESTATIONWEEKLY)\n",
    "\n",
    "    pushChunkwise(getMonthlySat(pullWeatherCopernicusData()), TABLESATMONTHLY)\n",
    "\n",
    "    pushChunkwise(getMonthlyStation(pullWeatherStationData()), TABLESTATIONMONTHLY)\n",
    "\n",
    "    mergeDf = pd.merge(\n",
    "        getDailySat(),\n",
    "        getDailySoil(),\n",
    "        on=[\"year\", \"day_of_year\", \"district\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    pushChunkwise(mergeDf, TABLESATSOILMDAILY)\n",
    "\n",
    "    mergeDf = pd.merge(\n",
    "        getDailyStation(),\n",
    "        getDailySoil(),\n",
    "        on=[\"year\", \"day_of_year\", \"district\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    pushChunkwise(mergeDf, TABLESTATIONSOILMDAILY)\n",
    "\n",
    "    weeklySat = getWeeklySat(getDailySat())\n",
    "    weeklySoil = getWeeklySoilMoisture(getDailySoil())\n",
    "    mergeDf = pd.merge(\n",
    "        weeklySat, weeklySoil, on=[\"year\", \"week_of_year\", \"district\"], how=\"left\"\n",
    "    )\n",
    "    pushChunkwise(mergeDf, TABLESATSOILMWEEKLY)\n",
    "\n",
    "    weeklyStation = getWeeklyStation(getDailyStation())\n",
    "    weeklySoil = getWeeklySoilMoisture(getDailySoil())\n",
    "    mergeDf = pd.merge(\n",
    "        weeklyStation, weeklySoil, on=[\"year\", \"week_of_year\", \"district\"], how=\"left\"\n",
    "    )\n",
    "    pushChunkwise(mergeDf, TABLESTATIONSOILMWEEKLY)\n",
    "\n",
    "    monthlySat = getMonthlySat(getDailySat())\n",
    "    monthlySoil = getMonthlySoilMoisture(getDailySoil())\n",
    "    mergeDf = pd.merge(\n",
    "        monthlySat, monthlySoil, on=[\"year\", \"month\", \"district\"], how=\"left\"\n",
    "    )\n",
    "    pushChunkwise(mergeDf, TABLESATSOILMMONTHLY)\n",
    "\n",
    "    monthlyStation = getMonthlyStation(getDailyStation())\n",
    "    monthlySoil = getMonthlySoilMoisture(getDailySoil())\n",
    "    mergeDf = pd.merge(\n",
    "        monthlyStation, monthlySoil, on=[\"year\", \"month\", \"district\"], how=\"left\"\n",
    "    )\n",
    "    pushChunkwise(mergeDf, TABLESTATIONSOILMMONTHLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the daily Copernicus satellite data from the daily Copernicus satellite data table\n",
    "\n",
    "Tables:\n",
    "- [dataset_daily_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_daily_sat)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetDailySat() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{TABLESATDAILY}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the daily weather station data from the daily weather station data table\n",
    "\n",
    "Tables:\n",
    "- [dataset_daily_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_daily_station)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetDailyStation() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{TABLESTATIONDAILY}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the weekly Copernicus data from the weekly Copernicus satellite weather data table\n",
    "\n",
    "Tables:\n",
    "- [dataset_weekly_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_weekly_sat)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetWeeklySat() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{TABLESATWEEKLY}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the weekly weather station data from the weekly weather station data table\n",
    "\n",
    "Tables:\n",
    "- [dataset_weekly_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_weekly_station)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetWeeklyStation() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{TABLESTATIONWEEKLY}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the monthly Copernicus data from the monthly Copernicus satellite weather data table\n",
    "\n",
    "Tables:\n",
    "- [dataset_monthly_sat](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_monthly_sat)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetMonthlySat() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{TABLESATMONTHLY}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Loads the monthly weather station data from the monthly weather station data table\n",
    "\n",
    "Tables:\n",
    "- [dataset_monthly_station](https://github.com/ChromaticPanic/CGC_Grain_Outcome_Predictions#dataset_monthly_station)\n",
    "\n",
    "Psuedocode:\n",
    "- Get a connection to the database\n",
    "- Create the ergot data SQL query\n",
    "- [Load the data from the database directly into a DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\n",
    "- Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetMonthlyStation() -> pd.DataFrame:\n",
    "    conn = getConn()\n",
    "    query = sq.text(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM public.{TABLESTATIONMONTHLY}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "We create a table where each row is a district and each column is a week of the year crossed with a weather attribute the columns are labeled as such: attribute_week_of_year the weekRange is a list of ints that represent the weeks of the year we want to include in the table\n",
    "\n",
    "Pseudocode:  \n",
    "- Drop columns that do not fit into the week range\n",
    "- Get the names of all the columns\n",
    "- Remove the irrelevant columns (these are the columns we wont want to appear once our data has been reshaped)\n",
    "- Get the unique years and districts in remaining data\n",
    "- Grab all attributes and establish them as key in a dictionary\n",
    "- Once finished for the current date, district combination, store the dictionary into a list\n",
    "\n",
    "Remark: for this function to work correctly the following columns must be present: year, district and week\n",
    "\n",
    "<br>\n",
    "\n",
    "Also note that we use a list of dictionaries since it is much faster to do so as opposed to the number of DataFrame manipulations we'd require otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossWeekOfYear(\n",
    "    df: pd.DataFrame, weekRange: typing.List[int], exclude: typing.List[str]\n",
    ") -> pd.DataFrame:\n",
    "    # keep only rows that are in the weekRange\n",
    "    df = df.loc[df[\"week_of_year\"].isin(weekRange)]\n",
    "\n",
    "    # get the columns we will want to pull information from\n",
    "    cols = df.columns.tolist()  # type: ignore\n",
    "    for col in exclude:\n",
    "        cols.remove(col)\n",
    "\n",
    "    years = df[\"year\"].unique().tolist()  # type: ignore\n",
    "    districts = df[\"district\"].unique().tolist()  # type: ignore\n",
    "\n",
    "    listForDF = []  # list of dictionaries that will be used to create the dataframe\n",
    "    for year in years:\n",
    "        for district in districts:\n",
    "            currData = {}  # for each year/district combination create a dictionary\n",
    "\n",
    "            # adds the year and district\n",
    "            currData[\"year\"] = year\n",
    "            currData[\"district\"] = district\n",
    "\n",
    "            # for each day we want to grab all attributes and establish them as columns i.e MO-DA:attribute\n",
    "            for week in weekRange:\n",
    "                # grab the row from the aggregated df\n",
    "                currRow = df.loc[\n",
    "                    (df[\"year\"] == year)\n",
    "                    & (df[\"week_of_year\"] == week)\n",
    "                    & (df[\"district\"] == district)\n",
    "                ]\n",
    "\n",
    "                for col in cols:  # parse each of the desired columns\n",
    "                    currAttr = f\"{week}:{col}\"  # the current attribute which corresponds to the date and the column\n",
    "                    currVal = 0  # defaults as zero incase it does not exist\n",
    "\n",
    "                    if len(currRow[col]) == 1:\n",
    "                        # the current value from the loaded data\n",
    "                        currVal = currRow[col].item()\n",
    "\n",
    "                    currData[currAttr] = currVal\n",
    "\n",
    "            listForDF.append(currData)\n",
    "\n",
    "    return pd.DataFrame(listForDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "We create a table where each row is a district and each column is a month of the year crossed with a weather attribute the columns are labeled as such: attribute_month_of_year the monthRange is a list of ints that represent the months of the year we want to include in the table\n",
    "\n",
    "Pseudocode:  \n",
    "- Drop columns that do not fit into the month range\n",
    "- Get the names of all the columns\n",
    "- Remove the irrelevant columns (these are the columns we wont want to appear once our data has been reshaped)\n",
    "- Get the unique years and districts in remaining data\n",
    "- Grab all attributes and establish them as key in a dictionary\n",
    "- Once finished for the current date, district combination, store the dictionary into a list\n",
    "\n",
    "Remark: for this function to work correctly the following columns must be present: year, district and month\n",
    "\n",
    "<br>\n",
    "\n",
    "Also note that we use a list of dictionaries since it is much faster to do so as opposed to the number of DataFrame manipulations we'd require otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossMonthOfYear(\n",
    "    df: pd.DataFrame, monthRange: typing.List[int], exclude: typing.List[str]\n",
    ") -> pd.DataFrame:\n",
    "    # keep only rows that are in the monthRange\n",
    "    df = df.loc[df[\"month\"].isin(monthRange)]\n",
    "\n",
    "    # get the columns we will want to pull information from\n",
    "    cols = df.columns.tolist()  # type: ignore\n",
    "    for col in exclude:\n",
    "        cols.remove(col)\n",
    "\n",
    "    years = df[\"year\"].unique().tolist()  # type: ignore\n",
    "    districts = df[\"district\"].unique().tolist()  # type: ignore\n",
    "\n",
    "    listForDF = []  # list of dictionaries that will be used to create the dataframe\n",
    "    for year in years:\n",
    "        for district in districts:\n",
    "            currData = {}\n",
    "            currData[\"year\"] = year\n",
    "            currData[\"district\"] = district\n",
    "\n",
    "            for month in monthRange:\n",
    "                currRow = df.loc[\n",
    "                    (df[\"year\"] == year)\n",
    "                    & (df[\"month\"] == month)\n",
    "                    & (df[\"district\"] == district)\n",
    "                ]\n",
    "\n",
    "                for col in cols:\n",
    "                    currAttr = f\"{month}:{col}\"\n",
    "                    currVal = 0\n",
    "\n",
    "                    if len(currRow[col]) == 1:\n",
    "                        currVal = currRow[col].item()\n",
    "\n",
    "                    currData[currAttr] = currVal\n",
    "\n",
    "            listForDF.append(currData)\n",
    "\n",
    "    return pd.DataFrame(listForDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Crosses weekly data against the year to help determine the importance of each parameter of each week is to the model which is then stored in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCrossWeeklyTables():\n",
    "    # weekly jan feb mar apr\n",
    "    weeks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklySat(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSATWEEKLYA)\n",
    "\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklyStation(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSTATIONWEEKLYA)\n",
    "\n",
    "    # weekly mar apr may jun\n",
    "    weeks = [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklySat(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSATWEEKLYB)\n",
    "\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklyStation(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSTATIONWEEKLYB)\n",
    "\n",
    "    # weekly may jun jul aug\n",
    "    weeks = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklySat(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSATWEEKLYC)\n",
    "\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklyStation(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSTATIONWEEKLYC)\n",
    "\n",
    "    # weekly jul aug sep oct\n",
    "    weeks = [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklySat(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSATWEEKLYD)\n",
    "\n",
    "    crossedDf = crossWeekOfYear(\n",
    "        getDatasetWeeklyStation(), weeks, [\"year\", \"district\", \"month\", \"week_of_year\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSTATIONWEEKLYD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Crosses monthly data against the year to help determine the importance of each parameter of each month is to the model which is then stored in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCrossMonthlyTables():\n",
    "    # monthly\n",
    "    months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    crossedDf = crossMonthOfYear(\n",
    "        getDatasetMonthlySat(), months, [\"year\", \"district\", \"month\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSATMONTHLY)\n",
    "\n",
    "    crossedDf = crossMonthOfYear(\n",
    "        getDatasetMonthlyStation(), months, [\"year\", \"district\", \"month\"]\n",
    "    )\n",
    "    pushChunkwise(crossedDf, TABLECROSSSTATIONMONTHLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
