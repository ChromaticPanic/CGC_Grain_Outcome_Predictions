{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifiers.ipynb\n",
    "\n",
    "- It experiments with machine learning models ([Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html)) on different datasets.\n",
    "- The goal is to evaluate the performance of these models with and without certain features (ergot-related predictors) to predict specific targets (\"ergot_present_in_q3\", \"ergot_present_in_q4\", \"sum_severity_in_q3\", \"sum_severity_in_q4\") in the datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # type: ignore\n",
    "from sklearn.svm import SVC, LinearSVC  # type: ignore\n",
    "from evaluator import ModelEvaluator\n",
    "import sys, warnings\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from datasets.setCreator import SetCreator  # type: ignore\n",
    "from datasets.setModifier import SetModifier  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "\n",
    "- it defines lists of hyperparameters for the Random Forest Classifier and Support Vector Machine, filters out unnecessary warning messages, and prepares the datasets using a custom data set creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = [100, 200, 500]\n",
    "MAX_DEPTH = [5, 7, 10, 15]\n",
    "\n",
    "C = [0.01, 0.25, 0.5, 0.75, 1]\n",
    "GAMMA = [0.1, 0.5, 2, 5, 10]\n",
    "DEGREE = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "setModifier = SetModifier()\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "setCreator = SetCreator()\n",
    "dataset1 = setCreator.getSetList1()\n",
    "dataset2 = setCreator.getSetList2()\n",
    "dataset3 = setCreator.getSetList3()\n",
    "dataset4 = setCreator.getSetList4()\n",
    "dataset5 = setCreator.getSetList5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "- The purpose of this function is to test and evaluate the performance of a Random Forest Classifier on multiple datasets with a specified predictor variable, considering different combinations of hyperparameters (N_ESTIMATORS and MAX_DEPTH). \n",
    "- It aims to find the best model (in terms of the Area Under the ROC Curve - AUC) among the tested combinations.\n",
    "\n",
    "Psuedocode:\n",
    "\n",
    "- Loops through different datasets. \n",
    "- Test Random Forest Classifier model with different hyperparameters.\n",
    "- Checks for the highest auc score.\n",
    "\n",
    "Note :\n",
    "- The difference between the two functions lies in how they handle the datasets: one function removes ergot-related predictors before training, while the other keeps them.\n",
    "- A bunch of decision trees chosen at random and then merged together based on scoring.\n",
    "- Prone to overfittin, hyperparameters are a must\n",
    "- One of the most powerful algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithErgotFeatures(predictor: str, datasets: list):\n",
    "    print(\"Running the Random Forest Classifier:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"auc\": 0}\n",
    "\n",
    "    numCombinations = len(datasets)\n",
    "\n",
    "    for currData in datasets:\n",
    "        trainningData = pd.DataFrame(currData[\"train\"])\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = pd.DataFrame(currData[\"test\"])\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for estimator in N_ESTIMATORS:\n",
    "            for depth in MAX_DEPTH:\n",
    "                try:\n",
    "                    rfc = RandomForestClassifier(\n",
    "                        random_state=5, n_estimators=estimator, max_depth=depth\n",
    "                    )\n",
    "                    rfc.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateClassification(\n",
    "                        rfc, currData[\"desc\"], trainX, trainY, testX, testY\n",
    "                    )\n",
    "\n",
    "                    if results[\"auc\"] > bestModel[\"auc\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"n_estimators\"] = estimator\n",
    "                        bestModel[\"max_depth\"] = depth\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the Random Forest Classifier\"\n",
    "    )\n",
    "    print(f\"The best model, as per roc, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithoutErgotFeatures(predictor: str, datasets: list):\n",
    "    print(\"Running the Random Forest Classifier:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"auc\": 0}\n",
    "\n",
    "    numCombinations = len(datasets)\n",
    "\n",
    "    for currData in datasets:\n",
    "        trainningData = pd.DataFrame(currData[\"train\"])\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotFeatures(trainningData)\n",
    "\n",
    "        testData = pd.DataFrame(currData[\"test\"])\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotFeatures(testData)\n",
    "\n",
    "        for estimator in N_ESTIMATORS:\n",
    "            for depth in MAX_DEPTH:\n",
    "                try:\n",
    "                    rfc = RandomForestClassifier(\n",
    "                        random_state=5, n_estimators=estimator, max_depth=depth\n",
    "                    )\n",
    "                    rfc.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateClassification(\n",
    "                        rfc, currData[\"desc\"], trainX, trainY, testX, testY\n",
    "                    )\n",
    "\n",
    "                    if results[\"auc\"] > bestModel[\"auc\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"n_estimators\"] = estimator\n",
    "                        bestModel[\"max_depth\"] = depth\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the Random Forest Classifier\"\n",
    "    )\n",
    "    print(f\"The best model, as per roc, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWithErgotFeatures(\"ergot_present_in_q3\", dataset1)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q3\", dataset1)\n",
    "testWithErgotFeatures(\"ergot_present_in_q3\", dataset2)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q3\", dataset2)\n",
    "testWithErgotFeatures(\"ergot_present_in_q3\", dataset3)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q3\", dataset3)\n",
    "testWithErgotFeatures(\"ergot_present_in_q3\", dataset4)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q3\", dataset4)\n",
    "testWithErgotFeatures(\"ergot_present_in_q3\", dataset5)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q3\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWithErgotFeatures(\"ergot_present_in_q4\", dataset1)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q4\", dataset1)\n",
    "testWithErgotFeatures(\"ergot_present_in_q4\", dataset2)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q4\", dataset2)\n",
    "testWithErgotFeatures(\"ergot_present_in_q4\", dataset3)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q4\", dataset3)\n",
    "testWithErgotFeatures(\"ergot_present_in_q4\", dataset4)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q4\", dataset4)\n",
    "testWithErgotFeatures(\"ergot_present_in_q4\", dataset5)\n",
    "testWithoutErgotFeatures(\"ergot_present_in_q4\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWithErgotFeatures(\"sum_severity_in_q3\", dataset1)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q3\", dataset1)\n",
    "testWithErgotFeatures(\"sum_severity_in_q3\", dataset2)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q3\", dataset2)\n",
    "testWithErgotFeatures(\"sum_severity_in_q3\", dataset3)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q3\", dataset3)\n",
    "testWithErgotFeatures(\"sum_severity_in_q3\", dataset4)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q3\", dataset4)\n",
    "testWithErgotFeatures(\"sum_severity_in_q3\", dataset5)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q3\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWithErgotFeatures(\"sum_severity_in_q4\", dataset1)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q4\", dataset1)\n",
    "testWithErgotFeatures(\"sum_severity_in_q4\", dataset2)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q4\", dataset2)\n",
    "testWithErgotFeatures(\"sum_severity_in_q4\", dataset3)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q4\", dataset3)\n",
    "testWithErgotFeatures(\"sum_severity_in_q4\", dataset4)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q4\", dataset4)\n",
    "testWithErgotFeatures(\"sum_severity_in_q4\", dataset5)\n",
    "testWithoutErgotFeatures(\"sum_severity_in_q4\", dataset5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- The purpose of this code is to test and find the best configuration for a Linear Support Vector Machine (SVM) classifier with different values of the regularization parameter 'C' on various datasets.\n",
    "- It aims to find the best model (in terms of the Area Under the ROC Curve - AUC) among the tested combinations.\n",
    "\n",
    "Psuedocode : \n",
    "- Loops through different datasets. \n",
    "- Train Support Vector Machine model with different hyperparameters.\n",
    "- Checks for the highest auc score.\n",
    "\n",
    "Note :\n",
    "- SVM better for smaller datasets, vulnerable to noise - therefore using feature reduction first\n",
    "- works even worse if lots of zero values\n",
    "- Handles outliers great - soft margines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMLinearWithErgotFeatures(predictor: str, datasets: list):\n",
    "    print(\"Running linear SVM Classifier:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"auc\": 0.0}\n",
    "\n",
    "    numCombinations = len(datasets)\n",
    "\n",
    "    for currData in datasets:\n",
    "        trainningData = currData[\"train\"]\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for c in C:\n",
    "            try:\n",
    "                smv = LinearSVC(C=c, random_state=0)\n",
    "                smv.fit(trainX, trainY)\n",
    "                results = evaluator.evaluateClassification(\n",
    "                    smv,\n",
    "                    currData[\"desc\"],\n",
    "                    trainX,\n",
    "                    trainY,\n",
    "                    testX,\n",
    "                    testY,\n",
    "                    hasFeatImportance=False,\n",
    "                )\n",
    "\n",
    "                if results[\"auc\"] > bestModel[\"auc\"]:\n",
    "                    bestModel = results\n",
    "\n",
    "                    bestModel[\"c\"] = c\n",
    "\n",
    "            except Exception as e:\n",
    "                numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the linear SVM Classifier\"\n",
    "    )\n",
    "    print(f\"The best model, as per roc, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- The purpose of this code is to test and find the best configuration for a Support Vector Machine (SVM) classifier with a polynomial kernel on various datasets. It iterates through a list of datasets.\n",
    "- It aims to find the best model (in terms of the Area Under the ROC Curve - AUC) among the tested combinations.\n",
    "\n",
    "Psuedocode : \n",
    "- Loops through different datasets. \n",
    "- Trains the classifier using different values of the regularization parameter 'C' and the polynomial degree 'deg', evaluates the performance using the AUC (Area Under the Receiver Operating Characteristic Curve) metric.\n",
    "- Checks for the highest auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMPolyWithErgotFeatures(predictor: str, datasets: list):\n",
    "    print(\"Running poly kernal SVM Classifier:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"auc\": 0.0}\n",
    "\n",
    "    numCombinations = len(datasets)\n",
    "\n",
    "    for currData in datasets:\n",
    "        trainningData = currData[\"train\"]\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for c in C:\n",
    "            for deg in DEGREE:\n",
    "                try:\n",
    "                    smv = SVC(kernel=\"poly\", degree=deg, coef0=1, C=c, random_state=0)\n",
    "                    smv.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateClassification(\n",
    "                        smv,\n",
    "                        currData[\"desc\"],\n",
    "                        trainX,\n",
    "                        trainY,\n",
    "                        testX,\n",
    "                        testY,\n",
    "                        hasFeatImportance=False,\n",
    "                    )\n",
    "\n",
    "                    if results[\"auc\"] > bestModel[\"auc\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"c\"] = c\n",
    "                        bestModel[\"degree\"] = deg\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the poly kernal SVM Classifier\"\n",
    "    )\n",
    "    print(f\"The best model, as per roc, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- The purpose of this code is to test and find the best configuration for a Support Vector Machine (SVM) classifier with a radial basis function (RBF) kernel on various datasets.\n",
    "- It aims to find the best model (in terms of the Area Under the ROC Curve - AUC) among the tested combinations.\n",
    "\n",
    "Psuedocode : \n",
    "- Loops through different datasets. \n",
    "- Trains the classifier using different values of the regularization parameter 'C' and the kernel coefficient 'gamma', evaluates the performance using the AUC (Area Under the Receiver Operating Characteristic Curve) metric.\n",
    "- Checks for the highest auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMRBFWithErgotFeatures(predictor: str, datasets: list):\n",
    "    print(\"Running RBF SVM Classifier:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"auc\": 0.0}\n",
    "\n",
    "    numCombinations = len(datasets)\n",
    "\n",
    "    for currData in datasets:\n",
    "        trainningData = currData[\"train\"]\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for c in C:\n",
    "            for gam in GAMMA:\n",
    "                try:\n",
    "                    smv = SVC(kernel=\"rbf\", gamma=gam, C=c, random_state=0)\n",
    "                    smv.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateClassification(\n",
    "                        smv,\n",
    "                        currData[\"desc\"],\n",
    "                        trainX,\n",
    "                        trainY,\n",
    "                        testX,\n",
    "                        testY,\n",
    "                        hasFeatImportance=False,\n",
    "                    )\n",
    "\n",
    "                    if results[\"auc\"] > bestModel[\"auc\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"c\"] = c\n",
    "                        bestModel[\"gamma\"] = gam\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the RBF SVM Classifier\"\n",
    "    )\n",
    "    print(f\"The best model, as per roc, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q3\", dataset2)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q3\", dataset2)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q3\", dataset2)\n",
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q3\", dataset3)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q3\", dataset3)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q3\", dataset3)\n",
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q3\", dataset4)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q3\", dataset4)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q3\", dataset4)\n",
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q3\", dataset5)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q3\", dataset5)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q3\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q4\", dataset2)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q4\", dataset2)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q4\", dataset2)\n",
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q4\", dataset3)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q4\", dataset3)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q4\", dataset3)\n",
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q4\", dataset4)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q4\", dataset4)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q4\", dataset4)\n",
    "SVMLinearWithErgotFeatures(\"ergot_present_in_q4\", dataset5)\n",
    "SVMPolyWithErgotFeatures(\"ergot_present_in_q4\", dataset5)\n",
    "SVMRBFWithErgotFeatures(\"ergot_present_in_q4\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q3\", dataset2)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q3\", dataset2)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q3\", dataset2)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q3\", dataset3)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q3\", dataset3)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q3\", dataset3)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q3\", dataset4)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q3\", dataset4)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q3\", dataset4)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q3\", dataset5)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q3\", dataset5)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q3\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q4\", dataset2)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q4\", dataset2)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q4\", dataset2)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q4\", dataset3)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q4\", dataset3)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q4\", dataset3)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q4\", dataset4)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q4\", dataset4)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q4\", dataset4)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity_in_q4\", dataset5)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity_in_q4\", dataset5)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity_in_q4\", dataset5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
