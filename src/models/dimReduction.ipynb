{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from evaluator import ModelEvaluator\n",
    "import sys, warnings\n",
    "\n",
    "sys.path.append('../')\n",
    "from datasets.setCreator import SetCreator\n",
    "from datasets.setModifier import SetModifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "setCreator = SetCreator()\n",
    "dataset1 = setCreator.getSetList1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset1:\n",
    "    currData['train'] = currData['train'].fillna(0)\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(currData['train'])\n",
    "    \n",
    "    print(f'[SUCCESS] identified {len(pca.components_)} relevant components')\n",
    "    print(pca.components_)\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset1:\n",
    "    trainningData = currData[\"train\"]\n",
    "    trainY = trainningData[\"ergot_present_in_q4\"]\n",
    "    trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "    For n in [2, 3, 4, 5]:\n",
    "        poly[n] = PolynomialFeatures(n)\n",
    "        X_poly[n] = poly[n].fit_transform(trainX)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100,max_depth=5, n_jobs=4, random_state=2)\n",
    "        rfecv = RFECV(estimator=model, n_jobs=1) # apply feature elimination/cross-validation to model\n",
    "        best_feat = rfecv.fit(X_poly[2], trainY)\n",
    "        X_support = X_poly[2][:, best_feat.support_] # X_support now automatically holds the best subset\n",
    "\n",
    "        print(X_support.shape)  # tells you the best dimensions to use\n",
    "        print(X_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset1:\n",
    "    currData['train'] = currData['train'].fillna(0)\n",
    "    gaussian_rnd_proj = GaussianRandomProjection(random_state=42)\n",
    "    X_reduced = gaussian_rnd_proj.fit_transform(currData['train'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
