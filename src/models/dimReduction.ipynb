{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimReduction.ipynb\n",
    "- Implementing combination of data preprocessing and feature selection for different datasets using Random Forest Classifier and feature reduction techniques (PCA and Gaussian Random Projection). \n",
    "- It aims to identify relevant components for the datasets using PCA, reduce the dataset dimensions using Gaussian Random Projection, and perform feature selection using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm in conjunction with a Random Forest Classifier.\n",
    "\n",
    "Note :\n",
    "- Both PCA and Gaussian Random Projection output entirely new attributes and neither are garunteed to improve the mode\n",
    "- Feature Importance with RFECV can be used to get the names of the most relevant attributes (but can take awhile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection  # type: ignore\n",
    "from sklearn.preprocessing import PolynomialFeatures  # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier  # type: ignore\n",
    "from sklearn.feature_selection import RFECV  # type: ignore\n",
    "from sklearn.decomposition import PCA  # type: ignore\n",
    "from evaluator import ModelEvaluator\n",
    "import sys, warnings\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from datasets.setCreator import SetCreator\n",
    "from datasets.setModifier import SetModifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "Silences warnings for cleaner output and loads datasets and dataset modifiers for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "setModifier = SetModifier()\n",
    "setCreator = SetCreator()\n",
    "dataset1 = setCreator.getSetList1()\n",
    "dataset2 = setCreator.getSetList2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- performs Principal Component Analysis ([PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)) on each dataset.\n",
    "- The PCA is used to reduce the dimensionality of the dataset and identify relevant components that explain the most variance in the data.\n",
    "\n",
    "Psuedocode :\n",
    "- Loops over each dataset.\n",
    "- Creates PCA class.\n",
    "- Train model with current dataset\n",
    "- Get relevant components and explained variance ratio of each principal component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset1:\n",
    "    pca = PCA()\n",
    "    pca.fit_transform(currData[\"train\"])\n",
    "\n",
    "    print(f\"[SUCCESS] identified {len(pca.components_)} relevant components\")\n",
    "    print(pca.components_)\n",
    "    print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- It applies [Gaussian Random Projection](https://scikit-learn.org/stable/modules/random_projection.html) to reduce the dimensionality of the training data for each dataset. \n",
    "\n",
    "Psuedocode :\n",
    "- Loop through datasets.\n",
    "- Create an instance of the GaussianRandomProjection class with a random state of 0 and sets the number of components to 25. \n",
    "- Fit the Gaussian Random Projection model to the training data of the current dataset and performs the actual random projection to reduce the dimensionality. \n",
    "\n",
    "Note: \n",
    "- The n_components parameter determines the desired reduced dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset2:\n",
    "    currData[\"train\"] = currData[\"train\"].fillna(0)\n",
    "    gaussian_rnd_proj = GaussianRandomProjection(random_state=0, n_components=25)\n",
    "    X_reduced = gaussian_rnd_proj.fit_transform(currData[\"train\"])\n",
    "\n",
    "    print(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [From the book](https://www.amazon.ca/Cleaning-Data-Effective-Science-command-line/dp/1801071292/ref=sr_1_1?keywords=data+cleaning&sr=8-1)\n",
    "\n",
    "This code snippet helps determine the name of the most relevant attributes in a model, however it is resource demanding and therefore is modified into the scripts below\n",
    "\n",
    "```\n",
    "for currData in dataset1:\n",
    "    trainningData = currData[\"train\"]\n",
    "    trainY = trainningData[\"ergot_present_in_q4\"]\n",
    "    trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "    poly = dict()\n",
    "    X_poly = dict()\n",
    "\n",
    "    For n in [2, 3, 4, 5]:\n",
    "        poly[n] = PolynomialFeatures(n)\n",
    "        X_poly[n] = poly[n].fit_transform(trainX)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100,max_depth=5, n_jobs=4, random_state=2)\n",
    "        rfecv = RFECV(estimator=model, n_jobs=1) # apply feature elimination/cross-validation to model\n",
    "        best_feat = rfecv.fit(X_poly[2], trainY)\n",
    "        X_support = X_poly[2][:, best_feat.support_] # X_support now automatically holds the best subset\n",
    "\n",
    "        print(X_support.shape)  # tells you the best dimensions to use\n",
    "        print(X_support)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runs it exactly once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "- Perform feature selection using Recursive Feature Elimination with Cross-Validation (RFECV) in combination with a Random Forest Classifier. \n",
    "- The goal is to identify the best subset of features that optimizes the classifier's performance.\n",
    "\n",
    "Psuedocode:  \n",
    "- Loop through the dataset.\n",
    "- Retrieve the training data and extract the target variable from the training data.\n",
    "- Create an instance of the RandomForestClassifier class with specific hyperparameters.\n",
    "- Create an instance of the [RFECV](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) class, which performs Recursive Feature Elimination with Cross-Validation using the given Random Forest Classifier model as the estimator.\n",
    "- Fit the RFECV model to the training data and retrieve the subset of features that were selected as the best subset by RFECV.\n",
    "\n",
    "Note:   \n",
    "- The RFECV process is ran exactly once in the snippet below\n",
    "- The n_jobs parameter specifies the number of CPU cores to use during cross-validation.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Using the snippet for feature analysis**:  \n",
    "- Change the dataset to whichever dataset youd like to use in the following line:  \n",
    "```for currData in dataset1:```  \n",
    "- Set the target in the following line (give the name of the column):  \n",
    "```trainY = trainningData[\"ergot_present_in_q4\"]```  \n",
    "- Remove all Ergot features or only other predictors in the following line:  \n",
    "```trainX = setModifier.rmErgotPredictors(trainningData)``` which can also be replaced with ```trainX = setModifier.rmErgotFeatures(trainningData)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset1:\n",
    "    trainningData = currData[\"train\"]\n",
    "    trainY = trainningData[\"ergot_present_in_q4\"]\n",
    "    trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "    try:\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "\n",
    "        # apply feature elimination/cross-validation to model\n",
    "        rfecv = RFECV(estimator=model, n_jobs=1)\n",
    "\n",
    "        best_feat = rfecv.fit(trainX, trainY)\n",
    "\n",
    "        # X_support now automatically holds the best subset\n",
    "        X_support = trainX.loc[:, best_feat.support_]\n",
    "\n",
    "        print(\"[SUCCESS]\")\n",
    "        print(X_support.shape)  # tells you the best dimensions to use\n",
    "\n",
    "        for col in X_support.columns.tolist():\n",
    "            print(col)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  \n",
    "- Perform feature selection using Recursive Feature Elimination with Cross-Validation (RFECV) in combination with a Random Forest Classifier. \n",
    "- The goal is to identify the best subset of features that optimizes the classifier's performance.\n",
    "\n",
    "Psuedocode:  \n",
    "- Loop through the dataset.\n",
    "- Retrieve the training data and extract the target variable from the training data.\n",
    "- Create an instance of the RandomForestClassifier class with specific hyperparameters.\n",
    "- Create an instance of the [RFECV](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) class, which performs Recursive Feature Elimination with Cross-Validation using the given Random Forest Classifier model as the estimator.\n",
    "- Fit the RFECV model to the training data and retrieve the subset of features that were selected as the best subset by RFECV.\n",
    "\n",
    "Note:   \n",
    "- The RFECV process is looped until no further changes are made between two iterrations (this can take awhile)\n",
    "- The n_jobs parameter specifies the number of CPU cores to use during cross-validation.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Using the snippet for feature analysis**:  \n",
    "- Change the dataset to whichever dataset youd like to use in the following line:  \n",
    "```for currData in dataset1:```  \n",
    "- Set the target in the following line (give the name of the column):  \n",
    "```trainY = trainningData[\"ergot_present_in_q4\"]```  \n",
    "- Remove all Ergot features or only other predictors in the following line:  \n",
    "```trainX = setModifier.rmErgotPredictors(trainningData)``` which can also be replaced with ```trainX = setModifier.rmErgotFeatures(trainningData)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currData in dataset2:\n",
    "    trainningData = currData[\"train\"]\n",
    "    trainY = trainningData[\"ergot_present_in_q4\"]\n",
    "    trainX = setModifier.rmErgotFeatures(trainningData)\n",
    "\n",
    "    reducable = True  # controls the loop, is true by default then is determined by\n",
    "\n",
    "    # comparing the calculated set of features against the current set of features\n",
    "    try:\n",
    "        while reducable:\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=100, max_depth=5, random_state=0\n",
    "            )\n",
    "\n",
    "            # apply feature elimination/cross-validation to model\n",
    "            rfecv = RFECV(estimator=model, n_jobs=1)\n",
    "\n",
    "            best_feat = rfecv.fit(trainX, trainY)\n",
    "\n",
    "            # X_support now automatically holds the best subset\n",
    "            X_support = trainX.loc[:, best_feat.support_]\n",
    "\n",
    "            # reduce the set to the subset proposed by the best features if we can\n",
    "            if X_support.shape < trainX.shape:\n",
    "                trainX = trainX[X_support.columns.tolist()]\n",
    "            else:\n",
    "                reducable = False\n",
    "\n",
    "        print(f'[SUCCESS] reduced data in dataset: {currData[\"desc\"]}')\n",
    "        print(X_support.shape)  # tells you the best dimensions to use\n",
    "\n",
    "        for col in X_support.columns.tolist():\n",
    "            print(col)\n",
    "\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
