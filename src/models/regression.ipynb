{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression.ipynb\n",
    " \n",
    "- Experiments on several regression models on different datasets to predict target variables (percnt_true and sum_severity) using different sets of features. \n",
    "- The models include Random Forest Regression and Support Vector Machine (SVM) Regression with different kernel functions (linear, polynomial, and radial basis function (RBF)).\n",
    "\n",
    "Note:\n",
    "- correlations between variables = bad therefore doing feature reduction to work around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor  # type: ignore\n",
    "from sklearn.svm import SVR, LinearSVR  # type: ignore\n",
    "from evaluator import ModelEvaluator\n",
    "import numpy as np\n",
    "import sys, warnings\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from datasets.setCreator import SetCreator\n",
    "from datasets.setModifier import SetModifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "\n",
    "- it defines lists of hyperparameters for the Random Forest Classifier and Support Vector Machine, filters out unnecessary warning messages, and prepares the datasets using a custom data set creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = [100, 200, 500]\n",
    "MAX_DEPTH = [5, 7, 10, 15]\n",
    "\n",
    "C = [0.01, 0.25, 0.5, 0.75, 1]\n",
    "GAMMA = [0.1, 0.5, 2, 5, 10]\n",
    "DEGREE = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "setModifier = SetModifier()\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "setCreator = SetCreator()\n",
    "dataset1 = setCreator.getSetList1()\n",
    "dataset2 = setCreator.getSetList2()\n",
    "dataset3 = setCreator.getSetList3()\n",
    "dataset4 = setCreator.getSetList4()\n",
    "dataset5 = setCreator.getSetList5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: \n",
    "- The purpose of this function is to run Random Forest Regression on a given dataset while performing feature selection using Recursive Feature Elimination with Cross-Validation (RFECV). \n",
    "- The function aims to find the best combination of hyperparameters for the Random Forest model that maximizes the average accuracy on the provided dataset.\n",
    "\n",
    "Psuedocode:\n",
    "- Loops through different datasets. \n",
    "- Test [Random Forest Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model with different hyperparameters.\n",
    "- Checks for the highest auc score.\n",
    "\n",
    "Note:\n",
    "- The difference between the two functions lies in how they handle the datasets: one function removes ergot-related predictors before training, while the other keeps them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithErgotFeatures(predictor, dataset):\n",
    "    print(\"Running the Random Forest Regression:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"avg_accuracy\": -100}\n",
    "\n",
    "    numCombinations = len(dataset)\n",
    "\n",
    "    for currData in dataset:\n",
    "        trainningData = currData[\"train\"]\n",
    "\n",
    "        trainY = []\n",
    "        for val in trainningData[predictor].values:\n",
    "            trainY.append(float(val))\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "\n",
    "        testY = []\n",
    "        for val in testData[predictor].values:\n",
    "            testY.append(float(val))\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for estimator in N_ESTIMATORS:\n",
    "            for depth in MAX_DEPTH:\n",
    "                try:\n",
    "                    rfc = RandomForestRegressor(\n",
    "                        random_state=5, n_estimators=estimator, max_depth=depth\n",
    "                    )\n",
    "                    rfc.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateRegression(\n",
    "                        rfc, currData[\"desc\"], trainX, trainY, testX, testY\n",
    "                    )\n",
    "\n",
    "                    if results[\"avg_accuracy\"] > bestModel[\"avg_accuracy\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"n_estimators\"] = estimator\n",
    "                        bestModel[\"max_depth\"] = depth\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the Random Forest Regression\"\n",
    "    )\n",
    "    print(f\"The best model, as per avg_accuracy, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithoutErgotFeatures(predictor, dataset):\n",
    "    print(\"Running the Random Forest Regression:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"avg_accuracy\": -100}\n",
    "\n",
    "    numCombinations = len(dataset)\n",
    "\n",
    "    for currData in dataset:\n",
    "        trainningData = currData[\"train\"]\n",
    "\n",
    "        trainY = []\n",
    "        for val in trainningData[predictor].values:\n",
    "            trainY.append(float(val))\n",
    "        trainX = setModifier.rmErgotFeatures(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "\n",
    "        testY = []\n",
    "        for val in testData[predictor].values:\n",
    "            testY.append(float(val))\n",
    "        testX = setModifier.rmErgotFeatures(testData)\n",
    "\n",
    "        for estimator in N_ESTIMATORS:\n",
    "            for depth in MAX_DEPTH:\n",
    "                try:\n",
    "                    rfc = RandomForestRegressor(\n",
    "                        random_state=5, n_estimators=estimator, max_depth=depth\n",
    "                    )\n",
    "                    rfc.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateRegression(\n",
    "                        rfc, currData[\"desc\"], trainX, trainY, testX, testY\n",
    "                    )\n",
    "\n",
    "                    if results[\"avg_accuracy\"] > bestModel[\"avg_accuracy\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"n_estimators\"] = estimator\n",
    "                        bestModel[\"max_depth\"] = depth\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested on the Random Forest Regression\"\n",
    "    )\n",
    "    print(f\"The best model, as per avg_accuracy, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWithErgotFeatures(\"percnt_true\", dataset1)\n",
    "testWithoutErgotFeatures(\"percnt_true\", dataset1)\n",
    "testWithErgotFeatures(\"percnt_true\", dataset2)\n",
    "testWithoutErgotFeatures(\"percnt_true\", dataset2)\n",
    "testWithErgotFeatures(\"percnt_true\", dataset3)\n",
    "testWithoutErgotFeatures(\"percnt_true\", dataset3)\n",
    "testWithErgotFeatures(\"percnt_true\", dataset4)\n",
    "testWithoutErgotFeatures(\"percnt_true\", dataset4)\n",
    "testWithErgotFeatures(\"percnt_true\", dataset5)\n",
    "testWithoutErgotFeatures(\"percnt_true\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWithErgotFeatures(\"sum_severity\", dataset1)\n",
    "testWithoutErgotFeatures(\"sum_severity\", dataset1)\n",
    "testWithErgotFeatures(\"sum_severity\", dataset2)\n",
    "testWithoutErgotFeatures(\"sum_severity\", dataset2)\n",
    "testWithErgotFeatures(\"sum_severity\", dataset3)\n",
    "testWithoutErgotFeatures(\"sum_severity\", dataset3)\n",
    "testWithErgotFeatures(\"sum_severity\", dataset4)\n",
    "testWithoutErgotFeatures(\"sum_severity\", dataset4)\n",
    "testWithErgotFeatures(\"sum_severity\", dataset5)\n",
    "testWithoutErgotFeatures(\"sum_severity\", dataset5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- The purpose of this code is to test and find the best configuration for a Linear [Support Vector Machine (SVM) regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html).\n",
    "- The function aims to find the best value for the hyperparameter C, which controls the trade-off between achieving a low training error and a low testing error, and maximizes the average accuracy on the provided dataset.\n",
    "\n",
    "Psuedocode : \n",
    "- Loops through different datasets. \n",
    "- Train Support Vector Machine model with different hyperparameters.\n",
    "- Checks for the highest auc score.\n",
    "\n",
    "Note :\n",
    "- The difference between the two functions lies in how they handle the datasets: one function removes ergot-related predictors before training, while the other keeps them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMLinearWithErgotFeatures(predictor, dataset):\n",
    "    print(\"Running linear SVM Regression:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"avg_accuracy\": -100}\n",
    "\n",
    "    numCombinations = len(dataset)\n",
    "\n",
    "    for currData in dataset:\n",
    "        trainningData = currData[\"train\"]\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for c in C:\n",
    "            try:\n",
    "                smv = LinearSVR(C=c, random_state=0)\n",
    "                smv.fit(trainX, trainY)\n",
    "                results = evaluator.evaluateRegression(\n",
    "                    smv,\n",
    "                    currData[\"desc\"],\n",
    "                    trainX,\n",
    "                    trainY,\n",
    "                    testX,\n",
    "                    testY,\n",
    "                    hasFeatImportance=False,\n",
    "                )\n",
    "\n",
    "                if results[\"avg_accuracy\"] > bestModel[\"avg_accuracy\"]:\n",
    "                    bestModel = results\n",
    "\n",
    "                    bestModel[\"c\"] = c\n",
    "\n",
    "            except Exception as e:\n",
    "                numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested with linear SVM Regression\"\n",
    "    )\n",
    "    print(f\"The best model, as per avg_accuracy, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- The purpose of this code is to test and find the best configuration for a Support Vector Machine (SVM) regression with a polynomial kernel on various datasets. It iterates through a list of datasets.\n",
    "- It aims to find the best model (in terms of the Area Under the ROC Curve - AUC) among the tested combinations.\n",
    "\n",
    "Psuedocode : \n",
    "- Loops through different datasets. \n",
    "- Trains the classifier using different values of the regularization parameter 'C' and the polynomial degree 'deg', evaluates the performance using the AUC (Area Under the Receiver Operating Characteristic Curve) metric.\n",
    "- Checks for the highest auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMPolyWithErgotFeatures(predictor, dataset):\n",
    "    print(\"Running poly kernal SVM Regression:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"avg_accuracy\": -100}\n",
    "\n",
    "    numCombinations = len(dataset)\n",
    "\n",
    "    for currData in dataset:\n",
    "        trainningData = currData[\"train\"]\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for c in C:\n",
    "            for deg in DEGREE:\n",
    "                try:\n",
    "                    smv = SVR(kernel=\"poly\", degree=deg, coef0=1, C=c, random_state=0)\n",
    "                    smv.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateRegression(\n",
    "                        smv,\n",
    "                        currData[\"desc\"],\n",
    "                        trainX,\n",
    "                        trainY,\n",
    "                        testX,\n",
    "                        testY,\n",
    "                        hasFeatImportance=False,\n",
    "                    )\n",
    "\n",
    "                    if results[\"avg_accuracy\"] > bestModel[\"avg_accuracy\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"c\"] = c\n",
    "                        bestModel[\"degree\"] = deg\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested with poly kernal SVM Regression\"\n",
    "    )\n",
    "    print(f\"The best model, as per avg_accuracy, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose :\n",
    "- The purpose of this code is to test and find the best configuration for a Support Vector Machine (SVM) regression with a radial basis function (RBF) kernel on various datasets.\n",
    "- It aims to find the best model (in terms of the Area Under the ROC Curve - AUC) among the tested combinations.\n",
    "\n",
    "Psuedocode : \n",
    "- Loops through different datasets. \n",
    "- Trains the classifier using different values of the regularization parameter 'C' and the kernel coefficient 'gamma', evaluates the performance using the AUC (Area Under the Receiver Operating Characteristic Curve) metric.\n",
    "- Checks for the highest auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMRBFWithErgotFeatures(predictor, dataset):\n",
    "    print(\"Running RBF SVM Regression:\")\n",
    "    print(f\"Predicting: {predictor}\\n\\n\")\n",
    "    numExcludedSets = 0\n",
    "    bestModel = {\"avg_accuracy\": -100}\n",
    "\n",
    "    numCombinations = len(dataset)\n",
    "\n",
    "    for currData in dataset:\n",
    "        trainningData = currData[\"train\"]\n",
    "        trainY = trainningData[predictor]\n",
    "        trainX = setModifier.rmErgotPredictors(trainningData)\n",
    "\n",
    "        testData = currData[\"test\"]\n",
    "        testY = testData[predictor]\n",
    "        testX = setModifier.rmErgotPredictors(testData)\n",
    "\n",
    "        for c in C:\n",
    "            for gam in GAMMA:\n",
    "                try:\n",
    "                    smv = SVR(kernel=\"rbf\", gamma=gam, C=c, random_state=0)\n",
    "                    smv.fit(trainX, trainY)\n",
    "                    results = evaluator.evaluateRegression(\n",
    "                        smv,\n",
    "                        currData[\"desc\"],\n",
    "                        trainX,\n",
    "                        trainY,\n",
    "                        testX,\n",
    "                        testY,\n",
    "                        hasFeatImportance=False,\n",
    "                    )\n",
    "\n",
    "                    if results[\"avg_accuracy\"] > bestModel[\"avg_accuracy\"]:\n",
    "                        bestModel = results\n",
    "\n",
    "                        bestModel[\"c\"] = c\n",
    "                        bestModel[\"gamma\"] = gam\n",
    "\n",
    "                except Exception as e:\n",
    "                    numExcludedSets += 1\n",
    "\n",
    "    print(\n",
    "        f\"[{numCombinations - numExcludedSets}/{numCombinations}] sets were tested with RBF SVM Regression\"\n",
    "    )\n",
    "    print(f\"The best model, as per avg_accuracy, was:\\n {bestModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMLinearWithErgotFeatures(\"percnt_true\", dataset1)\n",
    "SVMPolyWithErgotFeatures(\"percnt_true\", dataset1)\n",
    "SVMRBFWithErgotFeatures(\"percnt_true\", dataset1)\n",
    "SVMLinearWithErgotFeatures(\"percnt_true\", dataset2)\n",
    "SVMPolyWithErgotFeatures(\"percnt_true\", dataset2)\n",
    "SVMRBFWithErgotFeatures(\"percnt_true\", dataset2)\n",
    "SVMLinearWithErgotFeatures(\"percnt_true\", dataset3)\n",
    "SVMPolyWithErgotFeatures(\"percnt_true\", dataset3)\n",
    "SVMRBFWithErgotFeatures(\"percnt_true\", dataset3)\n",
    "SVMLinearWithErgotFeatures(\"percnt_true\", dataset4)\n",
    "SVMPolyWithErgotFeatures(\"percnt_true\", dataset4)\n",
    "SVMRBFWithErgotFeatures(\"percnt_true\", dataset4)\n",
    "SVMLinearWithErgotFeatures(\"percnt_true\", dataset5)\n",
    "SVMPolyWithErgotFeatures(\"percnt_true\", dataset5)\n",
    "SVMRBFWithErgotFeatures(\"percnt_true\", dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMLinearWithErgotFeatures(\"sum_severity\", dataset2)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity\", dataset2)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity\", dataset2)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity\", dataset3)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity\", dataset3)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity\", dataset3)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity\", dataset4)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity\", dataset4)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity\", dataset4)\n",
    "SVMLinearWithErgotFeatures(\"sum_severity\", dataset5)\n",
    "SVMPolyWithErgotFeatures(\"sum_severity\", dataset5)\n",
    "SVMRBFWithErgotFeatures(\"sum_severity\", dataset5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
