{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sq\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from Shared.DataService import DataService\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to update logs\n",
    "def updateLog(fileName: str, message: str) -> None:\n",
    "    try:\n",
    "        if fileName is not None:\n",
    "            with open(fileName, \"a\") as log:\n",
    "                log.write(message + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(message)\n",
    "\n",
    "LOG_FILE = \"/data/pull_moisture.log\"\n",
    "load_dotenv()\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PW = os.getenv(\"POSTGRES_PW\")\n",
    "PG_DB = os.getenv(\"POSTGRES_DB\")\n",
    "PG_ADDR = os.getenv(\"POSTGRES_ADDR\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "\n",
    "if (\n",
    "    PG_DB is None\n",
    "    or PG_ADDR is None\n",
    "    or PG_PORT is None\n",
    "    or PG_USER is None\n",
    "    or PG_PW is None\n",
    "):\n",
    "    updateLog(LOG_FILE, \"Missing database credentials\")\n",
    "    raise ValueError(\"Environment variables are not set\")\n",
    "else:\n",
    "    # connecting to database\n",
    "    db = DataService(PG_DB, PG_ADDR, int(PG_PORT), PG_USER, PG_PW)\n",
    "    conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"logistic_regression\": LogisticRegression,\n",
    "    \"random_forest\": RandomForestClassifier,\n",
    "    \"decision_tree\": DecisionTreeClassifier,\n",
    "    \"gradient_boost\": GradientBoostingClassifier,\n",
    "    #\"svc\": SVC,\n",
    "    #\"linear_svc\": LinearSVC,\n",
    "}\n",
    "\n",
    "def model_initializer(model_type:str, random_state:int=42 , max_depth:int=2):\n",
    "    # if network then initialize the network model differently (passing X-train, xtest, ytest ...)\n",
    "    # currently haven't had any networks.\n",
    "    if model_type == 'random_forest':\n",
    "        model = model_dict[model_type](random_state=random_state, max_depth=max_depth)\n",
    "    else: \n",
    "        model = model_dict[model_type](random_state=random_state)\n",
    "    return model\n",
    "\n",
    "# def evaluate_model(dataset, arg, model_type):\n",
    "#     f1_score = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data (only ergot and soil moisture rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>province</th>\n",
       "      <th>district</th>\n",
       "      <th>incidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>AB</td>\n",
       "      <td>4810</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1995</td>\n",
       "      <td>AB</td>\n",
       "      <td>4820</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1995</td>\n",
       "      <td>AB</td>\n",
       "      <td>4830</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1995</td>\n",
       "      <td>AB</td>\n",
       "      <td>4840</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1995</td>\n",
       "      <td>AB</td>\n",
       "      <td>4840</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158540</th>\n",
       "      <td>2022</td>\n",
       "      <td>AB</td>\n",
       "      <td>4830</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158636</th>\n",
       "      <td>2022</td>\n",
       "      <td>SK</td>\n",
       "      <td>4771</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158655</th>\n",
       "      <td>2022</td>\n",
       "      <td>MB</td>\n",
       "      <td>4603</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158660</th>\n",
       "      <td>2022</td>\n",
       "      <td>SK</td>\n",
       "      <td>4740</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158677</th>\n",
       "      <td>2022</td>\n",
       "      <td>SK</td>\n",
       "      <td>4721</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5449 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year province  district  incidence\n",
       "0       1995       AB      4810      False\n",
       "48      1995       AB      4820      False\n",
       "190     1995       AB      4830      False\n",
       "230     1995       AB      4840      False\n",
       "280     1995       AB      4840       True\n",
       "...      ...      ...       ...        ...\n",
       "158540  2022       AB      4830       True\n",
       "158636  2022       SK      4771       True\n",
       "158655  2022       MB      4603       True\n",
       "158660  2022       SK      4740       True\n",
       "158677  2022       SK      4721       True\n",
       "\n",
       "[5449 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling ergot data\n",
    "query = sq.text(\"select * FROM public.agg_ergot_samples\")\n",
    "ergot_df = pd.read_sql(query, conn).drop(columns=['sample_id']).drop_duplicates()[['year', 'province', 'district', 'incidence']]\n",
    "ergot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>cr_num</th>\n",
       "      <th>district</th>\n",
       "      <th>soil_moisture_min</th>\n",
       "      <th>soil_moisture_max</th>\n",
       "      <th>soil_moisture_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>4612</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.418710</td>\n",
       "      <td>0.237053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978</td>\n",
       "      <td>5</td>\n",
       "      <td>4740</td>\n",
       "      <td>0.127140</td>\n",
       "      <td>0.207248</td>\n",
       "      <td>0.163722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1978</td>\n",
       "      <td>5</td>\n",
       "      <td>4741</td>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.215304</td>\n",
       "      <td>0.170989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1978</td>\n",
       "      <td>7</td>\n",
       "      <td>4770</td>\n",
       "      <td>0.140772</td>\n",
       "      <td>0.186390</td>\n",
       "      <td>0.152211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>7</td>\n",
       "      <td>4771</td>\n",
       "      <td>0.116810</td>\n",
       "      <td>0.116810</td>\n",
       "      <td>0.116810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117216</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.191339</td>\n",
       "      <td>0.271052</td>\n",
       "      <td>0.220148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117217</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.251481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117218</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.193165</td>\n",
       "      <td>0.267507</td>\n",
       "      <td>0.223290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117219</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.191507</td>\n",
       "      <td>0.243024</td>\n",
       "      <td>0.208214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117220</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.203048</td>\n",
       "      <td>0.214118</td>\n",
       "      <td>0.208583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117211 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  cr_num  district  soil_moisture_min  soil_moisture_max  \\\n",
       "0       1978       0      4612           0.165900           0.418710   \n",
       "1       1978       5      4740           0.127140           0.207248   \n",
       "2       1978       5      4741           0.153398           0.215304   \n",
       "3       1978       7      4770           0.140772           0.186390   \n",
       "4       1978       7      4771           0.116810           0.116810   \n",
       "...      ...     ...       ...                ...                ...   \n",
       "117216  2017       9      4840           0.191339           0.271052   \n",
       "117217  2017       9      4840           0.251481           0.251481   \n",
       "117218  2017       9      4840           0.193165           0.267507   \n",
       "117219  2017       9      4840           0.191507           0.243024   \n",
       "117220  2017       9      4840           0.203048           0.214118   \n",
       "\n",
       "        soil_moisture_mean  \n",
       "0                 0.237053  \n",
       "1                 0.163722  \n",
       "2                 0.170989  \n",
       "3                 0.152211  \n",
       "4                 0.116810  \n",
       "...                    ...  \n",
       "117216            0.220148  \n",
       "117217            0.251481  \n",
       "117218            0.223290  \n",
       "117219            0.208214  \n",
       "117220            0.208583  \n",
       "\n",
       "[117211 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling soil moisture data\n",
    "query = sq.text(\"select * FROM public.agg_soil_moisture\")\n",
    "sm_df = pd.read_sql(query, conn).drop(columns=['index', 'month', 'day']).drop_duplicates()\n",
    "sm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data:  [[0.15443027 0.15443027 0.15443027]\n",
      " [0.16073954 0.20681489 0.18377721]\n",
      " [0.16988319 0.23791865 0.21258988]\n",
      " ...\n",
      " [0.22753887 0.26947325 0.24850606]\n",
      " [0.22753887 0.26947325 0.24850606]\n",
      " [0.22753887 0.26947325 0.24850606]]\n",
      "X shape: (353329, 3) \n",
      "\n",
      "y data:  [False False False ...  True  True  True]\n",
      "y shape:  (353329,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(sm_df, ergot_df, how=\"inner\", on=[\"year\", \"district\"])\n",
    "\n",
    "features = ['soil_moisture_min', 'soil_moisture_max', 'soil_moisture_mean']\n",
    "\n",
    "X = np.array(df[features]).squeeze()\n",
    "y = np.array(df[['incidence']]).squeeze()\n",
    "print('X data: ', X)\n",
    "print('X shape: {} \\n'.format(X.shape))\n",
    "print('y data: ', y)\n",
    "print('y shape: ', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: \n",
      "model type: logistic_regression, and its r^2 score is : 0.6834970141227747 and f1_score is: 0.8119967049409075\n",
      "model type: random_forest, and its r^2 score is : 0.6834970141227747 and f1_score is: 0.8119967049409075\n",
      "model type: decision_tree, and its r^2 score is : 0.6668694987688563 and f1_score is: 0.7941878458834946\n",
      "model type: gradient_boost, and its r^2 score is : 0.6835253162765687 and f1_score is: 0.8120103560741064\n",
      "End the fold 0\n",
      "\n",
      "Fold 1: \n",
      "model type: logistic_regression, and its r^2 score is : 0.8544278719610562 and f1_score is: 0.9214906623724519\n",
      "model type: random_forest, and its r^2 score is : 0.8548382531910679 and f1_score is: 0.9217388650685873\n",
      "model type: decision_tree, and its r^2 score is : 0.6842045679676223 and f1_score is: 0.8043794596679466\n",
      "model type: gradient_boost, and its r^2 score is : 0.8535788073472391 and f1_score is: 0.9209507001902317\n",
      "End the fold 1\n",
      "\n",
      "Fold 2: \n",
      "model type: logistic_regression, and its r^2 score is : 0.8394277304502873 and f1_score is: 0.912705312151402\n",
      "model type: random_forest, and its r^2 score is : 0.8394277304502873 and f1_score is: 0.912705312151402\n",
      "model type: decision_tree, and its r^2 score is : 0.6986952707101011 and f1_score is: 0.8149969589017292\n",
      "model type: gradient_boost, and its r^2 score is : 0.8394701836809781 and f1_score is: 0.9127263774984228\n",
      "End the fold 2\n",
      "\n",
      "Fold 3: \n",
      "model type: logistic_regression, and its r^2 score is : 0.8649704242492854 and f1_score is: 0.9275925391935165\n",
      "model type: random_forest, and its r^2 score is : 0.8649138199416976 and f1_score is: 0.9275643846842608\n",
      "model type: decision_tree, and its r^2 score is : 0.7083604562307192 and f1_score is: 0.8230029973290277\n",
      "model type: gradient_boost, and its r^2 score is : 0.8649704242492854 and f1_score is: 0.9275925391935165\n",
      "End the fold 3\n",
      "\n",
      "Fold 4: \n",
      "model type: logistic_regression, and its r^2 score is : 0.857807967169037 and f1_score is: 0.9234566396489731\n",
      "model type: random_forest, and its r^2 score is : 0.8580768414349395 and f1_score is: 0.9236182511938218\n",
      "model type: decision_tree, and its r^2 score is : 0.6851906884596335 and f1_score is: 0.8048596491228069\n",
      "model type: gradient_boost, and its r^2 score is : 0.8530248354914031 and f1_score is: 0.920581758120756\n",
      "End the fold 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5) # we need to modify it to make sure the outliers dont fall into 1 bin\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f'Fold {i}: ')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for model_type in model_dict:\n",
    "        model = model_initializer(model_type).fit(X_train, y_train.squeeze())\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f'model type: {model_type}, and its r^2 score is : {model.score(X_test, y_test)} and f1_score is: {f1_score(y_test, y_pred)}')\n",
    "    print(f'End the fold {i}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave one out cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified KFold\n",
    "\n",
    "KFold validation does not preserve the split of the output variable while splitting the data. For example, it is possible that if we have ten samples where 5 of them has incidence = True, and 5 of them has incidence = False, KFold can randomly put all positive (incidence = True) in 1 bin and all negative in another bin. To avoid that, we can use Stratified KFold - preserve the split in the original dataset in training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 37686  37687  37688 ... 353326 353327 353328]\n",
      "  Test:  index=[    0     1     2 ... 82284 82285 82286]\n",
      "model type: logistic_regression, and its r^2 score is : 0.8201398126397419 and f1_score is: 0.9011833123415901\n",
      "model type: random_forest, and its r^2 score is : 0.8201398126397419 and f1_score is: 0.9011833123415901\n",
      "model type: decision_tree, and its r^2 score is : 0.2918659609996321 and f1_score is: 0.3847392817183677\n",
      "model type: gradient_boost, and its r^2 score is : 0.8196303738714517 and f1_score is: 0.9008216875719754\n",
      "End the fold 0 \n",
      "\n",
      "Fold 1:\n",
      "  Train: index=[     0      1      2 ... 353326 353327 353328]\n",
      "  Test:  index=[ 37686  37687  37688 ... 149073 149074 149075]\n",
      "model type: logistic_regression, and its r^2 score is : 0.8198426400249059 and f1_score is: 0.9010038802186608\n",
      "model type: random_forest, and its r^2 score is : 0.8201539637166388 and f1_score is: 0.9011918552669429\n",
      "model type: decision_tree, and its r^2 score is : 0.08949141029632356 and f1_score is: 0.13651125962906296\n",
      "model type: gradient_boost, and its r^2 score is : 0.8186822517193558 and f1_score is: 0.9002576657506947\n",
      "End the fold 1 \n",
      "\n",
      "Fold 2:\n",
      "  Train: index=[     0      1      2 ... 353326 353327 353328]\n",
      "  Test:  index=[ 90470  90476  90482 ... 218879 218880 218882]\n",
      "model type: logistic_regression, and its r^2 score is : 0.8201964169473297 and f1_score is: 0.9012128751360596\n",
      "model type: random_forest, and its r^2 score is : 0.8201539637166388 and f1_score is: 0.9011918552669429\n",
      "model type: decision_tree, and its r^2 score is : 0.2718421871904452 and f1_score is: 0.40599819915498814\n",
      "model type: gradient_boost, and its r^2 score is : 0.820097359409051 and f1_score is: 0.9011546087159351\n",
      "End the fold 2 \n",
      "\n",
      "Fold 3:\n",
      "  Train: index=[     0      1      2 ... 353326 353327 353328]\n",
      "  Test:  index=[179927 179932 179937 ... 285828 285829 285830]\n",
      "model type: logistic_regression, and its r^2 score is : 0.8202105680242266 and f1_score is: 0.9012198819770019\n",
      "model type: random_forest, and its r^2 score is : 0.8201539637166388 and f1_score is: 0.9011918552669429\n",
      "model type: decision_tree, and its r^2 score is : 0.3926782328135171 and f1_score is: 0.5483514517537859\n",
      "model type: gradient_boost, and its r^2 score is : 0.8202247191011236 and f1_score is: 0.9012268889268998\n",
      "End the fold 3 \n",
      "\n",
      "Fold 4:\n",
      "  Train: index=[     0      1      2 ... 285828 285829 285830]\n",
      "  Test:  index=[259924 259925 259926 ... 353326 353327 353328]\n",
      "model type: logistic_regression, and its r^2 score is : 0.819882544399632 and f1_score is: 0.9010202811994525\n",
      "model type: random_forest, and its r^2 score is : 0.8201514186655345 and f1_score is: 0.9011903188437347\n",
      "model type: decision_tree, and its r^2 score is : 0.6552465860043869 and f1_score is: 0.7827420764442542\n",
      "model type: gradient_boost, and its r^2 score is : 0.8154248920965117 and f1_score is: 0.8982041536264234\n",
      "End the fold 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for model_type in model_dict:\n",
    "        model = model_initializer(model_type).fit(X_train, y_train.squeeze())\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f'   model type: {model_type}, and its r^2 score is : {model.score(X_test, y_test)} and f1_score is: {f1_score(y_test, y_pred)}')\n",
    "    print(f'End the fold {i} \\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
